% !TeX spellcheck = en_GB
\documentclass[12pt,a4paper,openright,twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage{phd-thesis}
\usepackage{code-lstlistings}
\usepackage{notes}
\usepackage{shortcuts}

\school{\MakeUppercase{\unibo}}
\programme{Dottorato di Ricerca in Data Science and Computation}
\title{On the role of Computational Logics in modern Data Science: representing, learning, reasoning, and explaining knowledge}
\author{Giovanni Ciatto}
\date{\today}
\contestsector{09/H1 -- Sistemi di Elaborazione delle Informazioni}
\scientificsector{ING-INF/05 -- Sistemi di Elaborazione delle Informazioni}
\coordinator{Andrea Cavalli}
\supervisor{Andrea Omicini}
\cycle{XXXIII}
\examyear{2022}

% \mainlinespacing{1.241} % line spacing in mainmatter, comment to default (1)

\begin{document}

\frontmatter
\frontispiece

\begin{abstract}
Max 2000 characters, strict.
\end{abstract}

\begin{dedication} % this is optional
Optional. Max a few lines.
\end{dedication}

\begin{acknowledgements} % this is optional
Optional. Max 1 page.
\end{acknowledgements}

%----------------------------------------------------------------------------------------
\tableofcontents
\listoffigures     % (optional) comment if empty
\lstlistoflistings % (optional) comment if empty
%----------------------------------------------------------------------------------------

\mainmatter

%----------------------------------------------------------------------------------------
\chapter{Introduction}
\label{chap:introduction}
%----------------------------------------------------------------------------------------

In the last decade we have witnessed an explosion in the exploitation of artificial intelligence (AI) both in the academy and in the industry, and in virtually all strategical sectors of human expertise.
%
This is not the first time in history that AI attains unprecedented levels of attention, expectation, and fundings, yet it is the first time that such momentum is driven by a pervasive adoption of data science (DS) and, in particular, machine learning (ML).

Nowadays, the tree terms -- AI, DS, and ML -- are often used mistakenly interchangeably, especially by practitioners.
%
Should we speculate on what the causes of such phenomenon are, we would argue this is likely due to the strong hype characterising modern data-driven solutions---both in theory and in practice.
%
This leads both researchers and practitioners to focus on the development of \emph{ML-oriented} frameworks or technologies which, in turn, create a sampling bias making people think that ML exhausts DS, and DS saturates AI.
%
As we further discuss in the subsequent chapters, this is really far from the truth.
%
There are many interesting aspects of AI which lay outside the realm of DS.
%
Notably, in this thesis we focus on computational logics (CL) -- a prominent aspect of AI populating the portion which is not covered by DS -- and its potential role in complementing DS.

As sub-fields of AI, both DS and CL share the common goal of mimicking human intelligence.
%
Of course, they do so in different ways.
%
They focus on different notions and aspects of intelligence, they pursue intelligence through different ways, and for different purposes.
%
Notably, most differences lay in the way CL and DS treat \emph{knowledge}, and, in particular, in the way knowledge is represented, acquired, manipulated, and transferred.

CL, for instance, focuses on \emph{rational} intelligence, and it aims at endowing machines with human-like, automated \emph{reasoning} capabilities.
%
Following this purpose, it relies on \emph{symbolically} represented knowledge, either acquired via logic induction or via manual handcrafting, manipulated via logic inference (e.g. deduction or abduction), and transferred by simply presenting symbols into shared formats.
%
Dually, DS focuses on \emph{intuitive} intelligence, and it aims at endowing humans with statistical tools for mining significant and predictive information from data, in a principled way.
%
When applied to machines, DS provides them with powerful pattern matching, recognition, or stimulus-response capabilities.
%
For this reason, it relies on sub-symbolically (e.g. \emph{numerically}) represented knowledge, commonly acquired from data via ML, manipulated via algebraic or differential operations, and transferred in disparate, purpose-specific ways.

Of course, both CL and DS come with shortcomings.
%
On the one side, CL commonly requires
%
\begin{inlinelist}
    \item some symbolic knowledge to be eventually handcrafted by humans, manually; and
    \item the task at hand to have a clear formulation, which can be expressed via crisp symbols.
\end{inlinelist}
%
The former issue, clearly hinders scalability, making CL fall short on the knowledge provisioning side.
%
Vice versa, DS is very well suited on this side, as it naturally leverages on scalable algorithms which have been designed mine information semi-automatically from data, possibly scaling up to very large datasets.
%
The latter issue, in turn, makes CL poorly suited to handle fuzzy tasks which are hard to formalise or encode symbolically---think, for instance, to the task of handwritten digits recognition.
%
On the other side, to be effective, DS commonly requires
%
\begin{inlinelist}
    \item very large amounts of data; and
    \item users to be willing and capable of interpreting the numeric results it outputs.
\end{inlinelist}
%
The former issue actually constrains the exploitation of DS into use cases where data is already available or a provisioning procedure is admissible.
%
Vice versa, CL is data efficient as it can bring valuable results even in presence of very small prior knowledge.
%
The interpretability issue is, in turn, among the most relevant topic nowadays.
%
Given the wide exploitation of DS in some many areas of expertise, clarity and intelligibility of its outcomes are becoming a critical aspects---mostly because of their sub-symbolic nature.
%
Vice versa, CL is inherently symbolic in nature and therefore less subject to such interpretability issues.

Accordingly, this thesis stems from the acknowledgement that CS and DS are complementary -- rather than competing -- aspects of AI, and that \emph{knowledge} plays a pivotal role in both these fields.
%
Along this line, we aim to \emph{elicit} and \emph{enable} the many possible bridges among them, w.r.t. knowledge manipulation.
%
In doing so, we follow the ultimate purpose of increasing the degree of intelligence and autonomy of modern computational systems.
%
Therefore, our focus is on computational entities and on the ways they can combine and integrate CL and DS to either act more intelligently or more autonomously---or both.

On the one side, we \emph{elicit} analogies, dichotomies, and possible synergies among CL and DS by analysing them along four orthogonal dimensions, corresponding to as many knowledge-related activities, namely:
%
\begin{description}
    \item[representation] | i.e. the way knowledge is expressed and made interpretable by either machines or human beings, or both; e.g. via symbols, formul\ae, or tensors of real numbers

    \item[acquisition] | i.e. the way novel knowledge is learned from prior information, mined from data, or attained from external sources; e.g. via data mining, via induction, or via interaction

    \item[inference] |  i.e. the way decisions, suggestions, recommendations, or predictions can be automatically computed out of prior knowledge; e.g. via automated deduction/abduction, or via classification/regression

    \item[explanation] | i.e. the way knowledge can be transferred to another entity---be it computational or human
\end{description}

On the other side, we acknowledge that both CL and DS have a prominent overlap with computer science (CS) and software engineering (SE).
%
Regardless of how they manipulate knowledge, both approaches subtend a mathematical modelling of many computational aspects, which must then be reified into well-engineered software technologies to let practitioners actually exploit them.
%
Accordingly, we further analyse CL and DS from both a computational and technological perspective.
%
While the computational perspective focuses on \emph{what} data structures, algorithms, and workflows they leverage upon to attain intelligence, the technological perspective focuses on \emph{how} such aspects can be translated in practice, via robust software architectures and effective implementations.
%
Along this line, in particular, we assess the current state of the art for technologies laying at the intersection among DS and CL -- or supporting the construction of bridges among the two fields --, identifying holes and proposing lacks to overcome them.
%
The latter in particular is the contribution by which we \emph{enable} the actual combination of CL and DS in practice.

We carry out the whole discussion under an agent-oriented mindset.
%
Within the scope of this document, we call ``agent'' any autonomous entity having its own \emph{locus of control}---be it a human being or a running process programmed software.
%
We may refer to agents as ``intelligent'' in case the come equipped with human-like knowledge-related capabilities, such as the aforementioned capabilities of representing, learning, inferring, or explaining knowledge---or, possibly, a multitude of them.
%
Under such a mindset, human agents are intelligent by definition, whereas software agents may tend to intelligence by acquiring one or more of these capabilities via either CS or DS---or, hopefully, a combination of them.
%
Accordingly, what we have so far called ``machines'' are indeed ``software agents'', and the overall role of the agent-oriented mindset is about focussing on \emph{who} is charge of manipulating knowledge and \emph{when}, other than \emph{where} should knowledge be located in the meanwhile.

\note{Discuss the goal of the thesis}

\paragraph{Structure of the thesis}

Summarising, the whole thesis discusses in what ways CL and DS can jointly contribute to the management of knowledge within the scope of modern and future intelligent systems, and how technically sound software technologies can be realised along the path.
%
An agent-oriented mindset permeates the whole discussion, by stressing pivotal role of autonomous agents in exploiting both means to reach higher degrees of intelligence.
%
Accordingly, this thesis is organised in three parts, named \emph{What}, \emph{How}, and \emph{Who}, respectively.

In the first part (\emph{What}), we focus on the computational perspective.
%
There, we present the two main branches of AI---namely, the \emph{symbolic} and \emph{sub-symbolic} ones.
%
In particular, we recall classical definitions and survey the current state of the art for both CL and DS.
%
We finally present their strengths and weaknesses, and the many possible bridges among them, w.r.t. knowledge representation, acquisition, manipulation, and transfer.

In the second part (\emph{How}), we focus on the technological perspective.
%
There, we survey the current state of technologies.
%
In particular, we focus on logic-based technologies laying at the intersection with DS, identifying the current lacks w.r.t. current theoretical advances.
%
We then propose the notion of AI ecosystem, and \twopkt{} as its main reification in software.
%
Finally, we present a number of possible ways to extend the \twopkt{} ecosystem towards DS.

Finally, the third part (\emph{Who}) closes the loop by discussing the role of agents \ldots
\note{TBD}


\part{What}
\label{part:what}

\chapter{Historical Perspective on AI}

AI is a multi-faceted discipline leveraging on contributions coming from several areas of human knowledge, there including Mathematics, Computer Science, Statistics, Psychology, Philosophy, and many others.
%
A famous and comprehensive survey on the many aspects of AI is proposed by Russell and Norving in \cite{russell2016artificial}.
%
In the second half the $20^{th}$ century -- when AI was firstly recognised as discipline by itself -- several approaches towards machine intelligence became subject of intensive research efforts, leading to the vast corpus of literature and to the abundance of techniques available today.

Notably, two main families of approaches has initially emerged in AI, namely, the \emph{symbolic} and \emph{connectionist} ones \cite{Smolensky1987, SUN2001783}.
%
While the former focuses on representing the world through symbols -- in turn representing concepts --, thus emulating how the human \emph{mind} reasons and infers, the latter aims at mimicking human intuition by emulating how the human \emph{brain} works at a very low level.
%
Despite both families have both pros and cons, they have stepped through both glory and misery---in terms of expectations, funding, research interest, and industry adoption \cite{Hendler2008, russell2016artificial}.

For instance, despite the initial hype, artificial neural networks (NN) -- the warhorse of connectionism -- encountered their first \emph{winter} when Rosenblatt's \emph{perceptron} \cite{rosenblatt1957perceptron} was proven unable to learn the XOR function \cite{Minsky1988}.
%
The period following the publication of the well-known back-propagation algorithm \cite{Rumelhart1986} and the proof that multi-layered perceptrons could be used as universal functional approximators \cite{Cybenko1989}, can be considered as the second \emph{spring} of connectionist approaches.
%
However, at the time -- likely, because of computational limits of the hardware and the lack of data -- the success of connectionist approaches can be considered very moderate, especially when compared with the explosion of deep NN and deep learning (DL) \cite{goodfellow2016deep} which was pervasive in both the academy and the industry during the 2010s, and can thus be considered the third spring of AI.

Even if it is currently not as popular as NN, the history of symbolic AI is extremely important as well---mostly because of the prominent influence it has on the many fields converging in AI.
%
Despite their original ambition of reproducing human reasoning \emph{in toto} has been inevitably rejected by facts, symbolic approaches gave birth to several research lines which are nowadays considered autonomous fields, such as computational logic \cite{lloyd1990computational}, logic programming \cite{apt1990logic}, planning \cite[Chap. 10-11]{russell2016artificial}, multi-agent systems \cite{ferber1999multi}, etc.

A few decades later, many things has changed.
%
ML, DL, Data Mining \cite{hand2006data}, and Bayesian Inference have enormously widened the spectrum of tasks AI can handle, other than the amount of use cases where AI can be applied.
%
Nevertheless, a dualism is still there, alive and healthy, dividing symbolic approaches from what are now called \emph{sub-symbolic}  ones.

Nowadays, sub-symbolic techniques include NN, but they are not limited to the connectionist techniques.
%
The panorama of sub-symbolic techniques has been widened by the development of several data-mining algorithms -- along with their efficient implementations --, such as SVM \cite{Smola2004}, K-Means, Expectation Maximisation \cite{Dempster77maximumlikelihood}, Viterbi \cite{Viterbi06}, etc., which mostly leverage on \emph{numerical} computations while not being backed by a biological metaphor.

Summarising, at the gates of 2020s, AI consists of a number of powerful techniques -- often backed by sound theoretical or empirical backgrounds --, which are widely employed to automate disparate tasks, both in the industry and in the research.
%
Such tasks, and, in particular, the techniques supporting them, can be categorised within two mostly disjoint families---namely the symbolic and sub-symbolic ones.

\subsubsection{Weak vs.\ Strong AI}

A fundamental question in AI concerns the ultimate goal of the discipline itself.
%
Some say AI should (tend to) produce machines which are actually able to think intelligently -- thus adapt to different situations, understand the context their are situated into, learn from the interactions with the environment and with others --, while say it would be sufficient to create machines simply acting \emph{as if} they were thinking intelligently.
%
The former perspective is classically known as \emph{strong} AI, while the latter is known as \emph{weak} AI.
%
Searle's Chinese Room argument \cite{searle1980} clearly explains the difference among the two by means of a practical example, whereas the well known Turing test \cite{Turing1950} provides a practical means to decide whether a machine's AI is actually strong or not.

Even without discussing the many important and subtle philosophical issues arising from such a dualistic view of AI, we note what follows.
%
The original goal of AI was reaching strong AI.
%
This is likely why, initially, so much hype was put in both symbolic and connectionist approaches.
%
But this is also justifying the strong disappointment which led AI towards its first winter.
%
Most researchers soon realised that weak AI was a far more affordable deal, and this is likely why they stopped seeking generality and started focusing on how to improve each single technique, tailoring them to the domains where they could bring more advantage.

A few years later, the global effect is that a plethora of techniques is available to effectively and efficiently tackle as many tasks.
%
But the glue keeping everything together is still human intelligence \cite{Yao2018}.
%
Indeed, symbolic techniques still require human beings to \emph{handcraft} most complex rules or to \emph{manually} build large knowledge bases.
%
Similarly, most ML-powered models still rely on data scientists to lead their training process.
%
Data scientists are still needed, for instance, to clean-up and pre-process data, and to set up predictors hyper-parameters through their experience, or to leverage on their intuition to interpret how a trained predictor is functioning.

Summarising, the success of AI nowadays is also due to its reduced expectations with respect to what can be delegated to machines.
%
As a side effect, poor care is dedicated in studying how AI could be used to \emph{automate} the many processes involving several, interrelated AI-powered tasks.

\subsubsection{Symbolic vs.\ Sub-symbolic AI}

In the recent years, the historical dichotomy between the ``two souls'' of AI has been reconciled, in favour of a comprehensive vision where symbolic and sub-symbolic approaches are seen as \emph{complementary} -- rather than in a competition -- so that they mutually soften their corners \cite{Hoehndorf2017, xailp-woa2019, lpaas-bdcc2}.
%
While symbolic approaches are well suited for relatively small-sized problems where complex and exact tasks has to be performed, possibly relying on structured data -- like for instance planning a sequence of actions, finding a path in a graph taking several constrains into an account, deducing information from a prior knowledge base, or learning mathematical relations from vary small data sets --, sub-symbolic approaches are best suited for those use cases where big (up to huge) amounts of possibly unstructured data  must be processed, where errors or lack of precision is tolerated to some extent, if unavoidable---like for instance classifying images or texts, profiling customers by looking at their shopping history, forecasting the weather for a particular area, etc.
%
Such issues, are not affecting symbolic techniques---especially when symbols are wisely chosen in order to steer humans' intuition.
%
This is because symbols are far closer to what our conscious, rational mind used to handle.
%
For all such reasons, many researchers along the history of AI have argued that a comprehensive approach unifying the two worlds would bring great advantage.

More precisely, complementarity between symbolic and sub-symbolic AI naturally emerges when comparing the two approaches under the following perspectives:
%
\begin{itemize}
    \item sub-symbolic AI is \emph{opaque}, meaning that human beings struggle in understanding the functioning and behaviour of sub-symbolically intelligent systems; instead, symbolic AI is more \emph{transparent}, as it is both human- and machine-interpretable at the same time
    %
    \item sub-symbolic AI can improve itself \emph{automatically} by consuming data, but it is difficult to extend and re-use outside the contexts it was designed for; conversely, symbolic AI is flexible and extensible, but requires humans to \emph{manually} provide symbolic knowledge
    %
    \item sub-symbolic AI is adequate for \emph{fuzzy} problems where some (minimal) degree of error or uncertainty can be tolerated; whereas symbolic AI calls for precise data and queries provided by human beings, yet provides exact, \emph{crisp} results as its outcome.
\end{itemize}

In the remainder of this chapter, we provide a brief overview of the two major disciplines laying within the scope of symbolic or sub-symbolic AI, respectively.
%
These are computational logic -- a prominent branch of symbolic AI leveraging on logics to per form any knowledge-related task, ranging from representation to inference --, and data science -- a prominent branch of sub-symbolic AI leveraging on statistics to manipulate data and mine knowledge out of them.

\section{Computational Logic}
\mypapers[section]{cco-softwarex-2021-2pkt,Korner2020HistoryFuturePrologTPLP,logictech-information11}

\emph{Computational logic} (CL) \cite{lloyd1990computational} is a fundamental research area for \emph{artificial intelligence} (AI), dealing with formal logic as a means for computing \cite{Paulson2018}.
%
Its penetration into \emph{symbolic AI} is nearly pervasive nowadays, and increasingly going deeper within \emph{sub-symbolic AI} \cite{xaisurvey-ia14,lptech4mas-jaamas35}: CL has enabled the development of the former in the past, and it is now pushing the latter towards interpretability and explainability.
%
Be it exploited to manipulate symbols, or to make sub-symbolic solutions human-intelligible, the common expectation behind CL is to endow software systems with \emph{automated} reasoning.

Generally speaking, automated reasoning involves three major aspects:
%
\begin{inlinelist}
    \item logics,
    \item inference rules, and
    \item resolution strategies.
\end{inlinelist}

\emph{Logic} formally defines how knowledge is represented and how novel knowledge can be derived from prior one.
%
Each logic comes with several \emph{inference rules}, dictating how to produce new knowledge under particular circumstances.
%
When coupled with some \emph{resolution strategy}, inference rules become deterministic algorithms that computers can execute to reason autonomously.

Many logics exist in CL -- e.g. propositional, first-order (FOL), temporal, deontic, etc. --, each one targeting a specific way of reasoning.
%
For instance, temporal logic enables reasoning about the chronological ordering of events, deontic logic supports reasoning about permissions/prohibitions and their circumstances, while FOL is general-purpose.
%
Furthermore, different sorts of inference rules exist for different logics.
%
Some are \emph{deductive} -- drawing conclusions out of premises --, some are \emph{inductive} -- looking for general rules out of several premises-conclusion examples --, while other are \emph{abductive}---speculating on which premises caused some conclusions.
%
Finally, when a resolution strategy exists for some rule and logic, it can be reified in software, and used to build intelligent systems capable of automated reasoning.
%
Software of that sort are commonly referred to as a part of the \emph{logic programming} (LP) paradigm~\cite{Nerode1996}.

In LP, programs are typically \emph{theories} (a.k.a.\ \emph{knowledge bases}, KB), i.e.\ collections of sentences in logical form, expressing \emph{facts} and \emph{rules} about some domain, typically in the form of \emph{clauses}, i.e. expressions connecting a number of interrelated \emph{predicates} via logic connectives (e.g. operators such as $\wedge$, $\vee$, $\rightarrow$, $\leftrightarrow$, $\lnot$, etc.).
 %, i.e.:
% \[ \mathit{Head} \impliedBy \mathit{Body_1},\ ...,\ \mathit{Body_n} \]%,
% where both $\mathit{Head}$ and $\mathit{Body_i}$ are \emph{atomic} formul\ae{}, and the whole sentence is read declaratively as logical implication (right-to-left).
% %
% If $n = 0$, the clause is called \emph{fact}, \emph{rule} otherwise.
% %
% An atomic formula is an expression in the form $P(t_1,...,t_m)$ where $P$ is a $m$-ary predicate ($m \geq 0$), and $t_j$ are \emph{terms}.
% %
% Terms are the most general sort of data structure in LP languages.
% %
% They can be \emph{constant} (either \emph{numbers} or \emph{atoms}/strings), \emph{variables}, or recursive elements named \emph{structures}.
% %
% Structures are used to represent clauses, lists, sets, or other sorts of expressions.
%
There, predicates represent statements describing or relating one or more entities about the domain at hand.

Depending on the particular logic of choice, predicates -- and therefore clauses -- may, carry \emph{variables}, i.e. placeholders for unknown entities, and possibly quantifiers for those variables ($\exists$ or $\forall$).
%
Some logics may also endow clauses with further information, such as for instance \emph{probabilities} -- describing the degree of likelihood for a clause to hold true --, or \emph{modalities}---describing the context in which a clause may hold (e.g. \emph{when}).
%
In any case, logic information is represented in such a way that both human and computational agents can interpret and manipulate it, in principle.

One powerful trait of logics is that they enable the representation of complex, intricate, or infinite domains \emph{intensively} (i.e. implicitly) rather than explicitly---e.g. via multiple recursive clauses.
%
So, if a domain involves an infinite amount of entites, these do not necessarily require an infinite amount of memory to be represented.
%
For instance, the set of natural integers can be represented in logic using just two FOL clauses---of which, one is recursive.

Software agents devoted to automated reasoning via LP are commonly referred to as logic \emph{solvers}.
%
They rely on pre-existing KB to derive inferences via some inference procedure and resolution strategy.
%
They may do so either \emph{reactively}, -- i.e. in response to some external stimulus, e.g. some user's \emph{query} --, or \emph{pro-actively}---i.e. spontaneously, in order to reach some goal, e.g. computing the optimal path before moving.
%
Prolog-based solvers \cite{ColmerauerR93,colmerauer1986-theoreticalProlog}, for instance, exploit a \emph{deductive} procedure rooted into the SLDNF resolution principle \cite{Kowalski1974, Clark77}, and a depth-first strategy.
%
They commonly do so in response to users' queries, provided via a textual interface.
%
Yet, a number of Prolog solvers exists supporting the same inference procedure via different strategies (e.g. tabled-resolution\missingref) or as well as entirely different principles (e.g. Constraint Logic Programming).
%
Of course, other options exist targetting other logics as well, like, e.g., abductive \cite{FungIff97}, inductive \cite{Muggleton94}, probabilistic \cite{RaedtK15} inference.
%
Each of them represents a particular reification of a logic solver.

\paragraph{Limits of CL}

Despite the many possibilities, however, there are a number of issues which are not tied to any particular choice of logic, inference procedure, or resolution strategy, but they are rather inherent to CL itself.
%
Such issues involve
%
\begin{inlinelist}
    \item decidability,
    \item tractability,
    \item knowledge acquisition, and
    \item symbols grounding.
\end{inlinelist}

Decidability and tractability deal with the theoretical questions: ``can a logic solver provide an answer to any logic query it receives? can it do so in reasonable time?''.
%
Such aspects are deeply entangled with the particular logic the solver is leveraging upon.
%
Depending on which and how many features a logic includes, it may be more or less \emph{expressive}.
%
The higher the expressiveness, the more the complexity of the problems which may be represented via logic and processed via inference increases.
%
This opens to the possibility, for the solver, to meet queries which cannot be answered in useful time, or relying upon a limited amount of memory, or at all.
%
Roughly speaking, more expressive logic languages make it easier for human beings to describe a particular domain -- usually, requiring them to write less and more concise clauses --, at the expense of an higher difficulty for software agents to draw inferences autonomously---because of computational \emph{tractability}.
%
This is a well-understood phenomenon in both CS and CL \cite{LevesqueB87, BrachmanL2004}, often referred to as the \emph{expressiveness--tractability} trade-off.
%
In practice, however, a good trade-off is represented by FOL and its subsets (e.g. Horn logic\missingref), or modal variants (e.g. linear temporal logic\missingref).
%
Despite consisting of Turing-equivalent formalisms -- for which the existence of undecidable or intractable situations cannot be excluded in the general case --, they come with sufficiently wide representational capabilities and effective inference procedures, making them exploitable in practice---provided that human developers avoid writing undecidable/intractable algorithms.

% A common mechanisms in LP is the \emph{unification} algorithm \cite{MartelliMontanari1982} for constructing a \emph{most general unifier} (MGU) for any two suitable terms.
% %
% Provided that an MGU exists, its subsequent \emph{application} to the terms, makes them syntactically equal.
% %
% This is a basic brick in virtually all LP algorithms, regardless of the particular inference rule.

% Summarising, LP leverages several mechanisms -- terms and clauses representation, knowledge base storage, unification, resolution, etc. --, which constitute the basis of any logic solver.
% %
% Subsets of these mechanisms may be useful \textit{per se}.

Knowledge acquisition deals with the question ``where does the knowledge solvers reason upon come from'', or alternatively: ``who is in charge of constructing knowledge bases''?
%
Recalling that logic clauses may become arbitrarily complex and represent possibly infinite domains in a very concise way, it is unsurprising that the burden of knowledge production is mostly on humans.
%
Unfortunately, this implies the degree of automatism in knowledge production is pretty low, as well as the scalability of the approach.
%
Many attempts have been performed over the years to distil human knowledge into symbolic form to formalise common-sense for software agents.
%
To date, there exist a number of common-sense knowledge bases and ontologies, supporting practical textual-reasoning tasks on real-world documents including analogy-making, and other context oriented inferences---see for instance \missingref[lieberman2004, trinh2018, liu2004conceptnet, liu2002goose, shapiro1999sneps from information-2020]).
%
Yet, most of these solutions are either semi-automatically constructed, or community driven -- when not both --, therefore exhaustiveness, consistency, or coherence may be lacking.
%
There have also been a number of attempts to construct very large knowledge bases of commonsense knowledge by hand, one of the largest being the CYC program by Douglas Lenat at CyCorp \missingref[lenat1995-cyc from information-2020]---which is, however, only usable behind payment.

Finally, symbols grounding deals with the problem of letting software agents provide semantics for the symbols they manipulate.
%
Put it simply, we may tell a logic solver that Abraham is the father of Isaac -- $father(\functor{isaac}, \functor{abraham})$ --, and also that, for all possible $X$ and $Y$, if $X$ is the father of $Y$, then $Y$ must be the child of $X$ -- $father(X, Y) \rightarrow child(Y, X)$ --, and the solver may also be able to infer that Isaac is thus the child of Abraham, while still having no idea of how to recognise Isaac, Abraham, nor the fatherhood relation, were it written in another form.
%
In other words, the bindings between the symbols processed by software agents and the corresponding entities from the real world are hard to establish and maintain for a bare logic solver---unless other mechanisms are in place.
%
This issue will hardly be solved within the symbolic world alone, as it is deeply entangled with the problem of letting a software agent perceive the external world via sensors, and recognising the objects therein contained.
%
The latter problem is inherently sub-symbolic as it requires acquiring, processing, and fusing raw data coming from the sensors.

\section{Data Science}
%
\mypapers[section]{xailp-woa2019,xaisurvey-ia14,agentbasedxai-extraamas2020}

Data science (DS) is a relatively young discipline laying at the intersection among AI, Statistics, CS and SE.
%
It essentially deals with the extraction of relevant information out of data, and, in particular, with the \emph{data-driven} creation of \emph{predictive} models of real world phenomena.
%
Thanks to its focus on predictive models, DS is applied to virtually all statistical sciences, ranging from physics to law, stepping through biology, healthcare, or finance.
%
In all such scenarios, the reliance on real-world data is quintessential to tune such predictive models in such a way to make them adhere to reality.

Data science can be described w.r.t. two major perspectives, here referred to as the \emph{scientific} and the \emph{engineering} perspectives on DS.
%
The scientific perspective focuses on the central aspect of DS -- namely, data -- and on \emph{what} algorithms, workflows, and practices can be exploited to process data to serve specific analytic purposes, in a sound way.
%
The engineering perspective focuses on \emph{how} to make such processing efficient and effective, in spite of the large volumes, and the wide variety of data required to this purpose.
%
Within this scope, another relevant concern is the velocity at which data is produced, and processed information is consumed.

\paragraph{The Scientific Perspective}

As a science, DS studies the many means one can exploit to % whenever in need to
%
\begin{inlinelist}
    \item let a software agent learn new behaviours from examples, which would otherwise be hard to encode for human developers (e.g. handwritten text recognition),
    \item automatically recognise patterns of similar objects given a number of examples (e.g. face detection),
    \item detect recurrent patterns in data, even in lack of prior examples (e.g. customer profiling),
    \item predict the future evolution of a phenomenon given its historical data (e.g. stock performance predictor),
    \item simulate the dynamics of complex phenomena (e.g. weather forecasting),
    \item figure out the mathematical relation biding two or more variables, from a number of samples (e.g. studying estate market prices),
    \item fuse data coming from different sources to infer unobservable measures (e.g. indoor localization), etc.
\end{inlinelist}
%
other than, of course the theories and practices to assess and increase the predictive performance of all such models.
%
In doing so, DS borrows countless algorithms, methods, and techniques from disparate fields, including but not limited to machine learning (there including supervised, unsupervised, and reinforcement learning), data mining, Bayesian inference, statistics, etc.

Despite the plethora of algorithms and methods which lay nowadays under the DS umbrella, a concise overview of the discipline can be outlined in terms of \emph{tasks}.
%
Several algorithms can be used in DS to perform a well-established pool of data-analytics tasks having a clear knowledge-related goal.
%
Most common tasks in DS are for instance:
%
\begin{description}
    \item[function fitting] (a.k.a. classification or regression) | i.e. the \emph{supervised} learning task of inferring the input-output relation among a number samples, to be later able to estimate likely outputs for novel, unseen inputs;
    \item[clustering] | i.e. the \emph{unsupervised} learning task of finding similar groups of instances in a dataset -- according to a given notion of \emph{similarity} or distance --, to be later able to classify novel instances according to some group;
    \item[anomaly detection] | i.e. the \emph{unsupervised} learning task of tuning an algorithm to discern ``normal'' situations from exceptional ones, provided that some historical data is available, to later be able to detect the latter;
    \item[filtering] (resp. \textbf{smoothing} or \textbf{forecasting}) | i.e. the Bayesian task of estimating the unknown \emph{current} (resp. \emph{past} or \emph{future}) state of a system given a sample of observations capturing the evolution of a number of variables which should depend of that state;
    \item[most likely explanation] | like the above, but focussing on the most likely \emph{sequence} of states a system has traversed.
\end{description}
%
Most of these tasks may be implemented in several ways and by several algorithms.
%
For instance, function fitting alone may be realised using neural networks, (generalised) linear models, support vector machines, decision trees, and many others.
%
Notably, the same algorithm could be used to implement several tasks---e.g. neural networks can be exploited to perform both classification and regression tasks, as well as anomaly detection.

For all such tasks, two major phases are commonly identified in DS, namely \emph{training} (a.k.a. learning, or fitting) and \emph{usage} (a.k.a. inference).
%
The first phase (training) commonly occurs behind the scenes, and it is led by \emph{data scientists} -- i.e. human beings --, despite involving semi-automated workflows.
%
The second phase (usage) is commonly what AI consumers use and deal with.
%
During training, the most adequate algorithm is selected for the data and the task at hand, and it is then trained on data, producing a predictive \emph{model} which, hopefully, is predictive enough to be later used on novel data.
%
Users may then exploit the model by feeding it with novel data, to draw predictions.
%
Predictions, in turn, may be presented to the users as recommendations, decisions, or outcomes.

Notably, regardless of their technical details, all the data-analytics tasks above may leverage on a number of lower-level ancillary activities which are orthogonal w.r.t. the choice of the particular implementing algorithm, as they involve routine operations, assessment procedures, or best practices which are commonly executed either before or after the data-analytics task itself.
%
Examples of such kinds of activities are, for instance:
%
\begin{description}
    \item[feature engineering] | i.e. a whole class of pre-processing techniques -- such normalising numeric data into predefined intervals, changing the way data is encoded, or creating new data from the available one -- which may be used to improve or transform the available data, in order to improve the performance of the data analytics task;
    \item[dimensionality reduction] | i.e. a whole class of data manipulation techniques aimed at selecting the most relevant attributes of data for a given data-analytics task (before running the task)---such as principal component analysis;
    \item[model assessment] i.e. a whole class of statistical methods, algorithms, and practices to assess the performance of the data-analytic task in a principle way---such as for instance supervised learning metrics (e.g. accuracy, or mean-squared error) or procedures such as cross-validation or test set separation;
    \item[model selection] i.e. a number of strategies, approaches, and practices to let data scientists select the best predictive model when multiple options fit the data and the situation at hand---e.g. by leveraging on \emph{cross-validation}, possibly in combination with a grid search strategy to identify the most adequate type of predictor.
\end{description}
%
% Despite being really important for the practice of data science, such aspects are quite marginal within the scope of this thesis.
%
% Accordingly, in the following chapters we focus data-analytics tasks, and in particular supervised learning ones.

\paragraph{The Engineering Perspective}

As a field of engineering, DS deals with the design and implementation of robust software and hardware architectures, which support the \emph{scalable} execution of the aforementioned data-analytic tasks over the so-called \emph{big data}.
%
For this reason, the engineering perspective of DS is also known as the field of \emph{big data processing}.

The exploitation of parallel or distributed solutions to speed up the data processing workflows is the most relevant object of study under the engineering perspective of DS.
%
Along this line, there are two broad sorts of situations which is worth mentioning, namely: \emph{on-line} or \emph{off-line} data processing.
%
They correspond to as many major approaches to big data processing, namely \emph{stream} processing and \emph{parallel}/\emph{distributed} computing.

On-line data processing deals with the need of processing data as soon as it is produced, without any intermediate accumulation phase.
%
The outcomes of on-line data processing must be consumed in useful time---hence the need to process it quickly, on the fly.
%
Along this line, the notion of data \emph{stream} -- that is, a possibly \emph{unlimited} sequence of data to be \emph{lazily} and reactively processed -- is fundamental as it supports the processing of large amounts of data without requiring them to be simultaneously stored in memory---therefore enabling great scalability.

Off-line data processing deals with the need of analysing data statistically, therefore requiring as much data as possible.
%
A data accumulation phase is commonly the underlying implicit assumption for off-line data processing.
%
Accordingly, the focus here is on speeding up -- through parallelisation -- the data processing workflows which would otherwise require too much computational time or power.
%
There, parallelisation may occur on either on multiple cores of the same machine, or multiple \emph{distributed} machines.

\chapter{Representing Data and Knowledge}

% \note{General introduction on KR as the lingua franca among humans and machines}
Representation deals with the expression of information to make it understandable and manipulable by agents---be they computational or humans.
%
From a philosophical perspective, there are two major premises to any well-funded discussion on representation.

First, both computational and human agents operate (i.e. compute or think) upon \emph{representations} of relevant aspects of the reality---and representations are everything an agent may ever hope to manipulate.
%
\emph{Noumena} -- i.e. what things actually are -- are not accessible directly, but rather via \emph{perception}.
%
Perception implies consuming some input data, which must in turn be represented, to enable further processing.
%
So, agents always deal with \emph{phenomena} -- i.e. how things appear --, hoping that the corresponding \emph{noumena} are reflected with sufficient precision.
%
(Of course, to reach a true understanding about a particular noumenon, several related phenomena should be observed, but this particular aspect is addressed in the following chapters.)
%
% In other words, whenever an agent is dealing with some information, it is actually dealing with a particular representation of some underlying concept which can only be grasped by its observable properties.

Second, representations are manifold and of different sorts, and they may focus on particular aspects of the phenomenon being represented.
%
In other words, whenever an agent is dealing with some information, it is actually dealing with a particular representation of some underlying concept, despite many others could be available.
%
Furthermore, representations are never good or bad per se, but rather more or less adequate to the agent exploiting them and to the task it is performing.
%
So, by whom information must be consumed, and to serve what purpose, is a relevant concern in deciding which representations are more adequate.


% Representations are subtle because they focus on a particular aspect of the information being represented.
%

Despite being rooted into deep and long-standing philosophical discussions, such premises are here reported serving a practical purpose.
%
Indeed, they synthesise the underlying mindset tying this chapter and the following ones together: the particular choice of a particular means to representation simultaneously enables and constrains the kinds of possible processing information may be subject to---and this in turns conditions any subsequent design choice.

Accordingly, within the scope of this chapter we discuss the representation of particular sorts of information, namely either \emph{data} or \emph{knowledge}.
%
We consider as data any \emph{raw} information attained by \emph{sampling} some phenomenon or situation from reality.
%
Data by itself simply describes the phenomenon / situation, yet it is hard to exploit and transfer directly, because of its granularity and volume.
%
Conversely, we consider as knowledge any coarse-grained piece of information describing entire classes of phenomena or situations, in a concise and reusable (i.e. predictive) way.
%
Differently from data, knowledge can be applied to unseen phenomena or situations, or transferred to agents which have not experienced any such phenomena / situations explicitly.

Be it devoted to data or knowledge, each representation comes with pros and cons, simplifying the expression of some aspects of the information being represented, while complicating the expression of others.
%
Indeed, a lot of effort in DS is devoted to the engineering of the best representation for the data at hand, to maximise the effectiveness of any subsequent data-processing task.

The means to represent data and knowledge are manifold and too many to count.
%
However, at the meta-level, we can categorise representations means as either \emph{symbolic} or \emph{sub-symbolic}.
%
While the two means are essentially interchangeable -- other than mutually convertible -- when they represent data, they lead to profoundly different ways of representing knowledge.
%
Indeed, while symbolic knowledge is both machine- and human-interpretable, sub-symbolic is mostly machine-interpretable, and is therefore treated by human beings as a black box in the general case.

Along this line, in the reminder of this chapter we focus on logic -- as the most prominent approach to \emph{symbolic} representation --, and vectors, matrices, or tensors of real numbers---as the most prominent approach to \emph{sub-symbolic} representation.
%
We show analogies and differences among such approaches to representation, eliciting the pros and cons of both, and, in particular, their differences among the interpretability perspective.

\section{Symbolic Knowledge Representation}

(Symbolic) Knowledge representation (KR) has always been regarded as a key issue since the early days of AI, as no intelligence can exist without knowledge, and no computation can occur in lack of representation.

Here we discuss the language of FOL as a means for representing symbolic information.
%
We choose FOL as it is quite general, and the other approaches can be described by either constraining or loosening the definition of FOL.

\subsection{First Order Logic (FOL)}

\begin{table}
    $$\begin{array}{rcl}
        \meta{Formula} & := & \meta{Clause} \mid \meta{Quantifier} \meta{Formula}
        \\
        \meta{Quantifier} & := & \terminal{\forall} \meta{Variable} \mid \terminal{\exists} \meta{Variable}
        \\
        \meta{Clause} & := & \meta{Literal} \mid \terminal{(} \meta{Formula} \meta{Connective} \meta{Formula} \terminal{)}
        \\
        \meta{Connective} & := & \terminal{\wedge} \mid \terminal{\vee} \mid \terminal{\rightarrow} \mid \terminal{\leftrightarrow} \mid \terminal{=}
        \\
        \meta{Literal}  & := & \meta{Predicate} \mid \terminal{\lnot} \meta{Predicate}
        \\
        \meta{Predicate} & := & \terminal{\top} \mid \terminal{\bot} \mid \meta{Predication} \mid \meta{Predication} \terminal{(} \meta{Arguments} \terminal{)}
        \\
        \meta{Predication} & := & p_1 \mid p_2 \mid p_3 \mid \ldots
        \\
        \meta{Arguments} & := & \meta{Term} \mid \meta{Term} \terminal{,} \meta{Arguments}
        \\
        \meta{Term} & := & \meta{Variable} \mid \meta{Structure} \mid \meta{Constant}
        \\
        \meta{Variable} & := & X_1 \mid X_2 \mid X_3 \mid \ldots
        \\
        \meta{Structure} & := & \meta{Functor} \terminal{(} \meta{Arguments} \terminal{)}
        \\
        \meta{Functor} & := & \functor{f}_1 \mid \functor{f}_2 \mid \functor{f}_3 \mid \ldots
        \\
        \meta{Constant} & := & \meta{Functor} \mid \meta{Number}\mid \meta{Boolean}
        \\
        \meta{Number} & := & \mathbb{R}
    \end{array}$$
    \caption[Context-free grammar for FOL]{Context-free grammar for FOL. Sans-serif words among angular brackets denote non-terminal symbols, whereas symbols among single apices denote terminal symbols.}
    \label{tab:fol-grammar}
\end{table}

First order logic (FOL) \cite{Smullyan1968} is a general-purpose logic which can be used to represent knowledge symbolically, in a very flexible way.
%
More precisely, it allows both human and computational agents to express (i.e. write) the properties of -- and the relations among -- a set of entities constituting the \emph{domain of the discourse}, via one or more \emph{formul\ae}---and, possibly, to reason over such formul\ae{} by drawing inferences.

In \cref{tab:fol-grammar} the syntax of FOL is formally defined via a context-free grammar.
%
Informally, the syntax for the general FOL formula is defined over the assumption that there exist:
%
\begin{itemize}
    \item a number of constant symbols, including: a number of \emph{functors}, denoted by monospaced symbols such as $\functor{f}_1, \functor{f}_2, \ldots$, and all real numbers;

    \item a number of \emph{predicate symbols} (a.k.a. predications), denoted by italic symbols starting with a lower case letter, such as $p_1, p_2, \ldots$;

    \item a number of \emph{variables}, denoted by italic symbols starting with a capital letter, such as $X_1, X_2, \ldots$.
\end{itemize}
%
Under such assumption a FOL formula is any expression composed by a list of quantified variables, followed by a number of \emph{literals}, i.e. \emph{predicates} which may or may not be prefixed by the negation operator ($\lnot$)---in which case would be called negated.
%
Each predicate consists of a predicate symbol, possibly applied to one or more \emph{terms}.
%
More precisely, each predicate may carry $N \geq 0$ terms.
%
When this is the case, the predicate is said $N$-ary (meaning that its arity, or amount of arguments, is $N$).
%
Terms may be of three sorts, namely \emph{constants}, \emph{structures}, or \emph{variables}.
%
Constants represent the many entities from the domain of the discourse.
%
In particular, each constant references a different entity.
%
Structures are combinations of one or more entities via one \emph{functor}.
%
Similarly to predicates, structures may carry $M \geq 0$ terms.
%
When this is the case, the structure is said $M$-ary as well.
%
Being containers of terms, structures enable the creation of arbitrarily complex data structures combining several entities from the domain of the discourse, and treating them as a whole.
%
Finally, variables are placeholders for unknown terms---i.e. for entities or groups of entities.

Predicates and terms are very flexible tools to represent knowledge.
%
While terms can be used to represent or reference either entities or groups of entities from the domain of the discourse, predicates can be used to represent relations among those entities, or the properties of each single entity.
%
There, the domain of the discourse $\mathbb{D}$ \cite{blackburn2008oxford} is the set of all relevant entities which should be represented in FOL to amenable of formal treatment, in a particular scenario.
%
Should we use FOL to treat arithmetic, $\mathbb{D}$ would include the set of \emph{natural} numbers---i.e. a symbol for each natural number.
%
Should we treat calculus, $\mathbb{D}$ would include the set of \emph{real} numbers.
%
Should we treat kinship relationships, $\mathbb{D}$ would include a symbol for each person taken into account.

Concerning predicates, let us denote by $p/N$ the $N$-ary predicate whose predicate symbol is $p$ and whose arity is $N$.
%
% Let us also assume that the $N$ arguments of the predicate are entities drawn from the sets of entities $\mathcal{D}_1, \ldots, \mathcal{D}_N$, where $\mathcal{D}_i \subseteq \mathbb{D}$, for all $i = 1, \ldots, N.$
%
When $N \geq 2$, the predicate represents one or more items from the relation $p \subseteq \mathbb{D} \times \ldots \times \mathbb{D}$.
%
So, for instance, the expression $p(t_1, \ldots, t_N)$, where all $t_i$ are non-variable terms, denotes that the $N$-uple $(t_1, \ldots, t_N)$ is part of the $N$-ary relation subtended by $p$---or that, in other words, the relation $N$-ary relation $p$ ties the entities $t_1, \ldots, t_N$ together.
%
Similarly, the expression $\forall X_i\ p(t_1, \ldots, X_i, \ldots, t_N)$, where $X_i$ is a variable, denotes a situation where, for each entity $X_i$ in $\mathbb{D}$, the relation $N$-ary relation $p$ ties the entities $t_1, \ldots, X_i, \ldots, t_N$ together.
%
Dually, the expression $\exists X_i\ p(t_1, \ldots, X_i, \ldots, t_N)$ denotes an item of the $N$-ary relation $p$ whose $i^{th}$ item is unknown, or, in other words, an item where the first argument is $t_1$, the second argument is $t_2$, \ldots, and the last argument is $t_N$, while the $i^{th}$ argument is arbitrary.
%
Conversely, when $N = 1$, the predicate represents one or more items from the set $p \subseteq \mathbb{D}$.
%
So, for instance, the expression $p(t)$, where $t$ is a non-variable term, denotes a situation where $t$ is an item of the set subtended by $p$---or that, in other words, the property $p$ holds for the entity $t$.
%
Similarly, the expression $\forall X\ p(X)$, denotes a situation where all items in $\mathbb{D}$ are items of the set $p$ as well---or that, in other words, the property $p$ holds for all entities in $\mathbb{D}$.
%
Dually, the expression $\exists X\ p(X)$, denotes a situation where some item in $\mathbb{D}$ is in $p$ as well.
%
Finally, when $N = 0$, the predicate $p$ represents a Boolean proposition which may or may not be true.
%
Notably, the predicate $\top$ is always true, by construction, whereas the predicate $\bot$ is always false.

Concerning non-variable terms, let us denote by $\functor{f}/M$ the $M$-ary term whose functor is $\functor{f}$ and whose arity is $M$.
%
When $M \geq 0$, the term is a constant and it represents some entity from $\mathbb{D}$.
%
When $M \geq 1$, the term is a structure -- i.e. a named and ordered group of terms -- and it represents a complex or composite entity from $\mathbb{D}$.
%
The actual interpretation of a structure really depends on the scenario at hand.
%
So, for instance, in the arithmetic domain, it is possible to represent natural numbers by mimicking the Peano axioms\footnotemark{} via a unary structure -- e.g. $\functor{s}$, for \emph{successor} -- and a constant -- e.g. $\functor{z}$, for \emph{zero} -- as follows:
$\functor{z}$ represents $0$,
$\functor{s}(\functor{z})$ represents $1$,
$\functor{s}(\functor{s}(\functor{z}))$ represents $2$, etc.
%
Under this representation, each natural number (except $\functor{z}$) is composed by its predecessor, and the successor functor $\functor{s}/1$.

\footnotetext{\url{https://www.britannica.com/science/Peano-axioms}}

\paragraph{Structures as composite entities}

Structures may be used in logic to represent composite entities.
%
Such composite entities may either be of fixed size or of variable size.

A fixed-size composite entity made up of $M$ sub-entities may be represented in FOL via a $M$-ary structure.
%
For instance, one may represent a person in terms of first name, last name, and birthdate.
%
In that case $M = 3$, and an adequate functor is `$\functor{person}$':
%
$$
\functor{person}(\functor{adam},\ \functor{smith},\ \functor{date}(1723,\ \functor{june},\ 5))
$$
%
The underlying assumption here is that dates are represented as ternary structures as well.

A variable-size composite entity, in turn, may be made up of an unknown amount of sub-entities.
%
Furthermore, two different composite entities of the same sort may be of different sizes.
%
Consider for instances two different journeys on a map: one may involve 3 cities, and the other may involve 4 cities, yet both can be represented by \emph{lists} of cities to be visited in a row.

Lists -- and, more generally, data structures -- can be represented in FOL via ad-hoc fixed-size structures, to be used recursively.
%
In particular, a common convention is to represent \emph{singly linked} lists of entities using:
%
\begin{itemize}
    \item a binary structure, denoting element--successor couples, e.g. $\functor{cons}/2$ or $\functor{.}/2$,
    \item a constant, denoting the termination of the list, e.g. $\functor{nil}$ or $\functor{[]}$.
\end{itemize}
%
So, for instance, a journey from Rome to Milan, stepping through Florence and Bologna may be represented as follows:
%
\begin{equation}\label{eq:path-rome-milan}
    \functor{cons}(\functor{rome},\
        \functor{cons}(\functor{florence},\
            \functor{cons}(\functor{bologna},\
                \functor{cons}(\functor{milan},\
                    \functor{nil}
                )
            )
        )
    )
\end{equation}
%
whereas a journey from Rome to Naples would be as simple as:
%
\begin{equation*}
    \functor{cons}(\functor{rome},\
        \functor{cons}(\functor{naples},\
            \functor{nil}
        )
    )
\end{equation*}
%
In both cases, cities are represented by constants, whereas lists of cities are attained by combining cities into data structures---i.e. by \emph{recursively} wrapping cities via the $\functor{cons}/2$ functor, and by exploiting the constant $\functor{nil}$ to conclude the list.

It is worth to be mentioned that, a more practical and common notation involves the exploitation of $\functor{.}/2$ and $\functor{[]}$ instead of $\functor{cons}/2$ and $\functor{nil}$, respectively, where $\functor{.}/2$ is usually written as an \emph{infix} symbol.
%
With this notation, the path from \cref{eq:path-rome-milan}, could be written as:
%
\begin{equation*}
    \functor{rome \consdot florence \consdot bologna \consdot milan \consdot []}
\end{equation*}
%
or, equivalently:
%
\begin{equation*}
    \functor{[rome,\ florence,\ bologna,\ milan]}
\end{equation*}

\paragraph{Knowledge Bases}

From a knowledge representation perspective, knowledge bases (KB) (a.k.a. \emph{theories}) are sets of related FOL formul\ae{} concerning the same domain of the discourse.
%
We denote theories as lists of dot-terminated formul\ae.

For instance, a simple KB describing natural numbers may be defined as follows:
%
\begin{equation}\label{eq:kb-peano-naturals}
    \begin{array}{c}
        natural(\functor{z}).
        \\
        \forall X\ natural(X) \rightarrow natural(\functor{s}(X)).
    \end{array}
\end{equation}
%
There, the KB is composed by two formul\ae, and it aims to define the set of natural numbers by means of the unary predicate $natural/1$, the unary structure $\functor{s}/1$, and the constant $\functor{z}$.
%
More precisely, the first formula states that the constant $\functor{z}$ is included into the set of natural numbers, by construction, whereas the second one states that, whenever some object $X$ is in the set of natural numbers, then object $\functor{s}(X)$ is in the same set as well.
%
By recursively applying that formula, one may express any natural number in Peano notation.

\paragraph{Intensional vs. Extensional}

The recursive definition of natural numbers from \cref{eq:kb-peano-naturals} is also interesting because it exemplifies the difference among \emph{extensional} and \emph{intensional} definitions.

In logic, one may define concepts -- i.e. describe data -- either extensionally or intensionally.
%
Extensional definitions are \emph{direct} representation of data.
%
In the particular case of FOL, this implies defining a relation or set by explicitly mentioning the entities it involves.
%
The $natural(\functor{z})$ formula from \cref{eq:kb-peano-naturals} is a particular case of \emph{extensional} definition of the symbol $\functor{z}$ as a natural number.
%
In other words, it partially defines the $natural$ set by specifying some of its items.
%
Conversely, intensional definitions are \emph{indirect} representations of data.
%
In the particular case of FOL, this implies defining a relation or set by describing its elements via other relations or sets.
%
The $X\ natural(X) \rightarrow natural(\functor{s}(X))$ formula from \cref{eq:kb-peano-naturals} is a particular case of \emph{intensional} definition of the any symbol of the form $\functor{s}(X)$ as a natural number, provided that $X$ is a natural number as well.

Notice that the focus here is \emph{not} on recursion.
%
Intentional definitions must not necessarily be recursive.
%
For instance, one may intensionally define the $child/2$ relation via the $parent/2$ relation as follows:
%
\begin{equation*}
    \forall X ~ \forall Y\ parent(X, Y) \rightarrow child(Y, X).
\end{equation*}
%
Yet, recursive intensional predicates are very expressive and powerful, as they enable the description of infinite sets via a finite (and commonly small) amount of formul\ae{}.

\paragraph{Herbrand and its ground}\label{par:herbrand}

Variables play a fundamental role in intensional KR, as they allow referencing unknown entities and tie them together via either predicates or structures.
%
However, there exists situations -- described later in this thesis -- where the presence of variables may be troublesome.
%
Accordingly, here we provide a number of definitions related to variable-free FOL formul\ae{} and KB.

A term is considered \emph{ground} if and only if
%
\begin{inlinelist}
    \item it is a constant, or
    \item it is a structure ant it is only composed by constant or ground arguments.
\end{inlinelist}
%
In other words, a term if it contains no variable, not even recursively.
%
A predicate is ground it any term therein contained is ground as well.
%
A formula is ground if it only contains ground predicates, and a KB is ground if it only contains ground formul\ae{}.

We call \emph{Herbrand universe} the set of all possible ground terms, denoted by $\mathcal{H}$.
%
In other words, $\mathcal{H}$ is the set of all possible representations of all entities in the domain of the discourse.
%
Given a set of constants and functor symbols, $\mathcal{H}$ can be recursively defined as the set containing:
%
\begin{inlinelist}
    \item all possible constants, and
    \item all structures attained by applying all possible $M$-ary functors to each possible $M$-uple of items in $\mathcal{H}$.
\end{inlinelist}

The Herbrand universe may easily become infinite.
%
A single functor of arity greater than 0 -- say, $\functor{f}$ -- plus a single constant -- say, $\functor{x}$ -- are sufficient to create an infinite Herbrand universe, as the functor may be recursively applied to the constant, infinitely many times---i.e. $\mathcal{H} = \{ \functor{x}, \functor{f}(\functor{x}), \functor{f}(\functor{f}(\functor{x})), \ldots \}$.

\subsection{Representation Engineering}

When handling knowledge in practice, the particular way knowledge is modelled is quintessential for computational systems to be effective.
%
Of course, any particular modelling is better suited to support some sorts of algorithms while it may make the exploitation of other algorithms cumbersome.
%
In other words, the particular shape of predicates and structures may be chosen in manifold ways, depending on the nature of the data at hand, and on the computations that designers are expecting for that data.

Here we briefly examinate the two extremes in a spectrum of possibilities, with the purpose of discussing how each choice in KR may come with both pros and cons---which must therefore be engineered.

We rely on two running examples, namely the ``ties of kinship'' example -- mimicking a simple scenario where the ties of kinship among a number of people must be represented --, and the ``Iris'' example, where data about a number of Iris flowers are collected.
%
For both of them, we discuss possibilities in KR strategies.

\paragraph{Representing relational data}

We here consider a simple scenario where the ties of kinship among a number of people must be represented via FOL.
%
We take Abraham's family tree from the Genesis as an example.

A natural way to represent a family tree is by using constants to represent people, while extensively representing a minimal pool of relations, and intensively representing any other relation---in both cases, via predicates.
%
For instance, we may choose to extensively represent parenthood relations among couples of people, other than the gender of each person.
%
Other kinds of relations could be represented intensively.
%
For example:
%
\begin{equation}\label{eq:abraham-family-tree}
    \begin{array}{rcl}
        parent(\functor{abraham}, \functor{isaac}). & {} & male(\functor{abraham}).
        \\
        parent(\functor{sarah}, \functor{isaac}). & {} & female(\functor{sarah}).
        \\
        parent(\functor{isaac}, \functor{jacob}). & {} & male(\functor{isaac}).
        \\
        parent(\functor{rebekah}, \functor{jacob}). & {} & female(\functor{rebekah}).
        \\
        \ldots & {} & male(\functor{jacob}).
        \\
        \forall X ~ \forall Y\ parent(X, Y) & \rightarrow & child(Y, X).
        \\
        \forall X ~ \forall Y\ parent(X, Y) \wedge male(X) & \rightarrow & father(X, Y).
        \\
        \forall X ~ \forall Y\ parent(X, Y) \wedge female(X) & \rightarrow & mother(X, Y).
        \\
        \forall X ~ \forall Y ~ \exists Z \ parent(X, Z) \wedge parent(Z, Y) & \rightarrow & grandparent(X, Y).
    \end{array}
\end{equation}

This approach to KR is particularly adequate to describe situations involving several entities and many relations or properties, but where, however, each predicate only spans through a few entities, and most entities are not involved in all relations or properties.
%
In other words, this approach is well suited to represent \emph{heterogeneous} data.

\paragraph{Representing propositional data}\label{sec:kr-tabular-data}

We here consider a simple scenario where the well-known Iris dataset\footnote{\url{https://archive.ics.uci.edu/ml/datasets/iris}} is represented via FOL.
%
Notably, the Iris dataset is a collection of 150 individuals of the Iris flower.
%
For each exemplary, 4 numeric input features -- petal and sepal width and length -- are recorded, other than a class label---i.e. which particular sort of Iris plant the exemplary has been classified as.
%
There are three particular sub-sorts of Iris in this data set -- namely, Iris-Setosa, -Virginica, and -Versicolor --, and the 150 examples are evenly distributed among them---i.e. there are 50 instances for each class.

The Iris dataset essentially consists of a bi-dimensional $150 \times 5$ table, where each row corresponds to an exemplary, each column corresponds to a relevant \emph{feature}, and each cell carries the value of a particular feature for a particular exemplary.
%
A natural way to represent $N$ -- e.g. 150 -- records of equals size $M$ -- e.g. 5 -- is by leveraging on $N$ predicates, all having the same arity $M$, and the same functor---e.g. $iris$.
%
There, each predicate \emph{extensionally} represents an instance of the same $M$-ary relation -- e.g. $iris$ --, and the $j^{th}$ argument of each predicate carries the value of the $j^{th}$ feature for that instance---according to some predefined ordering of features.
%
Thus, the values corresponding to numeric features can be represented in FOL by numeric constants, while the values corresponding to the class feature could be represented by ad-hoc constants.
%
So, a KB describing the Iris dataset in FOL according to this may look as follows:
%
\begin{equation}
    \begin{array}{c}
        iris(5.1,\ 3.5,\ 1.4,\ 0.2,\ \functor{setosa}).
        \\\vdots\\
        iris(7.0,\ 3.2,\ 4.7,\ 1.4,\ \functor{versicolor}).
        \\\vdots\\
        iris(6.3,\ 3.3,\ 6.0,\ 2.5,\ \functor{virginica}).
    \end{array}
\end{equation}
%
where the predefined ordering of features is:
%
\begin{inlinelist}
    \item sepal length,
    \item sepal width,
    \item petal length,
    \item petal width, and
    \item class.
\end{inlinelist}

This approach to KR is particularly adequate to describe situations where the same amount and sorts of fields are available for each datum, thus making the whole dataset suitably described by an $N \times M$ table---and, therefore, therefore extensively represented as an $M$-ary relation having with $N$ instances.
%
In other words, this approach is well suited to represent \emph{homogeneous} data.

\paragraph{Comparison}

Both approaches to KR come with both pros and cons, and they are, at least in principle, interchangeable---meaning that, conversions may be performed from data represented via any of the two approaches into the other.
%
Here, we simply highlight how the effectiveness of KR heavily depends on the particular computation to be performed.

There are two kinds of activities one may use as benchmarks to assess the limits of each approach to KR, namely:
%
\begin{inlinelist}
    \item\label{item:enumerate-features} enumerating all the individuals involved into a KB and all the features describing them, and
    \item\label{item:add-features} adding one new feature to the KB, updating all involved individuals accordingly.
\end{inlinelist}

On the one side, in the propositional approach, the amount of individual is equal to the amount on predicates, whereas the amount of features is equal to the arity of all predicates.
%
So enumeration of both individuals and features is straightforward.
%
Conversely, in the relational approach, individuals should be enumerated by stepping through all predicates, and removing duplicates; whereas the enumeration of all features may require a lot of computations---as the intensionally represented features should be made explicit.

On the other side, adding a new feature to a KB represented via heterogeneous approach is straightforward.
%
It just requires the novel predicates to be added to the KB.
%
Conversely, in the propositional approach, the same operation would require the \emph{whole} KB to be rewritten---to let each predicate carry one more feature.

\subsection{Relevant Subsets of FOL}\label{ssec:fol-sub-sets}

Historically, most KR formalisms and technologies have been designed around either sub-sets or applications of the \emph{first order logic} (FOL).
%
Consider for instance, \emph{deductive databases} \cite{green1968}, \emph{description logics} \cite{baader2002}, \emph{ontologies} \cite{cimiano2006-ontologies}, \emph{Horn} logic \cite{Mcnulty1977}, \emph{higher-order} logic \cite{VanBenthem2001}, just to name a few.

Many kinds of logic-based knowledge representation systems have been proposed over the years, mostly relying on FOL -- either by restricting or extending it --, e.g. on description logics and modal logics, which have been used to represent, for instance, terminological knowledge and time-dependent or subjective knowledge.

\paragraph{Ontologies and Description Logics}

Early KR formalisms, such as \emph{semantic networks} and \emph{frames} \cite{sowa2014}, mostly aimed at providing a structured representation of information.
%
For this reason, description logics are characterised by several restrictions w.r.t. to FOL
%
Applications range from reasoning with database schemas and queries \cite{artale2002} to \emph{ontology languages} such as OIL, DAML+OIL and OWL \cite{horrocks2005}---always keeping in mind that not only the key inference problems should be decidable, but also that the decision procedures should be implemented \emph{efficiently}.

Ontology-based approaches are popular because of their basic goal---a common understanding of some domain that can be shared between people and application systems.
%
At the same time, it should be understood that the general concepts and relations of a top-level ontology can rarely accommodate all of the systems peculiarities \cite{van2008,valente2005}.

A number of systems based on description logics have been developed -- e.g. \cite{cohen1994,moller2003} -- in diverse application domains, such as natural language processing, configuration of technical systems, software information systems, optimising queries to databases, planning.

\paragraph{Horn Logic}

Horn logic is a notable subset of FOL, characterised by a good trade-off among theoretical expressiveness, and practical tractability \cite{Makowsky1987}.

Horn logic is designed around the notion of \emph{Horn clause} \cite{Horn1951}.
%
Horn clauses are FOL formul\ae{} having no quantifiers, and consisting of:
%
\begin{itemize}
    \item a disjunction of predicates, where only at most one literal is non-negated:
    %
    \begin{equation*}
        \lnot b_1 \vee \ldots \vee \lnot b_n \vee h
    \end{equation*}

    \item or, equivalently (applying De Morgan rules), a disjunction among a predicate and a negated conjunction of predicates:
    %
    \begin{equation*}
        \lnot (b_1 \wedge \ldots \wedge b_n) \vee h
    \end{equation*}

    \item or, equivalently (applying the equivalence $\lnot X \vee Y \equiv X \rightarrow Y$), an implication having a single predicate as post-condition and a conjunction of predicates as pre-condition:
    %
    \begin{equation*}
        b_1 \wedge \ldots \wedge b_n \rightarrow h
    \end{equation*}

    \item often conveniently written as:
    %
    \begin{equation}\label{eq:horn-clause-form}
        h \leftarrow b_1,\ \ldots,\ b_n
    \end{equation}

\end{itemize}
%
where $\leftarrow$ denotes logic implication from right to left, commas denote logic conjunction, and all $b_i$, as well as $h$, are predicates of arbitrary arity, possibly carrying FOL terms of any sort---i.e. variables, constants, or structures.
%
By looking at \cref{eq:horn-clause-form}, it should be evident why $h$ is often called \emph{head} (of the clause), while the conjunction $(b_1, \ldots, b_n)$ is often called \emph{body} (of the clause).
%
Quantification of variables is omitted, as all variables possibly occurring in the head are assumed to be \emph{universally} quantified, whereas all other variables possibly occurring in the body (and not in the head) are assumed to be \emph{existentially} quantified.

So, essentially, Horn logic is a very restricted subset of FOL where:
%
\begin{itemize}
    \item formul\ae{} are reduced to clauses, as they can only contain predicates, conjunctions, and a single implication operator, therefore
    \item operators such as $\vee$, $\leftrightarrow$, or $\lnot$ cannot be used,
    \item variables are implicitly quantified, and
    \item terms work as in FOL (there including the definition of ``ground term'' and ``Herbrand universe'').
\end{itemize}
%
Similarly to FOL, Horn logic KB consist of sets of Horn clauses.

Despite being very restrictive in theory, the lack of basic operators such as $\vee$, $=$, or $\lnot$ can be circumvented in practice, via \emph{meta-predicates}---i.e. predicates accepting other predicates as arguments.
%
Circumvention in these cases steps through a smart trick: by letting the set of admissible functors \emph{include} the set of possible predicate symbols, one may enable the representation of predicates via terms.
%
So, a meta-predicate can be described as an ordinary predicate, accepting terms as arguments, and considering its arguments as predicates.
%
However, these aspects are covered in \cref{chap:reasoning}.

It is worth to be noted that Horn clauses can be read under both a \emph{logic} and a \emph{procedural} perspective \cite{Kowalski1976}.
%
Under a logic perspective, Horn clauses are bare implications, which can be used to define relations or sets, as in FOL.
%
Under a procedural perspective, any Horn clause states that ``to prove $h$, one should prove all $b_1$, \ldots, $b_n$ first''.
%
Along this line, when Horn clauses are exploited in practice, they are commonly referred to as
%
\begin{description}
    \item[facts] when their body consist of just the $\top$ predicate:
    $$ h \leftarrow \top \quad \text{or simply} \quad h$$
    stating that $h$ is known to be true (as it requires nothing to be proven first),

    \item[goals] (a.k.a.\textbf{directives}) when their head consist of just the $\bot$ predicate (or, equivalently, when the head is missing):
    $$
    \bot \leftarrow b_1,\ \ldots,\ b_n
    \quad
    \text{or simply}
    \quad
    \leftarrow b_1,\ \ldots,\ b_n
    $$
    stating that predicates $b_1, \ldots, b_n$ should be all proven,

    \item[rules] otherwise, i.e. when both the head and the body involve arbitrary predicates.
\end{description}
%
It is worth to be mentioned that facts are particular case of rules.
%
Indeed, both facts and rules are also known as \emph{definite} clauses.

\section{Sub-symbolic Data Representation}

Symbolic KR approaches, such as FOL and its subsets, represent both data and knowledge uniformly---meaning that they provide a common language capable of representing both.
%
The same statement does not hold for sub-symbolic approaches, which commonly represent data as (possibly multi-dimensional) \emph{arrays} (e.g. vectors, matrices, or tensors) of real numbers, and knowledge as functions over such data.

Despite numbers are technically symbols as well, we cannot consider arrays and their functions of as symbolic KR means.
%
Indeed, according to \cite{Gelder90}, to be considered as symbolic, KR approaches should:
%
\begin{inlinelist}
    \item involve a set of symbols,
    \item\label{item:combination} which can be combined (e.g. concatenated) in possibly infinite ways, following precise grammatical rules, and
    \item\label{item:meaning} where both elementary symbols and any admissible combination of them can be assigned with meaning---i.e. each symbol can be mapped into some entity from the domain of the discourse.
\end{inlinelist}
%
In this section we discuss how sub-symbolic approaches are characterised by the frequent violation of items \ref{item:combination} and \ref{item:meaning}.

\paragraph{Vectors, matrices, tensors}

Multi-dimensional arrays are the basic brick of sub-symbolic data representation.
%
More formally, a $D$-order array consists of an ordered container of real numbers, where $D$ denotes the amount of indices required to locate each single item into the array.
%
The $i^{th}$ index of the array is assumed to range through the interval $1, \ldots, d_i$, so that the whole dimension of the array -- i.e. the total amount of numbers therein contained -- is $d_1 \times \ldots \times d_D$.
%
In what follows, we may abuse the notation by referring to 1-order arrays as \emph{vectors}, 2-order array as \emph{matrices}, and higher-order arrays as \emph{tensors}.
%
Along this line, we may also denote by $\mathbb{R}^{n}$ the set of $n$-dimensional vectors, by $\mathbb{R}^{n \times m}$ the set of $(n \times m)$-dimensional matrices, and by $\mathbb{R}^{d_1 \times \ldots \times d_D}$ the set of $(d_1 \times \ldots \times d_D)$-dimensional tensors.

In any given sub-symbolic data-representation task leveraging upon arrays, information may be carried by both:
%
\begin{itemize}
    \item the actual numbers contained into the array, and
    \item their location into the array itself.
\end{itemize}
%
In practice, the actual dimensions $(d_1 \times \ldots \times d_D)$ of the array play a central role as well.
%
Indeed, as further discussed in \cref{chap:learning}, sub-symbolic data processing is commonly tailored on arrays of \emph{fixed} sizes---meaning that the actual values of $d_1, \ldots, d_D$ are chosen at design time and never changed after that.
%
For this reason, we define sub-symbolic data representation as the task of expressing data in the form of \emph{rigid} arrays of \emph{numbers}.
%
Notably, such a task is \emph{extensional} by construction, as information can only be explicitly represented.

\paragraph{Local vs. Distributed}

An important distinction, when data is represented in the form of numeric arrays, is about whether the representation is \emph{local} or \emph{distributed} \cite{Gelder90}.
%
In local representations, each single number into the array is characterised by a well-delimited meaning---i.e. it is measuring or describing a clearly identifiable concept from the domain of the discourse.
%
Conversely, in distributed representations, each single item of the array is nearly meaningless, unless it is considered along with its neighbourhood---i.e. any other item which is ``close'' in the indexing space of the array, according to some given notion of closeness.
%
So, while in local representations the location of each number in the array is quite negligible, in distributed representations it is of paramount importance.

Consider for instance the Iris dataset from \cref{sec:kr-tabular-data}: it is a tabular dataset where each datum can be considered as a 5-dimensional vector.
%
There, each component of the vector is informative \emph{per se}: it may describe e.g. the petal/sepal length/width.
%
Conversely, consider a dataset of black/white images whose resolution is $w \times h$.
%
There, each image can be represented as a $h \times w$ matrix of numbers in the range $[0, 1]$, where each location represents a pixel and the corresponding brightness.
%
The single pixel carries very small information when considered alone, whereas groups of contiguous pixel may describe details which are relevant for image processing.

\paragraph{Feature Engineering}

Of course, not all data is both rigid and numeric in nature.
%
So, to fit this paradigm, data scientists designed a plethora of conversion methods to transform data from various forms (e.g. possibly non-rigid or non-numeric, when not both) into rigid arrays of numbers.
%
In particular, when raw data is very flexible (i.e. variable in size) and very distributed, a common method consists of computing the so-called \emph{embeddings}, i.e. fixed-size arrays synthesising the information contained into the raw data.
%
All such methods lay under the \emph{feature engineering} umbrella.

The ideal situation, under a data representation perspective, is when data is in \emph{tabular} form, i.e. $N$ instances and $M$ features, and all features only involve numeric values.
%
There, each instance is naturally described by a $M$-dimensional vector, while the whole dataset is described by an $N \times M$ matrix.
%
However, in practice, only rarely raw data fits the rigid and numeric paradigm since the very beginning.
%
More commonly, raw data may diverge from the paradigm in several ways---possibly, simultaneously.
%
When this is the case, a number of transformations can be applied to the data to make it converge to the paradigm.

\subparagraph{Non-numeric features}

A dataset may involve non-numeric features, even when of tabular form.
%
When this is the case, each single non-numeric feature may be transformed into numeric by applying a transformation to each value.
%
The most adequate transformation heavily depends on the domain of the feature itself:
%
\begin{description}
    \item[boolean] features may be trivially converted into numbers via the $\{ \functor{false} \mapsto 0, \functor{true} \mapsto 1 \}$ encoding;

    \item[ordinal] features may be trivially converted into natural numbers reflecting the same ordering;

    \item[categorical] features may be converted into boolean features via the one-hot encoding\footnotemark;

    \item[structured] features having a \textbf{fixed} structure (e.g. dates or timestamps) can be decomposed into their components;
\end{description}
%
while other situations may fit the cases below.

\footnotetext{
    An $n$-dimensional vector $\mathbf{x}$ of categorical values $x_1, \ldots, x_n$ where each $x_i \in \mathcal{C} = \{ c_1, \ldots, c_m \}$ can always be \emph{one-hot encoded} into a $m \times n$ matrix where the item in position $i, j$ is 1 iff $x_i = c_j$, or 0 otherwise.
}

\subparagraph{Variable-size data}

A dataset may involve data of variable size.
%
Consider for instance time series (e.g. samples of some phenomenon over time), or free text, or graph-like information (e.g. friendships on social networks, citations in papers).
%
There, despite each single instance of the dataset can be trivially translated into an array of numbers of some size, any two different instances from the same dataset may have different sizes and internal structures.

For instance, time series can be easily modelled as $T$-dimensional vectors -- where $T$ is the total amount of available samples --, and the $t^{th}$ component of the vector represents the sample at time $t$;
%
free text can be represented as $W$-dimensional vectors -- where $W$ is the total amount of words/bigram/trigram/\ldots in the text --, and
the $w^{th}$ component of the vector represents the frequency of the $w^{th}$ word in the text (according to some ordering of words in the text);
%
graphs can described by $N \times N$ adjacency matrices---where $N$ is the total amount of nodes into the graph.
%
These data representation approaches are inherently distributed and non-rigid.
%
In fact, for any two different time series (possibly sampling the similar phenomena), the amount of available samples may be different.
%
Similarly, two different text may involve different sets of words, resulting in vectors of different sizes.
%
Finally, two different graphs (possibly describing similar situations), may involve a different amount of nodes.

Depending on the nature of the data itself, and on the particular data-analytic goal data representation is serving, datasets of such sorts can be translated into rigid form by following one of the strategies below:
%
\begin{description}
    \item[draw a number of statistics] on each datum (e.g. mean, standard deviation, min, max, etc.), attempting to aggregate the information therein contained: if the same amount and sorts of statistics are drawn for each datum, the dataset will then become tabular;
    \item[apply a domain-chancing transformation] such as the Fourier transform \cite{CooleyLW1969} or the wavelet transform \cite{Zhang2019};
    \item[sub-sample each variable-size datum] using a fixed-size sampling step; e.g. a sliding window for time series \cite{FrankDH01}, or neighbourhoods of fixed sizes for graphs;
    \item[exploit \emph{ad-hoc} embeddings] targetting particular sorts of data, such as GNN \cite{WuPCLZY2021}, Word2Vec \cite{Church2017}, etc.
\end{description}

\section{Comparison: Symbolic vs. Sub-Symbolic KR}

Symbolic and sub-symbolic approaches to KR can be compared along several dimensions, along which their duality seems clear.

\paragraph{Crispness vs. Fuzziness}

At the syntactical level we describe symbolic KR as ``flexible'' -- mostly because it can represent knowledge intensionally, via variables, and concisely, via recursive structures -- and sub-symbol KR as ``rigid''---because of its prominent reliance on fixed-size arrays.
%
However, it is well understood how, in practice, symbolic KR leads to \emph{crisp} representations, whereas sub-symbolic KR leads to \emph{fuzzy} representations.
%
The distinction is well-established within the AI literature.
%
For instance, in the early 90s, Minsky described symbolic approaches as neat, and sub-symbolic ones as scruffy \cite{Minsky1991}.

Regardless of the particular terminological choices, the statement stems from the exact nature of symbolic KR as opposed to the approximate nature of its sub-symbolic counterpart.
%
Indeed, while the interpretation of logic formul\ae{} is often discrete and finite-valued -- and more commonly Boolean (i.e. two-valued) --, arrays of real numbers may span through an infinity of values, and continuos notions of similarity or distance may be defined among them.
%
So, for instance, while symbolically represented objects can only be either equals or not, vectors, matrices, or tensors may be more or less similar, according to a continuum of possibilities.

Accordingly, logic-based representation are most adequate to represent exact situations, where the world can be modelled according to precise rules.
%
Conversely, array-based representation are most adequate to represent approximate situations, where similarity or slight differences among entities are interesting and should be explicitly captured.

\paragraph{Extensional vs. Intensional}

Another relevant distinction concerns the capability of representing knowledge intensionally.
%
While symbolic approaches support both intensional and extensional representations, sub-symbolic approaches only support extensional representations.
%
This implies that, when represented sub-symbolically, all data should be represented explicitly.

The explicit representation of \emph{all} the available information is at the same time a blessing and a curse.
%
In fact, while it costs far more space -- thus complicating both storage and processing --, it simplifies the design of sub-symbolic algorithms, which can rely on the assumption that all relevant data is immediately available.

\paragraph{About Conversions}

Conversions among the symbolic and sub-symbol realm (or vice versa) are where discrepancies become more evident.
%
In particular, while the conversion in symbolic form of some sub-symbolic array of number is always possible -- as extensive tabular information can be suitably represented via logic formul\ae{} as well --, the conversion of logic knowledge into sub-symbolic form is cumbersome.
%
Despite many conversion strategies (or embeddings) have been proposed into the literature, they commonly require:
%
\begin{enumerate}
    \item\label{item:finite-symbols} all the constants, functor symbols, and predicate symbols to be explicitly encoded \cite[sec. 6.2]{CropperDM20},
    \item\label{item:gound-kbs} variables to be missing, as they would imply some intensional representation \cite{SerafiniG16},
    \item\label{item:tensor-products} $N$-ary structures to be encoded into tensors having at least $N$ dimensions, possibly recursively combined via the tensor product \cite{Smolensky1990}.
\end{enumerate}
%
Unfortunately, all such requirements come with quite strong limitations.
%
In particular, item \ref{item:finite-symbols} implies that constants, functors, and predicate symbols must be of finite quantity and all \emph{a-priori} known---both conditions which rarely hold in practice.
%
Item \ref{item:gound-kbs} implies logic formul\ae{} should be \emph{grounded}, if not already ground---which would obliterate the advantages coming from intensional representations.
%
Finally, item \ref{item:tensor-products} implies that the maximum level of recursion should be \emph{a-priori} defined, as each tensor product increases the dimensionality of the tensors at hand---which in turn cannot increase indefinitely, as it would violate the rigidity required by sub-symbolic KR.
%
All such issues arise because sub-symbolic KR is inherently extensional, and it involves no simple way to express data intensionally -- and therefore concisely -- as in logic.

\chapter{Learning Knowledge from Data}\label{chap:learning}

A famous definition of machine learning from \cite{Mitchell1997} states:
%
\begin{displayquote}
    A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$ if its performance at tasks in $T$, as measured by $P$, improves with experience $E$
\end{displayquote}
%
This definition is very wide, as it does not specify
%
\begin{inlinelist}
    \item what are the possible tasks,
    % \item whether they are subject to some constraint,
    \item how performance measured is in practice,
    \item how / when experience should be provided to tasks,
    \item how exactly the program is supposed learn, and
    \item under which form learnt information is represented.
\end{inlinelist}
%
Accordingly, depending on the particular ways these aspects are tackled, a categorisation of the approaches and techniques for letting software agents learn may be drawn.

\begin{figure}
    \centering
    \includegraphics[width=.8\linewidth]{figures/ml-taxonomy.pdf}
    \caption[Taxonomy of ML]{Taxonomy of ML. The second column enumerates the three major families of ML approaches, the third one enumerates the main sorts of tasks affiliated with each family, whereas the fourth one enumerates possible applications for each task.}
    \label{fig:ml-taxonomy}
\end{figure}
%
As depicted in \cref{fig:ml-taxonomy}, three major approaches to ML exist.
%
Each approach is characterised by a well-defined pool of tasks, which may, in turn, be applied in wide range of use case scenarios.
%
The three major approaches to learning are: \emph{supervised}, \emph{unsupervised}, and \emph{reinforcement}.
%
They essentially deal with the kind of task $T$ to be learned -- commonly consisting in the estimation of an unknown relation --, and how experience $E$ is provided to the learning algorithm.

In supervised learning, the learning task consists of finding a way to approximate an unknown relation, given a sampling of its items---which constitute the experience.
%
In unsupervised learning, the learning task consists of finding the best relation for a sample of items -- which constitute the experience --, following a given optimality criterion intensionally describing the target relation.
%
In reinforcement learning, the learning task consists of letting an agent estimate optimal plans given the reward it receives whenever it reaches particular goals---constituting the experience.
%
There, a plan can be described as a relation among the possible states of the world, the actions to be performed in those states, and the reward the agents expects to receive from that action.

Such categorization of learning approaches can be applied to both symbolic and sub-symbolic techniques.
%
Indeed, in this chapter, we provide an overview of learning on a per representation basis.
%
In particular, in the following sections we summarise the state of the art for what concerns both symbolic and sub-symbolic forms of \emph{supervised} learning.

\section{Sub-Symbolic Supervised Machine Learning}

Since several practical AI problems -- such as image recognition, financial and medical decision support systems -- can be reduced to \emph{supervised} ML -- which can be further grouped in terms of either  \emph{classification} or \emph{regression} problems \cite{twala2010,smlreview-faia160} --, in the reminder of this section we focus on this set of ML problems.

Within the scope of sub-symbolic supervised ML, a \emph{learning algorithm} is commonly exploited to approximate the specific nature and shape of an unknown \emph{prediction} function (or \emph{predictor}) $\pi^*: \mathcal{X} \rightarrow \mathcal{Y}$, mapping data from an input space $\mathcal{X}$ into an output space $\mathcal{Y}$.
%
There, common choices for both $\mathcal{X}$ and $\mathcal{Y}$ are, for instance, the set of vectors, matrices, or tensors of numbers of a given size---hence the sub-symbolic nature of the approach.

An important assumption significantly affecting both the theory and the practice of sub-symbolic supervised learning is that vectors, matrices, or tensors in $\mathcal{X}$ and $\mathcal{Y}$ are of \emph{fixed} size---despite items in $\mathcal{X}$ may have a different sizes than the items in $\mathcal{Y}$.
%
Without lack of generality, in what follows we refer to items in $\mathcal{X}$ as $n$-dimensional vectors denoted as $\mathbf{x}$, whereas items in $\mathcal{Y}$ are $m$-dimensional vectors denoted as $\mathbf{y}$---despite matrices or tensors may be suitable choices as well.

To approximate function $\pi^*$, supervised learning assumes a learning \emph{algorithm} is in place.
%
This algorithm computes the approximation by taking into account a number $N$ of \emph{examples} of the form $(\mathbf{x}_i,\mathbf{y}_i)$ such that $\mathbf{x}_i \in X \subset \mathcal{X}$, $\mathbf{y}_i \in Y \subset \mathcal{Y}$, and $|X| \equiv |Y| \equiv N$.
%
There, the set $D = \{ (\mathbf{x}_i,\mathbf{y}_i) \mid \mathbf{x}_i \in X, \mathbf{y}_i \in Y \}$ is called \emph{training} set, and it consists of $(n+m)$-dimensional vectors.
%
The dataset can be considered as the concatenation of two matrices, namely the $N \times n$ matrix of \emph{input} data ($X$) and the $N \times m$ matrix of \emph{expected output} data ($Y$).
%
There, each $\mathbf{x}_i$ represents an instance of the input data for which the expected output value $\mathbf{y}_i \equiv \pi^*(\mathbf{x}_i)$ is known or has already been estimated.
%
Notably, such sorts of ML problems are said to be ``supervised'' \emph{because} the expected outputs $Y$ are available.
%
Furthermore, the function approximation task is called ``regression'' if the components of $Y$ consist of continuous or numerable -- i.e. \emph{infinite} -- values, or ``classification'' problems they consist of categorical -- i.e. \emph{finite} -- values.

Many learning algorithms exist, and they work in quite different ways.
%
However, the general layout of sub-symbolic supervised learning is the same in all cases.
%
The learning algorithm assumes $\pi^*$ to be a function from a given set of functions $\mathcal{H}$ called \emph{hypotheses} space---i.e. $\pi^* \in \mathcal{H}$.
%
In other words, the underlying assumption is that the unknown prediction function $\pi^*$ exists, and it is of the form characterising all functions in $\mathcal{H}$.
%
The algorithm performs an exploration of the \emph{hypotheses} space $\mathcal{H}$ looking for the hypothesis function $\hat{\pi} \in \mathcal{H}$ that better fits the data in $D$---and that, therefore, better approximates $\pi^*$.

The goodness of the fitting among a hypothesis function $\hat{\pi}$ and the data can be assessed via either
%
\begin{inlinelist}
    \item an error function $\varepsilon : \mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb{R}_{\geq 0}$ measuring the discrepancy among the expected outputs in $Y$ and the values attained by applying $\hat{\pi}$ to $X$, or dually,
    \item an adherence function $\rho : \mathcal{Y} \times \mathcal{Y} \rightarrow \mathbb{R}_{\leq 1}$, measuring the similarities among the same values.
\end{inlinelist}
%
For the sake of simplicity, we here consider the best hypothesis $\hat{\pi}$ the one item of $\mathcal{H}$ for which the total error is minimal -- or the total adherence is maximal --, w.r.t. the data in $D$.
%
Therefore, in theory, any sub-symbolic supervised learning process can be abstractly described via any of the following formul\ae{}:
%
$$
\hat{\pi} = \argmin{\pi \in \mathcal{H}}{ \sum_{i=1}^{N} \varepsilon(\mathbf{y}_i,\ \pi(\mathbf{x}_i)) }
\quad \text{or} \quad
\hat{\pi} = \argmax{\pi \in \mathcal{H}}{ \sum_{i=1}^{N} \rho(\mathbf{y}_i,\ \pi(\mathbf{x}_i)) }
$$

\paragraph{Parameters and hyper-parameters}

Exploration of the hypothesis space is what is commonly referred to as ``learning'' or ``training''.
%
Learning algorithms mostly differ for the strategy they follow to perform such exploration, other than the particular hypotheses spaces they support.

A common strategy followed by most learning algorithms leverages on the assumption that the hypothesis space is the set of all functions having the same shape, regulated by a given amount $p$ of \emph{parameters}---namely $\mathcal{H}_\Theta$ where $\Theta \subseteq \mathbb{R}^p$ is space of parameters, enumerated by $\theta$.
%.
Under such assumption, the formulation of supervised learning can be rewritten as the optimisation task of finding the optimal parameters $\theta^*$ among the ones in $\Theta$:
%
$$
\theta^* = \argmin{\theta \in \Theta}{ \sum_{i=1}^{N} \varepsilon(\mathbf{y}_i,\ \pi_\theta(\mathbf{x}_i)) }
\quad \text{or} \quad
\theta^* = \argmax{\theta \in \Theta}{ \sum_{i=1}^{N} \rho(\mathbf{y}_i,\ \pi_\theta(\mathbf{x}_i)) }
$$
%
where $\pi_\theta \in \mathcal{H}_\Theta$ is the particular function using the parameters in $\theta$.

If all functions in $\mathcal{H}_\Theta$, as well as the error (resp. adherence) function $\varepsilon$ (resp. $\rho$), are differentiable w.r.t. $\theta$, then the optimisation task can be tackled via gradient descent (resp. climbing) in the general case---despite better options may exist for particular shapes of the functions in $\mathcal{H}_\Theta$.
%
Such need to rely on differentiable functions of vectors of real numbers is what forces many ML techniques into the sub-symbolic realm.

Notably, a hypothesis space is commonly generated by a particular assignment of a number $q$ of \emph{hyper-parameters} $\omega \in \mathbb{R}^q$.
%
Each particular value of $\omega$ corresponds to a particular parameters space $\Theta$, and therefore to a particular hypothesis space $\mathcal{H}_\Theta^\omega$.
%
The hypothesis space may consist for instance of the set of all polynomials of $a$ variables whose degree is $b$.
%
That would imply the corresponding parameters space to comprehend all possible vectors having $\binom{b}{a}$ components.
%
So, if $a = b = 1$, then $\mathcal{H}_\Theta^\omega$ is the set of all possible straight lines on a plane, i.e. polynomials parametrised by $\theta_1$ and $\theta_2$.
%
For $a = 1$ and $b = 2$, $\mathcal{H}_\Theta^\omega$ corresponds to the set of all possible parabolas on a plane, i.e. polynomials parametrised by $\theta_1$ and $\theta_2$ and $\theta_3$.
%
A similar example may be built upon polynomials of 2 variables, and so on.

The difference among parameters and \emph{hyper-}parameters is very important in practice.
%
In fact, while parameters are \emph{automatically} computed by the learning algorithm, hyper-parameters are not.
%
They may be either guessed or estimated by trial-and-error by data scientists---hence representing a bottleneck in the automatisation of learning.

%\note{About generalisation: the bias-variance trade-off?} % maybe out of topic

\subsection{Overview on learning algorithms}

%\note{
%    Comments on existing algorithms and their relevant aspects?
%    Let's distinguish among parametric and non-parametric algorithms.
%    Let's distinguish among regression and classification algorithms, with a focus on regression as classification can be reduced to regression.
%    Focus on gradient descent, back-propagation and deep learning.
%}

Depending on the predictor family of choice, the nature of the admissible hypotheses spaces and learning algorithms may vary dramatically, as well as the predictive performance of the target predictor, and the whole efficiency of learning.

In the literature of machine learning, statistical learning, and data mining, a plethora of learning algorithms have been proposed along the years.
%
Because of the ``no free lunch'' (NFL) theorem \cite{DolpertM97}, however, no algorithm is guaranteed to outperform the others in all possible scenarios.
%
For this reason, the literature and the practice of data science keeps leveraging on algorithms and methods whose first proposal was published decades ago.
%
Most notable algorithms include for instance (deep) neural networks, decision trees, (generalised) linear models, nearest neighbours, support vector machines (SVM), random forests, and many others.

These algorithms can be categorised in several ways, for instance depending on
%
\begin{inlinelist}
    \item the supervised learning task they support (classification vs. regression),
    \item on when they consume data (lazy vs. eager),
    \item or on the underlying strategy adopted for learning (e.g. gradient descent, least squares optimization), etc.
\end{inlinelist}


Some learning algorithms (e.g. neural networks) target regression problems, whereas others (e.g. SVM) target classification problems.
%
Similarly, some target multi-dimensional outputs ($\mathbf{y} \in \mathbb{R}^m$), whereas others target mono-dimensional outputs ($m = 1$).
%
Regressors are considered as the most general case, as other learning tasks can usually be defined in terms of mono-dimensional regression.
%
Binary classifiers, for instance, can be treated as mono-dimensional regressors where admissible outputs lay in the interval $[0, 1]$, while multi-class (resp. multi-dimensional) classifiers (resp. regressors) can be treated as ensembles of multiple binary classifiers (resp. regressors).

% briefly explain the eager-lazy dicotomy
The eager--lazy dichotomy relates to operational aspects of learning, and, in particular, to \emph{when} training data is actually processed.
%
This, in turn, affects the computational time required in the training and inference phases---i.e. when the predictor is exploited to draw predictions.
%
In principle, the training phase of \emph{lazy} predictors (e.g. nearest neighbours) is trivial and no data needs to be processed as training data is mostly processed in the inference phase.
%
This makes the training phase quicker, at the expense of a slower inference phase.
%
To mitigate this issue, in practice, indexing or grouping of training data may be exploited in the training phase, with the purpose of speeding up the inference phase.
%
Conversely, \emph{eager} predictors (e.g. linear models, neural networks, and virtually any other method mentioned so far) come with a full-fledged learning phase, where the unknown function binding input and outputs is approximated from training data.
%
There, the learning phase carries the higher computational effort, and the inference phase is quick.
%
In the reminder of this section, we focus on eager predictors as they actually produce an internal representation of data during their learning phase, which is the starting point of relevant discussion carried out in \cref{chap:explaining}.

% discuss about GD-based approaces
Finally, the learning strategy is inherently bound to the predictor family of choice.
%
Neural networks, for instance, are trained via back-propagation \cite{Rumelhart1986} -- a particular case of stochastic gradient descent (SDG, \cite{enwiki:SGD}), tailored on NN --, generalised linear models via Gauss' least squares method, decision trees via CART \cite{breiman1984classification}, etc.
%
Despite all such algorithms may appear interchangeable in principle -- because of the NFL theorem --, their malleability is very different in practice.
%
For instance, the least squares method involves inverting matrices of order $N$ -- where $N$ is the amount of available examples in the training set --, making the computational complexity of learning more than quadratic in time.
%
Furthermore, in practice, convergence of the method is not guaranteed in the general case, while it is for generalised linear models---hence why it is not adopted elsewhere.
%
Thus, learning by least squares optimisation may become impractical for big datasets or for predictor families outside the scope of generalised linear models.
%
Conversely, the SGD method involves arbitrarily-sized subsets of the dataset (a.k.a. batches) to be processed a limited (i.e. controllable) amount of times.
%
Hence, the complexity of SGD can be finely controlled and adapted to the computational resources at hand---e.g. by making the learning process incremental, and by avoiding all data to be loaded in memory.
%
Furthermore, SGD can be applied to several sorts of predictor families (there including neural networks and generalised linear models), as it only requires the target function to be differentiable w.r.t. its parameters.
%
For all these reasons, despite the lack of optimality guarantees, SGD is considered as very effective, scalable, and malleable in practice, hence why it is extensively exploited in the modern data science applications.

In the reminder of this thesis, we focus on two particular families of predictors -- namely, decision trees and neural networks --, and their respective learning methods---i.e. the CART \cite{breiman1984classification} and back-propagation \cite{Rumelhart1986} algorithms.
%
Notably, decision tree are relevant because of their user friendliness, whereas neural networks are relevant because of their predictive performance and flexibility.

\paragraph{Decision Trees}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/dt-kyphosis.png}
    \caption{An example decision tree estimating the probability of kyphosis after spinal surgery, given the \emph{age} of the patient and the vertebra at which surgery was \emph{start}ed \cite{wiki:dt-learning}. Notice that each decision tree subtends a partition of the input space, and that the tree itself provides an intelligible representation of \emph{how} predictions are attained.}
    \label{fig:dt-example}
\end{figure}

Decision trees (DT) are particular sorts of predictors supporting both classification and regression tasks.
%
In their learning phase, the input space is recursively \emph{partitioned} through a number of splits (a.k.a. \emph{decisions}) based on the input data $X$, in such a way that the prediction in each partition is constant, and the error w.r.t.\ the expected outputs $Y$ is minimal, while keeping the total amount of partitions low as well.
%
The whole procedure then synthesises a number of \emph{hierarchical} decision rules to be followed whenever the prediction corresponding to any $x \in \mathcal{X}$ must be computed.
%
In the inference phase, decision rules are orderly evaluated from the root to some leaf, in order to select the portion of the input space  $\mathcal{X}$ containing $x$.
%
As each leaf corresponds to a single portion of the input space, the whole procedure results in a single prediction for each $x$.

Differently from other families of predictors, the peculiarity of decision trees lays in the particular outcome of the learning process -- namely, the \emph{tree} of decision rules -- which is naturally intelligible for humans and graphically representable in 2D charts.
%
As further discussed in the reminder of this thesis, this property is of paramount importance whenever the inner operation of an automatic predictor must be interpreted by a human being.


%Without affecting generality, we focus on the case of mono-dimensional classification -- thus we write $y$ instead of $\mathbf{y}$ --, since other cases can be easily reduced to this one.
%%
%We further assume the input space $\mathcal{X}$ is $N$-dimensional, and let $n_j$ be the meta-variable representing the name of the $j^{th}$ dimension of $\mathcal{X}$.
%
%Under such hypotheses, a DT predictor $p_T \in \mathcal{P}_{dt}$ assumes a \emph{binary} tree $T$ exists such that each node is either
%%
%\begin{itemize}
%    \item a \emph{leaf}, carrying and representing a prediction, i.e. and assignment for $y$,
%    \item an \emph{internal} node, carrying and representing a \emph{decision}, i.e. a formula in the form $(n_j \leq c)$---where $c$ is a constant \emph{threshold} chosen by the learning algorithm.
%\end{itemize}
%%
%Each node $\nu$ inherits a partition $X_\nu \subseteq X$ of the original input data, from its parent.
%%
%Since the root node $\nu_0$ has no parent, it is assigned to the whole set of input data---i.e. $X_{\nu_0} \equiv X$.
%%
%The decision carried by each internal node splits its $X_\nu$ into two disjoint parts -- $X^L_\nu$ and $X_\nu^R$ -- along the $j^{th}$ dimension of $\mathcal{X}$.
%%
%In particular, $X_\nu^L $ contains all the residual $x_i \in X_\nu$ such that $(x_i^j \leq c_\nu)$ -- which are inherited by $\nu$ left child --, whereas $X_\nu^R$ contains all the residual $x_i \in X_\nu$ such that $x_i^j > c_\nu$---which are inherited by  by $\nu$ right child.
%%
%A leaf node $l$ is created whenever a sequence of splits (i.e., a path from the tree root to the leaf parent) leads to a partition $X_l$ which is (almost) \emph{pure}---roughly, meaning that $X_l$ (mostly) contains input data $x_i$ for which the expected output is the same $y_l$.
%%
%In this case, we say that the prediction carried by $l$ is $y_l$.
%%
%Assuming such a tree $T$ exists, in order to classify some input data $\mathbf{x} \in \mathcal{X}$, the predictor $p_T$ simply navigates the path $P = (\nu_0, \nu_1, \nu_2, \ldots, l)$ of $T$ such that all decisions $\nu_k$ are matched by $\mathbf{x}$, then it outputs $y_l$.

\paragraph{Neural Networks}

Neural networks (NN) are biologically-inspired computational models, made of several elementary units (neurons) interconnected into a graph (commonly, \emph{directed} and \emph{acyclic}, a.k.a. DAG) via \emph{weighted} synapses.
%
Accordingly, the most relevant aspects of NN concern the inner functioning of neurons and the particular architecture of their interconnection.

Neurons are very simple numeric computational units.
%
They accept $n$ scalar inputs $(x_1, \ldots, x_n) = \mathbf{x} \in \mathbb{R}^n$ weighted by as many scalar weights $(w_1, \ldots, w_n) = \mathbf{w} \in \mathbb{R}^n$, and they process their linear combination $\mathbf{x} \cdot \mathbf{w}$ via an activation function \cite{enwiki:ActivationFunctions} $\sigma : \mathbb{R} \mapsto \mathbb{R}$, producing a scalar output $y = \sigma(\mathbf{x} \cdot \mathbf{w})$, as depicted in \cref{fig:neuron}.
%
\begin{figure}
    \centering
    \includegraphics[width=.6\linewidth]{figures/neuron.png}
    \caption{Admissible architectures for neural networks \cite{VanVeenL2019}}
    \label{fig:neuron}
\end{figure}
%
The output of a neuron may become the input of many others, possibly forming \emph{networks} of neurons having arbitrary topologies.
%
These network may be fed with any numeric information encoded as vectors of real numbers by simply letting a number of neurons produce constant outputs.

While virtually all topologies are admissible for NN, not all are convenient.
%
A number of convenient \emph{architectures} -- roughly, patterns of well-studied topologies -- have been proposed into the literature \cite{VanVeenL2019} to serve disparate purposes---far beyond the scope of supervised machine learning.
%
\Cref{fig:nn-architectures} overviews the current state of the art of NN architectures.
%
\begin{figure}
    \centering
    \includegraphics[width=.8\linewidth]{figures/neural-network-architectures.png}
    \caption{Admissible architectures for neural networks \cite{VanVeenL2019}}
    \label{fig:nn-architectures}
\end{figure}

NN can be \emph{trained} on numeric data via stochastic gradient descent and exploited into both supervised and unsupervised learning tasks such as classification, regression, and anomaly detection, depending on the particular architecture of choice.
%
More precisely, while the training \emph{automatically} sets up the weights of each neuron's ingoing synapses, the overall topology of the network is not allowed to vary.
%
It is rather assumed to be \emph{manually} engineered by data scientists.

Most common NN architectures are feed-forward, meaning that neurons are organised in successive \emph{layers}, in such a way that neurons from layer $i$ can only accept ingoing synapses from neurons of layers $j < i$.
%
The first layer is considered the input layer, which is used to \emph{feed} the whole network, while the last one is the output layer, where prediction are drawn.
%
In these kind of architectures, inference lets information flow from the input to the output layers -- assuming the weights of synapses are fixed --, while training lets information flow from the output to the input layers---provoking the variation of weights to minimise the prediction error of the overall network.

The recent success of deep learning \cite{GoodfellowBC2016} has proved the flexibility and the predictive performance of \emph{deep} neural networks (DNN).
%
`Deep' here refers to the large amount of (possibly \emph{convolutional}) layers.
%
In other words, DNN can learn how to apply cascades of convolutional operations to the input data.
%
Convolutions let the network spot relevant features into the input data, at possibly different scales.
%
Hence why DNN are good at solving complex pattern-recognition tasks, such as in computer vision or speech recognition.
%
Unfortunately, however, unprecedented predictive performances of DNN come at the cost of their increased internal complexity and greater data greediness.

\section{Symbolic Supervised Learning}

Within the realm of symbolic AI, supervised ML commonly refers to either \emph{inductive logic programming} (ILP) \cite{Muggleton91} or \emph{statistical relational learning} (SRL) \cite{DeRaedt2010}, despite the overlap among the two disciplines is wide.

In both cases, learning consists of approximating an unknown \emph{intensional} representation $H^*$ for a number of positive examples $E^+$, possibly leveraging on
%
\begin{itemize}
    \item some prior KB $B$, carrying the so-called \emph{background knowledge} about the domain at hand;
    \item a number of \emph{negative} examples $E^-$;
    \item a \emph{language bias} $C$, constraining the admissible shapes for the representation to-be-learned.
\end{itemize}
%
In the general case, $H^*$, $E^+$, $E^-$, and $B$ are knowledge bases, possibly involving several definite clauses (i.e. either rules or facts), while the shape of $C$ really depends on the particular learning approach at hand.
%
Of course, there may be cases where $E^-$, $B$ or $C$ are not required, and therefore considered as empty sets.

The main difference among ILP and SLR lays in the particular language used for knowledge representation.
%
While in ILP knowledge bases simply consist of bare definite clauses, SRL leverages on a superset of Horn Logic called ProbLog \cite{RaedtKT07}, where definite clauses are enriched with probability values.

According to the SLR nomenclature of \cite{DeRaedt2010} -- where a unifying model generalising ILP and SLR is proposed --, there are two relevant problems which lay under the symbolic supervised learning umbrella, namely:
%
\begin{description}
    \item[parameters learning] where $H$ consists of a given ProbLog KB, where the shape of facts and rules is known, while their probabilities are not, and learning aims at simply estimating those probabilities

    \item[structure learning] where $H$ is completely unknown, and the whole shape of facts and rules therein contained must be computed, possibly along with their corresponding probabilities
\end{description}

In both cases, learning can be defined as an optimisation problem aimed at approximating $H^*$ by search for the best KB $\hat{H}$ into an hypothesis space $\mathcal{H}_{B,C}$, defined by applying all possible combinations of clauses in $B$, as dictated by $C$.
%
There, each KB $H \in \mathcal{H}_{B,C}$ consists of a number of definite clauses defining the $n$-ary relation $h$, possibly leveraging on the relations defined in $B$, and satisfying the suggestions/constraints expressed by $C$.
%
In other words, they consist of KB intensionally defining $h$ via rules of the form:
%
\begin{equation*}
    \psi :: h(X_1,\ \ldots,\ X_n) \leftarrow f(\bar{X}),\ f'(\bar{X}'),\ f''(\bar{X}''),\ \ldots
\end{equation*}
%
where $\psi$ denotes an optional probability value,  while $\bar{X}, \bar{X}', \bar{X}'', \ldots$ are tuples involving one or more head variables (i.e., $X_1, \ldots, X_n$), and $f, f', f'', \ldots$ are either predicates defined in $B$ or combinations of those predicates, attained by following the suggestions/constraints contained in $C$.
%
Similarly, $E^+$ (resp. $E^-$) consists of facts of the form $h/n$, extensionally defining known (resp. invalid) items of the $n$-aray relation $h$, and possibly labelled with probabilities.

Analogously to the sub-symbolic case, symbolic supervised learning leverages upon some adherence function $\rho$, aimed at measuring the adherence of some hypothesis KB $H \in \mathcal{H}_{B,C}$ w.r.t. either $E^+$ or $E^-$.
%
For instance, in SRL, $\rho$ is commonly modelled probabilistically:
%
\begin{equation*}
    \rho(H, E, B) = \sum_{e \in E} \mathbb{P}(e \mid H, B)
\end{equation*}
%
where $\mathbb{P}(\cdot \mid \cdot)$ denotes the conditional probability operator.
%
Conversely, in ILP, $\rho$ is modelled in terms of logic inference\footnotemark:
%
\begin{equation*}
    \rho(H, E, B) = \sum_{e \in E} \rho(H, e, B)
    \quad \text{and} \quad
    \rho(H, e, B) = \begin{cases}
        1 & \text{if} ~ H, B \models e
        \\
        0 & \text{otherwise}
    \end{cases}
\end{equation*}
%
\footnotetext{
    This aspect is better discussed in \cref{chap:reasoning}.
    %
    Within the scope of this chapter, the notation $K \models \phi$, where $K$ is a knowledge base and $\phi$ is a logic formula, can simply be read as ``$\phi$ can be inferred from $K$ via some inference procedure''.
}
%
Under such hypothesis, symbolic supervised learning can be defined as \cite{DeRaedt2010} the optimisation task aimed at finding the hypothesis which adheres to as much positive examples as possible, while adhering to no negative example at all:
%
\begin{equation}
    \hat{H} = \argmax{H \in \mathcal{H}_{B,C} ~ \text{s.t.} ~ \rho(H, E^-, B) = 0}{\rho(H, E^+, B)}
\end{equation}

Parameter and structure learning differ for the actual way the search is performed, other than for the actual object of search.
%
In parameter learning, algorithms can assume the shape of (facts and rules in) $\hat{H}$ to be given (and fixed), and therefore focus on the mere estimation of probabilities.
%
Conversely, in structure learning, algorithms must also consider the many possible shapes $\hat{H}$ may have.
%
This includes all possible combinations of all relations possibly defined in $B$.
%
Assuming, for instance, that $B$ intensionally defines $r$ relations $f_1, \ldots, f_r$, whose arity is at least $a$, and that the target relation is $h$, whose arity is $n$.
%
Under such hypothesis, rules in $H$ should be of the form:
%
\begin{equation*}
    h(X_1,\ \ldots,\ X_n) \leftarrow \ldots
\end{equation*}
%
where the body of the rule may contain as many predicates as in any possible permutation of any possible subset of $\{ f_1, \ldots, f_r \}$.
%
There, each possible $a$-ary relation could be written as a predicate involving some disposition of $a$ variables from the set $\{ X_1, \ldots, X_n \}$.
%
In other words, the search space for structure learning is \emph{huge} and definitely impossible to explore in useful time, unless in trivial cases.
%
To complicate the matter, differently from the sub-symbolic case, the search space is not even continuous---meaning that gradient based approaches cannot be applied.

To mitigate such issues -- and to reduce the search space --, the ILP community leverages on smart choices of the linguistic bias $C$.
%
The general purpose of the linguistic bias is to constrain the particular way relations from $B$ can be combined in $H$.
%
For instance, in the meta-interpretative learning approach \cite{MuggletonLPT14}, $C$ consists of a library of higher-order rules (a.k.a. meta-rules), which define the admissible sorts of combinations.
%
There, a meta-rule is a rule involving higher-order variables enumerating over predicate symbols, such as:
%
\begin{equation}\label{eq:meta-rule-example}
    \textsf{P}(A,\ B) \leftarrow \textsf{Q}(A,\ C),\ \textsf{R}(C,\ B)
\end{equation}
%
where uppercase, sans-serif letters $\textsf{P}, \textsf{Q}, \textsf{R}$ denote higher-order variables, while $A, B, C$ are ordinary variables; and the whole formula allows an induction algorithm to \emph{invent} \cite{MuggletonB88} some binary predicate $\textsf{P}$ by combinations of two binary predicates $\textsf{Q}$ and $\textsf{R}$.

Consider for instance the case of an ILP problem aimed at learning the positive example $grandparent(\functor{abraham}, \functor{jacob})$, given the background knowledge containing a number of facts expressing parenthood facts of the form $parent(\functor{p}, \functor{p}')$, describing Abraham's family tree---as in \cref{eq:abraham-family-tree}.
%
There, the meta-rule \ref{eq:meta-rule-example} may suggest the correct identification of the target rule -- namely, $grandparent(X, Y) \leftarrow parent(X, Z), parent(Z, Y)$ -- via the variable assignment $\{ \textsf{P} \mapsto grandparent, \textsf{Q} \mapsto parent, \textsf{R} \mapsto parent \}$.

It is worth to be noted how the language bias $C$ plays, in symbolic supervised learning, the same role played by hyper-parameters in sub-symbolic supervised learning.
%
In both cases, \emph{automated} learning relies on some prior knowledge, which must be handcrafted by data scientists.
%
In fact, similarly to sub-symbolic approaches, some mechanism is needed to let humans control either the complexity or learning or the dimension of the search space.
%
In the particular case of symbolic supervised learning, that mechanism is the language bias.

\subsection{Overview on learning algorithms}

\note{
    Intuition behind the functioning of the algorithms.
    ProbLog as the main approach to SRL.
    Bottom up or top down approaches in ILP.
    Mention main approaches: relatively least general generalisation, reverse entailment, bottom clause generalisation, meta-interpretative learning.
    Mention major algorithms developed in this field.
}

\section{Symbolic vs. Sub-Symbolic Learning}

Symbolic and sub-symbolic approaches to supervised learning share similar formulations, despite the corresponding methods and algorithms operate in quite different ways.
%
Both formulations deal with optimisation problems aimed at iteratively constructing an algorithm mimicking an unknown relation/function in the best possible way, leveraging on a number of examples.
%
However, because of their nature and the inherent way they represent knowledge, both approaches come with pros and cons.
%
Here we focus, on their flexibility, maturity, data and computational efficiency, degree of automation, and validation.

\paragraph{Flexibility and maturity}

For what concerns flexibility, symbolic approaches produce more flexible outcomes, whereas sub-symbolic approaches are characterised by more flexible learning processes.

\subparagraph{Outcomes}

Focussing on symbolic approaches, flexibility lays in the shape of the expected outcomes, which is a direct effect of the particular choice of symbols for KR.
%
``Symbolic'' here implies that knowledge is represented via logic clauses, which in turn pave the way towards learning intensional \emph{relations}---possibly taking some prior (background) knowledge into account.
%
Indeed, representing the target of knowledge in the form of relations expressed by logic formul\ae{} comes with two major advantages---namely bi-directionality and re-usability.

First, relations are \emph{bi-directional}, meaning that any argument of the relation can be considered either an input or an output, depending on the situation at hand.
%
So, for instance, if an agent is capable of learning the clauses expressing the $grandparent/2$ relation -- cf. \cref{eq:abraham-family-tree} --, then it acquires a lot of relevant information, namely:
%
\begin{inlinelist}
    \item an explicit, generic representation of \emph{how} the relation can be tested among any two entities $X$ and $Y$,
    \item a way to compute all the grand-children of any given grand-parent $\functor{p}$ -- i.e. $grandparent(\functor{p}, Y)$ --, and
    \item a way to compute all the grand-parents of any given grand-child $\functor{c}$---i.e. $grandparent(X, \functor{c})$.
\end{inlinelist}

Second, relations are \emph{re-usable} (w.r.t. a learning process), meaning that learned relations can be used as prior knowledge in any sub-sequent learning process, as both the inputs and outputs of any symbolic learning process are represented in the same form---namely, logic clauses.
%
This in turn paves the way towards the definition of learning \emph{cycles} where a learning algorithm is executed several times and the knowledge acquired after each round is included in the background knowledge of successive rounds.

Conversely, sub-symbolic approaches aim to learn \emph{functions}, rather than relations.
%
The learned functions are generally \emph{mono-directional} -- in the sense that they are not (easily) invertible -- and extensional.
%
Consider for instance the case of a neural network aimed at classifying images of animals.
%
It may easily discriminate among dogs and cats (i.e. compute the classification, given an input), yet it may hardly generate admissible images of neither dogs or cats (i.e. compute an input, given a class)\footnotemark.

\footnotetext{Generative Adversarial Neural Networks \cite{GoodfellowPMXWOCB14} may be used whenever bi-directionality is needed, yet that essentially implies training two networks: one \emph{classifier} and one \emph{generator} of data, where the former can only classify, and the latter can only generate data.}

\subparagraph{Processes}

Focussing on sub-symbolic approaches, flexibility lays in the variety of methods to approximate the target function.
%
Such variety is once again the result of the particular choice of arrays of numbers for KR.
%
In fact, this choice enables the pervasive exploitation of mathematical operations as the basic bricks of sub-symbolic processing. %learning and computing.
%
These include basic algebraic operators (sum, product, etc.), as well as statistical (mean, variance, standard deviation, etc.), information-theoretical (cross-entropy, mutual information, etc.), signal-processing (Fourier- or Laplace-transform, etc.), binary (bitwise-and, -or, etc.), or differential (differentiation, integration, etc.) operators.
%
All such operators, in turn, come with two major advantages in terms of \emph{malleability} and \emph{parallelisation}.

Malleability refers to the capability of learning in spite of how the many elementary operators are combined.
%
Within the scope of sub-symbolic approaches, malleability is commonly guaranteed by the pervasive exploitation of \emph{differentiable} operators, which supports learning via numeric optimisation algorithms---e.g. stochastic gradient descent (SGD) and its variants \cite{enwiki:SGD}.
%
Conversely, within the scope of symbolic approaches, the presence (resp. lack) of any given operator may greatly affect the \emph{expressiveness} of the underlying logic, therefore making learning more (resp. less) complex from a computational perspective.

Parallelisation refers to the capability of speeding up learning algorithms by executing as much sub-tasks as possible in parallel, provided that the adequate hardware is in place.
%
Within the scope of sub-symbolic approaches, most basic mathematical operators -- such as matrix- or tensor-products --, as well as whole learning steps -- such as \emph{batches} in SGD --, can be executed in parallel to some extent, possible via ad-hoc hardware facilities
%
Conversely, within the scope of symbolic learning, further research on concurrent / parallel solutions is still needed.

Consider, for instance, neural networks as opposed to ILP.
%
They are characterised by a great flexibility because of their reliance on differentiable operators (mostly sums, multiplications and activation functions \cite{enwiki:ActivationFunctions}), and malleable way of combining them into arbitrarily complex structures.
%
Therefore, regardless of the complexity of the overall structure, a NN is composed by the recursive composition of differentiable operators---which makes the whole network trainable via SGD.
%
To further speed up NN training, a plethora of software frameworks have been designed and implemented, with the purpose of exploiting ad-hoc hardware, such as GPUs---cf. Tensorflow \cite{tensorflow2015-whitepaper}, Theano \cite{theano2016}, Caffe \cite{JiaSDKLGGD14}, etc.
%
Conversely, despite the many algorithms designed for ILP, the availability of software frameworks reifying them is quite scarce, and the support for parallelisation is even scarcer.
%
Should we speculate on the motivations behind this situation, we would argue that symbolic and sub-symbolic approaches to learning have so far reached different levels of \emph{maturity}---especially, for what concerns technological readiness.

% \note{Higher flexibility of symbolic learning which learns intensional representations, yet higher maturity of sub-symbolic approaches.}

\paragraph{Efficiency}

Efficiency in learning can be measured against two major aspects, namely time and space.
%
Data (resp. computational) efficiency deals with space (resp. time), and it is related to the amount of data (resp. time) required by learning to be effective.
%
% Computational efficiency deals with time, and it is related the amount of time required by learning to be effective.
%
% In both cases,
Here, effectiveness refers to the adherence of the learned relation/function w.r.t. the available examples.

Concerning data efficiency, sub-symbolic approaches are notably data-hungry \cite{Adadi21}, as they require tons of examples to learn tasks for which a human would require just a handful.
%
Conversely, symbolic approaches are considered far more data-efficient.
%
In \cite{EvansG18}, the authors discuss this notable difference, arguing that a motivation may lay in the strong language bias imposed by choice of logic formul\ae{} as the preferred means for KR.

Concerning computational efficiency, while in theory both symbolic and sub-symbolic approaches must explore \emph{infinite} search spaces, in practice, efficiency can be improved by
%
\begin{inlinelist}
    \item sacrificing effectiveness, e.g. by leveraging on greedy algorithms, strong biases, or aggressive stopping criteria,
    \item parallelising the learning algorithm, as discussed above.
\end{inlinelist}

% \note{Data efficiency: sub-symbolic approaches usually require more data. Computational efficiency: sub-symbolic approaches can be parallelised, especially GD, eg. via GPUs. Symbolic approaches cannot}.

\paragraph{Automation and autonomy}

% \note{Similar formulation, similar issue: no silver bullet, i.e. not everthing is handled automatically}

A common trait shared by both symbolic and sub-symbolic approaches to supervised learning is their reliance on semi-automatic workflows.
%
In other words, despite the name, both approaches require a ``human in the loop'' -- namely, the data scientist -- to take care of those aspects which learning algorithms cannot autonomously deal with.
%
In the case of sub-symbolic approaches, these aspects involve the choice of hyper-parameters.
%
In the case of symbolic approaches, these aspects involve the choice of the language bias and background knowledge.
%
In both cases, these aspects involve the choice of the most adequate learning algorithm(s), other than the engineering of the representation of available data, in maximise the effectiveness the learning algorithm(s).

Within the scope of sub-symbolic learning, the problem of hyper-parameters tuning is currently addressed via a number of practices aimed at automating and speeding up their selection.
%
A summary of such practices can be found in \cite{ClaesenM15}.
%
The recent advances in the field of \emph{Automated ML} \cite{HeZC21} are building on such practices in order to further increase the degree of automation in sub-symbolic ML.
%
However, current efforts are focussing on supporting data-scientists in an end-to-end fashion, rather than letting software agents learn autonomously.

To the best of our knowledge, automating the definition of background knowledges and language biases in symbolic learning is not a major concern.
%
Should we speculate on the reasons behind this phenomenon, we would argue that both background knowledges and language biases are the preferred way to let human beings transfer their commonsense and wisdom to the learning algorithms.
%
In this sense, the creation of background knowledges and language biases is inherently poorly automatable.
%
However, background knowledges can be incrementally constructed by an agent (be it human or software) and then shared or transferred to other agents.
%
A similar argument may hold for language bias, since it may be considers as meta-level background knowledge---i.e. knowledge about how further knowledge may be constructed.

% \paragraph{Validation}

% \note{Sub-symbolic approaches care a lot about model validation as a means to assess the generalisation capabilities of a trained model. ILP model care less. Speculating on the motivation: the outcome of ILP is symbolic, therefore the human being can understand if it is correct or not. Or maybe it's simply because it has not been applied on a large scale, yet?}

\chapter{Reasoning over Knowledge}\label{chap:reasoning}

The Cambridge dictionary\footnote{\url{https://dictionary.cambridge.org/dictionary/english/reasoning}} defines \emph{reasoning} as
%
``the process of thinking about something in order to make a decision''.
%
Conversely, the Oxford dictionary\footnote{\url{https://www.oxfordlearnersdictionaries.com/definition/english/reasoning?q=reasoning}} states that reasoning is
%
``the process of thinking about things in a logical way''.
%
Notably, while both definitions agree that reasoning essentially consists in the \emph{process of thinking}, none of them actually constrains the nature of the entity enacting this process, despite thinking -- and, in particular, reasoning -- is the most characterising capability of \emph{humans}' mind.
%
This welcomes the idea that software agents may be capable of \emph{automated} reasoning as well.

Indeed, within the scope of this thesis, we consider reasoning as the activity performed by an agent (either human, or computational) whenever it draws new knowledge out of prior knowledge.
%
Of course, as for learning, the particular way knowledge is drawn heavily depends on how it is represented.

When knowledge is symbolically represented, reasoning leverages on one or more \emph{inference rules}, i.e. logic formul\ae{} dictating under which conditions conclusions may be draw out of premises.
%
This reflects the Oxford definition, where the \emph{logic} nature of reasoning is stressed.
%
Inference rules may be used, for instance, to deduce a particular case from a general rule, to induce the general rule justifying a number of observations, or to speculate on the possible causes for some phenomena, given the particular rules governing the underlying noumena.
%
Therefore, within the symbolic realm, the terms ``inference'' and ``reasoning'' are used almost interchangeably.
%
% Under such setting, when it comes
Research in this field aims at letting computational agents draw logic inferences automatically.
%
For this reason, the focus of computer scientists is on finding effective and efficient algorithms to let agents reason autonomously---i.e. with minimal human intervention.

Conversely, when knowledge is sub-symbolically represented, ``inference'' and ``reasoning'' are \emph{reduced} to the data-analytic activity of applying the models learned from previous data to novel data, in order to mine useful information.
%
Such activity is far from trivial, as it may used to perform tasks which would be prohibitively complex to express otherwise---e.g. image recognition.
%
Accordingly, the Cambridge definition is more adequate in this case: reasoning is not necessarily logic in nature, but for sure it is aimed at driving decisions---e.g. deciding whether handwritten characters is more likely a 1 or a 7, or whether an histological image should or should not raise an alarm for cancer.
%
Research in this field aims at letting sub-symbolic algorithms attain better predictive performances.
%
As such, data scientists' efforts are mostly devoted to the improvement of \emph{learning} algorithms, as inference is straightforward.
%
However, recent research efforts are being devoted to the exploitation of sub-symbolic algorithms as means for performing symbolic computations---therefore mimicking logic reasoning.

In the reminder of this chapter we delve into the details of reasoning from both a symbolic and sub-symbolic perspective.
%
In particular, we present the classic approaches and algorithms to automate logical reasoning and we introduce the theory behind the mimicking of symbolic reasoning via sub-symbolic facilities.

\section{Symbolic Reasoning}\label{sec:symbolic-reasoning}
\mypapers{logictech-information11}

Symbolic (i.e., logic-based) reasoning approaches root back to John McCarthy's work of 1958 \cite{Mccarthy1958}, aimed at developing the idea of formalising the so-called \emph{commonsense reasoning} to build intelligent artefacts---i.e. computational or cyber-physical agents endowed with human-like intelligence.
%
There, commonsense intuitively refers to the basic understanding of the physical world, its cause-effect rules, and the effects of one's actions on it, etc. \cite{Mccarthy1989}.
%
It is such an obvious capability for human beings that most of it is not even explicitly taught in schools, yet it is incredibly hard to formalise and represent for computational agents, which are therefore inherently lacking such kind of basic knowledge.

Despite the formalisation of commonsense soon proved to be very challenging -- mostly because of the many non-trivial involved issues, such as the need of formalising the situation the agent is immersed into, actions it may perform of be subject to, and physical and legal laws governing its environment and context, etc. --, many frameworks and tools have been developed over the years while pursuing such goal.
%
There are freely available commonsense knowledge bases and natural language processing toolkits, supporting practical textual-reasoning tasks on real-world documents including analogy-making, and other context oriented inferences---see for instance \cite{lieberman2004,liu2004conceptnet,liu2002goose,shapiro1999sneps}).
%
There have been also a number of attempts to construct very large knowledge bases of commonsense knowledge by hand, one of the largest being the CYC program by Douglas Lenat at CyCorp \cite{lenat1995-cyc}.

The modern approach to automated reasoning starts with Robinson's resolution principle \cite{robinson1965}: since then, several technologies have exploited \emph{deduction} on FOL knowledge bases to provide reasoning capabilities in diverse areas---logic programming, deductive data bases, and constraint logic programming (CLP) possibly being the major ones.
%
Other approaches and techniques, however, built upon the \emph{induction} and \emph{abduction} principles.

As its name suggests, \emph{deduction} operates top-down, deriving a true conclusion from a universal true premise: logically speaking, this means that the conclusion's truth necessarily follows from the premise's truth.
%
\emph{Induction}, instead, operates bottom-up, basically making a guess -- a generalization -- from specific known facts: so, the reasoning involves an element of probability, as the conclusion is not based on universal premises.
%
\emph{Abduction} is somehow similar, but seeks for cause-effect relationships---i.e., the goal is to find out under which hypotheses (or premises) a certain goal is provable.
%
Such technologies are exploited, in particular, for the verification of compliance of specific properties \cite{montali2010}.

\emph{Logic programming} (LP) is likely the most widely-adopted paradigm based on deduction.
%
From Colmerauer and Kowalsky's seminal work \cite{Kowalski1974,colmerauer1986-theoreticalProlog}, the Prolog language has been since then one of the most exploited language in AI applications \cite{Dawson1996}.
%
Other valuable approaches include \emph{fuzzy logic}, \emph{answer-set programming} (ASP), \emph{constraint logic programming} (CLP), \emph{non-monotonic reasoning}, and \emph{belief-desire-intention} (BDI).

Fuzzy logic \cite{yen1999} aims at dealing with lack of precision or uncertainty.
%
In this sense, it is perhaps closer in spirit to the human thinking than traditional logic systems.
%
Not surprisingly, fuzzy approaches are exploited as a key technology in specific application areas, e.g., the selection of manufacturing technologies \cite{goyal2012}, and industrial processes where the control via conventional methods suffers from the lack of quantitative data about I/O relations.
%
There, a fuzzy logic controller effectively synthesises an automatic control strategy from a linguistic control strategy based on an expert's knowledge.

\emph{Answer set programming} (ASP) and \emph{constraint logic programming} (CLP) are the two main logical paradigms for dealing with various classes of NP-complete combinatorial problems.
%
ASP solvers are aimed at computing the answer sets of standard logic programs; these tools can be seen as theorem provers, or model builders, enhanced with several built-in heuristics to guide the exploration of the solution space.
%
% Some of the best known solvers are Clingo \cite{gebser2014-clingo} and DLV \cite{eiter2000}.

Constraint logic programming (CLP) \cite{jaffar1987}, perhaps the most natural extension of LP (or, its most relevant generalisation), has evolved over the years into a powerful programming paradigm, widely used to model and solve hard real-life problems \cite{Rossi2000} in diverse application domains---from circuit verification to scheduling, resource allocation, timetabling, control systems, etc.
%
CLP technologies can be seen as complementary to \emph{operation research} (OR) techniques: while OR is often the only way to find the optimal solution, CLP provides generality, together with a high-level modelling environment, search control, compactness of the problem representation, constraint propagation, and fast methods to achieve a valuable solution \cite{rossi2008}.
%
% CLP tools evolved from the  ancestor -- CHIP \cite{simonis1995-chip}, the first to adopt constraint propagation -- to the constraint-handling libraries of ILOG \cite{ilog} and COSYTEC \cite{aggoun1993}, up to CLP languages such as Prolog III \cite{colmerauer1990}, Prolog IV \cite{benhamou1995}, CLP(R) \cite{jaffar1992}, and clp(fd) \cite{codognet1996}.

Non-monotonic reasoning means to face the basic objection \cite{minsky1975} that logic could not represent knowledge and commonsense reasoning as humans because the human reasoning is inherently \emph{non monotonic}---that is, consequences are not always preserved, in contrast to first-order logic.
%
Since then, a family of approaches have been developed to suit specific needs---among these, \emph{default reasoning} \cite{reiter1980}, \emph{defeasible reasoning} \cite{pollock1987}, \emph{abstract argumentation} theory \cite{bondarenko1997}.
%
Defeasible reasoning, in particular, is widely adopted in \emph{AI \& law} applications, to represent the complex intertwining of legal norms, often overlapping among each other, possibly from different, non-coherent sources.
%
Abstract argumentation theory, in its turn, is concerned with the formalisation and implementation of methods for rationally resolving disagreements, providing a general approach for modelling conflicts between arguments, and a semantics to establish if an argument can be acceptable or not.

Belief-desire-intention (BDI) logic is a kind of modal logic used for formalising, validating, and designing cognitive \emph{agents}---typically, in the \emph{multi-agent systems} (MAS) context.
%
A cognitive agent is an entity consisting of
%
\begin{inlinelist}
    \item a belief base storing the agent's \emph{beliefs}, i.e. what the agent knows about the world, itself, and other agents;
    \item a set of \emph{desires} (or goals), i.e. the proprieties of the world the agent wants to eventually become true;
    \item a \emph{plan} library, encapsulating the agent's procedural knowledge (in the form of plans) aimed at making some goals become true; and
    \item a set of \emph{intentions}, storing the states of the plans the agent is currently enacting as an attempt to satisfy some desires.
\end{inlinelist}
%
All such data usually consist of first-order formulas.
%
Then, the dynamic behaviour of a BDI agent is driven by either internal (updates to the belief-base or changes in the set of desires) or external (perceptions or messages coming from the outside) events, which may cause new intentions to be created, or current intentions to be dropped.
%
By suitably capturing the revision of beliefs, and supporting the concurrent execution of goal-oriented computations, BDI architectures overcome critical issues of ``classical'' logic-based technologies -- \emph{concurrency} and \emph{mutability} -- in a sound way.
%
Overall, BDI architecture leads to a clear and intuitive design, where the underlying BDI logic provides for the formal background.
%
Among the frameworks rooted on a BDI approach, let us mention the AgentSpeak(L) \cite{Rao96} abstract language and its major implementation, namely Jason, Structured Circuit Semantics \cite{lee1994}, Act Plan Interlingua \cite{huber1999-jam}, JACK \cite{howden2001}, and dMARS---a platform for building complex, distributed, time-critical systems in C++ \cite{dmars}.

In the reminder of this section we focus on logic programming as the most common means to endow computational agent with reasoning capabilities.
%
Before doing so, however, we recall major definitions and notations concerning logic inference as a means for manipulating knowledge.

\subsection{Symbolic Inference} % Deduction, Abduction, Induction, Probabilistic, etc.

% Inference as the operation of producing new knowledge by applying rules to knowledge base.
Within the realm of symbolic AI and, in particular, computational logic, inference is the process of mechanically producing new knowledge by applying rules to some knowledge base.
%
Such rules are commonly expressed via a particular notation, heavily leveraging on the notion of \emph{unification}.

\paragraph{Substitutions and Unification}

Unification \cite{MartelliMontanari1982} is among the most fundamental mechanism in CL: it enables the formalisation of inference, as well virtually any other symbolic manipulation of logic formul\ae{}.

Informally speaking, unification aims at computing a \emph{unifier} among any two FOL formul\ae{}, i.e. a substitution (a.k.a. assignments of variables) making the two formul\ae{} syntactically equal, by properly assigning the variables therein contained.
%
So, in other words, unification computes substitutions out of logic formul\ae{}, checking whether they can be made equal, or failing otherwise.

We denote substitutions as sets of mappings of the form $\sigma = \{ X \mapsto \phi, X' \mapsto \phi', X'' \mapsto \phi'', \ldots \}$, where $X, X', X''$ are variables, and $\phi, \phi', \phi''$ are FOL formul\ae{}.
%
Furthermore, we enumerate substitutions by $\sigma$ or $\omega$.
%
Finally, we let the binary operator $(\cdot)$ denote the application of a substitution to either a formula or another substitution.
%
So, for instance $\phi \cdot \sigma$ denotes the formula attained by applying all variable assignments carried by $\sigma$ to $\phi$.
%
Similarly, $\sigma \cdot \omega$ denotes the substitution attained by applying $\omega$ to the right-hand-side of all variable assignments in $\sigma$.

Consider for instance the case of the general clause $\phi$ and its particular case $\psi$
%
\begin{equation*}
    \begin{array}{c}
        \phi \equiv (g(X, Y) \leftarrow f(X, Z), f(Z, Y))
        \\
        \psi \equiv (g(\functor{a}, \functor{b}) \leftarrow f(\functor{a}, \functor{c}), f(\functor{c}, \functor{b}))
    \end{array}
\end{equation*}
%
The two clauses can be made syntactically equal via the substitution $\sigma = \{ X \mapsto \functor{a}, Y \mapsto \functor{b}, Z \mapsto \functor{c} \}$, because $\psi = \phi \cdot \sigma$.

Accordingly, a unifier among any two non-ground FOL formul\ae{} $\phi$ and $\psi$, is defined as a substitution $\sigma$ such that $\phi = \psi \cdot \sigma$.
%
A trivial way to recursively compute a unifier among $\phi$ and $\psi$ is as follows:
%
\begin{equation}
    \unify{\phi}{\psi} = \begin{cases}
        \varnothing & \text{if} ~ \phi = \psi = \functor{x}
        \\
        \{ X \mapsto Y \} & \text{if} ~ \phi = X \wedge \psi = Y
        \\
        \bigcup_{i}^{N} \unify{\alpha_i}{\alpha'_i} & \text{if} ~ \phi = f(\alpha_1, \ldots, \alpha_N)
        \\
        & \qquad \wedge\ \psi = f(\alpha'_1, \ldots, \alpha'_N)
        \\
        \unify{\alpha_1}{\alpha'_1} \cup \unify{\alpha_2}{\alpha'_2}  & \text{if} ~ \phi = \alpha_1 \odot \alpha_2 \wedge \psi = \alpha'_1 \odot \alpha'_2
        \\
        \square & \text{otherwise}
    \end{cases}
\end{equation}
%
where $\square$ denotes the lack of any unifier -- capturing the situation where two formul\ae{} cannot be unified -- and $\varnothing$ denotes the empty substitution -- characterising the situation where two formul\ae{} are identical.
%
There, $f$ is either a predicate or functor symbol ($N$-ary, in both cases), $\alpha_i, \alpha'_i$ are arbitrary formul\ae{}, and $\odot$ denotes any binary logical connective.

More precisely, unification aims at computing the \emph{most general} unifier (MGU), i.e. the unifier $\sigma^*$ such that, for each substitution $\sigma$ making $\phi$ and $\psi$ syntactically equal (i.e., $\phi = \psi \cdot \sigma$) there exists a substitution $\omega$ making it possible to write $\sigma$ as a particular case of $\sigma^*$ (i.e., $\sigma = \sigma^* \cdot \omega$).
%
Despite computing the MGU among any two formul\ae{} is a non-trivial problem in general, an efficient algorithm is described in \cite{MartelliMontanari1982}.
%
A formal description of this algorithm lays outside this chapter.
%
However, in what follows we denote by $\mgu{\phi}{\psi}$ the function computing the MGU among any two FOL formul\ae{}.

\paragraph{Inference Rules}

Inference rules are functions mapping premises (logic formul\ae{}) into conclusions (other logic formul\ae{}).
%
They can be denoted both as $\phi_1, \ldots, \phi_N \vdash \psi_1, \ldots, \psi_M$ or as
%
\begin{equation*}
    \frac{\phi_1, \ldots, \phi_N}{\psi_1, \ldots, \psi_M} ~ [\text{Rule name}]
\end{equation*}
%
where $\phi_1, \ldots, \phi_N$ are premises and $\psi_1, \ldots, \psi_M$ are conclusions.
%
Both expressions can be read as ``when all $\phi_1, \ldots, \phi_N$ are known to hold, then all $\psi_1, \ldots, \psi_M$ can be inferred''.

The notation if often abused by only including among the premises those formul\ae{} which are strictly needed to draw conclusions.
%
When this is the case, a knowledge base $\mathbf{K}$ is then assumed, behind the scenes.
%
Thus, rules of the form $\phi \vdash \psi$ are usually written as concise notation for $\exists \sigma$ s.t. $\phi \cdot \sigma \in \mathbf{K} \vdash \psi \cdot \sigma$.

A plethora of inference rules have been defined in the history of logic.
%
Here we focus on four major examples, corresponding to as many inference principles, namely:
%
\begin{equation*}
    \frac{\alpha \rightarrow \beta, \alpha}{\beta} ~ [\text{Modus Ponens}]
    \qquad
    \frac{\phi\cdot\sigma_1, \ldots, \phi\cdot\sigma_n}{\phi} ~ [\text{Subsumption}]
\end{equation*}
\begin{equation*}
    \frac{\alpha \rightarrow \beta, \lnot\beta}{\lnot\alpha} ~ [\text{Modus Tollens}]
    \qquad
    \frac{\alpha \rightarrow \beta, \beta}{\alpha} ~ [\text{Abduction}]
\end{equation*}

Modus ponens (resp. tollens) is a \emph{deductive} inference rule, stating that whenever one knows that $\alpha$ implies $\beta$ and $\alpha$ is true (resp. $\beta$ is false), then they can infer $\beta$ (resp. $\lnot\alpha$).
%
As a deductive rule, it simply elicits particular consequences which are implicit into the general premises, and therefore certain.
%
It is for instance by modus ponens that one can infer $grand\-pa\-rent(\functor{abraham}, \functor{jacob})$ from a knowledge base containing the clauses $grand\-pa\-rent(X, Y) \leftarrow parent(X, Z), parent(Z, Y)$, $parent(\functor{abraham}, \functor{isaac})$, and $pa\-rent(\functor{isa\-ac}, \functor{ja\-cob})$.

Subsumption is an \emph{inductive} inference rule, stating that if a number of particular expressions share the same form, than that form can be raised to general knowledge.
%
As an inductive rule, it attempts to derive novel hypotheses out of prior experience, therefore producing uncertain conclusions that may be eventually contradicted by some later experience.
%
It is for instance by subsumption that one can hypothesise how a general rule for grandparenthood works (i.e. $grand\-pa\-rent(X, Y) \leftarrow parent(X, Z), parent(Z, Y)$) if they only know about a number of parenthood and grandparenthood relations---namely $parent(\functor{abraham}, \functor{isaac})$, $parent(\functor{isaac}, \functor{jacob})$, and $grandparent(\functor{abraham}, \functor{jacob})$.

Finally, abduction is an \emph{abductive} inference rule, stating that if one knows how a particular cause--effect phenomenon works, and they observe the effect, then they can infer the cause.
%
Similarly to induction, abduction produces uncertain -- yet likely -- conclusions out of prior experience and some basic knowledge about the world.
%
It is for instance by abduction that one can hypothesise that it is raining ($rain$) after observing that the floor is wet ($wet\_floor$) knowing that the flow may be wet because of either the rain or a broken glass ($\{ wet\_floor \leftarrow rain, wet\_floor \leftarrow broken\_glass \}$).

Notice that only deductive rules lead to certainly correct conclusions, whereas inductive and deductive rules do not.
%
Accordingly, Bayesian inference may be better suited to represent inductive or abductive inference -- as it let us infer not only hypotheses but their likelihood as well --, yet it requires trepassing the sub-symbolic realm---as probabilities must be explicitly represented.

\paragraph{Inference Procedures}

Inference rules alone are able to express reasoning, but they are not enough to let computational draw inferences autonomously.
%
When dealing with inference, computational agents need an inference \emph{procedure}, i.e. an algorithm applying one or more inference rules to a knowledge base, in such a way that conclusions are eventually reached when the algorithm terminates.

In practice, inference procedures should support the efficient and effective computation of correct conclusions.
%
Within this scope, ``efficiently'' means ``in useful time'', whereas ``effectively'' refers to notable properties such \emph{soundness} and \emph{completeness}.
%
There, a \emph{sound} procedure ensures that all output conclusions are correct, whereas a \emph{complete} procedure ensures that (at least) all correct conclusions are drawn.
%
Notably, these properties can -- and usually are -- satisfied by algorithms supporting \emph{deductive} inference procedures, whereas they are out of reach for inductive or abductive algorithms (because of uncertainty).

Another common way of categorising inference procedures is w.r.t. the \emph{verse} they follow in applying inference rules.
%
Two strategies may be followed by inference procedures, namely either \emph{forward} or \emph{backward}-chaining.

In forward-chaining, inference rules are naturally applied from premises to conclusions, in top-down fashion.
%
The starting point is commonly a knowledge base, and, as a result, many possible conclusions are drawn---possibly even more than needed.

Conversely, in backward-chaining, inference rules are reversely applied from conclusion to premises in order to prove a particular \emph{goal}.
%
So, inference proceeds in a bottom-up fashion, attempting to reach the knowledge base from the goal.
%
Under such setting, inference rules should be read in the opposite way.
%
For instance, modus ponens should be read as ``to infer $\beta$, knowing that $\alpha \rightarrow \beta$, one should prove $\alpha$ first''.

In the reminder of this section, we briefly overview the field of logic programming, where logic and computational aspects are deeply intertwined to endow computational agents with actual automated reasoning capabilities.

\subsection{Logic Programming}

% \cite{logictech-information11}
% \cite{lptech4mas-aamas2021}
% \cite{lptech4mas-jaamas35}
% \cite{Korner2020HistoryFuturePrologTPLP}

Logic programming (LP) is computational paradigm where logic is used to represent both data and programs, and inference is used to perform computations.
%
From a human-centred perspective, LP is a means for programming computers to perform symbolic AI related tasks.
%
However, from a agent-oriented perspective, LP is the means to endow software agents with automated reasoning capabilities.

There are a few peculiar milestones in the history of LP.
%
These are
%
\begin{inlinelist}
    \item Robinson's proposal of the selective linear (SL) resolution principle \cite{robinson1965} for FOL,
    \item Kowalsky's proposal of the selective linear \emph{definite} (SLD) resolution principle \cite{Kowalski1976} for Horn clauses,
    \item Colmerauer's proposal of Prolog \cite{ColmerauerR93},
    \item Clark's proposal of negation as failure (NaF) \cite{Clark77} as an extension to the SLD  principle.
\end{inlinelist}

\paragraph{Robinson's selective linear resolution principle}

The SL resolution principle \cite{robinson1965} is a general procedure for proving a set of FOL formul\ae{} in Skolemized form\footnotemark{} true, by \emph{refutation}.
%
More precisely, the SL procedure aims at proving a set of clauses as contradictory, by attempting to derive the empty clause $\bot$ (denoting contradiction) out of it via a number of reduction steps.
%
Thus, in practice, proving a formula $\phi$ true is achieved by proving $\lnot\phi$ as false---i.e. by refuting it.
%
The basic inference rule operating in this context states that, in a set of Skolemized formul\ae{} $\mathbf{K}$ including $\phi$ and $\psi$, those formul\ae{} may be reduced $\phi'$ and $\psi'$, under the following condition:
%
\begin{equation*}
    \frac{x \in \phi \quad \lnot y \in \psi \quad \sigma = \mgu{x}{y}}{\phi' = (\phi - x)\cdot\sigma \quad \psi' = (\psi - \lnot y)\cdot\sigma}[\text{SL}]
\end{equation*}
%
where $x$ and $y$ are literals possibly contained into $\phi$ and $\psi$, and operator $(-)$ denotes the eviction of a literal from a formula.
%
In other words, if any two formul\ae{} in $\mathbf{K}$ respectively include two literals, $x$ and $y$, which can be unified by $\sigma$ and such that \emph{only} one is negated, then the two literals are evicted from the corresponding formul\ae{}, and the substitution $\sigma$ is be applied to the reminder of those formul\ae{}.
%
If the repeated application of this rule leads to a situation where a formula has no more literals, the original set of formul\ae{} $\mathbf{K}$ is proved to be false, as it contains an unsatisfiable (i.e. contradictory) formula---namely, the one that has been emptied by the SL procedure.
%
Otherwise, if no further reduction is possible, $\mathbf{K}$ is proved to \emph{satisfiable}.

\footnotetext{\url{cf. https://mathworld.wolfram.com/SkolemizedForm.html}}

Backward-chaining can be performed via SL.
%
This implies a goal $\gamma$ can be proved against a knowledge base $\mathbf{K}$ .
%
When this is the case, proof by refutation if applied to the set $\lnot\gamma \cup \mathbf{K}$: at each step, some literal of $\lnot\gamma$ is reduced, along with some other formula in $\textbf{K}$.
%
Upon termination, if all literals of $\lnot\gamma$ have been evicted, then $\lnot\gamma$ is considered unsatisfiable, therefore $\gamma$ is provable, and the formula $\gamma \cdot \sigma_1 \cdot \sigma_2 \cdots$ -- attained by applying all the MGU computed at each reduction step -- represents a \emph{solution} for $\gamma$, according to $\mathbf{K}$.

The whole process subtends the so-called \emph{proof tree}: at each step of the procedure, several formual\ae{} may be selected from $\mathbf{K}$, therefore the algorithm may follow as many different paths.
%
In other words, the SL resolution is a \emph{non-deterministic} algorithm.
%
Details and examples are provided for instance in \cite{CureRdf2015}.

\paragraph{Kowalsky's selective linear definite resolution principle}

The SLD resolution principle \cite{Kowalski1976} is a refinement of the SL principle, tailored on Horn clauses.
%
By restricting the scope of resolution to Horn logic, Kowalsky shows how logic resolution can be described via a \emph{procedural} interpretation, mimicking programs execution.
%
The result is a non-deterministic algorithm describing how the proof tree of any given query -- expressed as a goal -- against any given knowledge base -- expressed as a set of definite clauses -- can be \emph{lazily} constructed, while attempting to refute the query.

The basic inference rule operating in this contexts states that any goal $\gamma$ can be rewritten as $\gamma'$, provided that some definite clause $\phi$ exists in the knowledge base whose head unifies with some literal in $\gamma$.
%
When this is the case, the matching literal of $\gamma$ is replaced by the body of $\phi$---or simply removed in case $\phi$ is a fact.
%
More formally:
%
\begin{equation*}
    \frac{
        \gamma \equiv (\leftarrow g_1, \ldots, g_i, \ldots, g_n)
        \qquad
        \phi \equiv (h \leftarrow b_1, \ldots, b_m)
        \qquad
        \sigma = \mgu{g_i}{h}
    }{
        \gamma' \equiv (\leftarrow g_1, \ldots, g_{i-1}, b_1, \ldots, b_m, g_{i+1}, \ldots, g_n) \cdot \sigma
    }[\text{SLD}]
\end{equation*}
%
The recursive application of this rule is what enables automated reasoning.
%
Similarly to the SL case, if $\gamma$ can be emptied via a number of successive applications of the inference rule, then it is considered proven by refutation.

The relation among SL and SLD becomes quite evident if one writes clauses in disjunctive form.
%
Under such perspective, $\gamma$ is written as a disjunctive of negated literals $\lnot g_1 \vee \ldots \vee \lnot g_n$, as well as each rule $\phi \equiv (h \vee \lnot b_1 \vee \ldots \vee \lnot b_m)$.
%
Therefore, whenever applying the SL inference rule to any literal in $\gamma$, one can only choose among the heads of each rule, as all literals in $\gamma$ are negated and all heads of all rules are positive.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/proof-tree.png}
    \caption{An example of proof tree generated by the SLD resolution principle while attempting to prove the goal $son(S, \functor{jacob})$ against the depicted knowledge base. }
    \label{fig:proof-tree}
\end{figure}

\Cref{fig:proof-tree} exemplifies the proof tree generated by the recursive application of SLD inference rule to the goal $son(S, \functor{jacob})$.
%
The resolution attempts to prove the goal against a knowledge base describing Abraham's family tree, represented in the same image.
%
Each node in the tree represents a rewritten form of the original goal, whereas each arc subtends the selection of a rule from the knowledge base and a literal from the source node: the label of each edge describes their MGU.

Of course, at each step of the SLD resolution, several choices may be taken.
%
For instance, several literals may be selected, and each literal may unify with potentially many rules in the knowledge base.
%
The theoretical formulation of the SLD principle addresses such choices via \emph{non-determinism}.
%
However, whenever an actual computational agent needs to perform automated reasoning, it must leverage upon some smart strategy to explore the proof tree sequentially, and in useful time.

\paragraph{Colmerauer's Prolog}

Prolog \cite{ColmerauerR93} is the most successful expression of the LP paradigm.
%
It is at the same time a particular way of expressing logic resolution, and a very powerful technology to perform automated reasoning in practice.
%
Here we focus on the theoretical aspects of Prolog, whereas technological aspects are treated later in this thesis.

Prolog is essentially a particular way to make the exploration of the proof tree subtended by the SLD resolution principle \emph{sequential}.
%
In other words, Prolog makes the SLD resolution a sequential algorithm.
%
More precisely, Prolog assumes goals to be \emph{ordered} disjunctions of literals (left to right), and knowledge bases to be \emph{ordered} sets of definite clauses (top to bottom).
%
Under such assumption, it adopts the following strategy while dealing with the non-determinism of SLD resolution:
%
\begin{itemize}
    \item literals in the current goal are reduced from left to right,
    \item rules are selected from top to bottom.
\end{itemize}
%
This strategy subtends a \emph{depth-first} exploration of the proof tree.

Another relevant modelling choice in Prolog concerns the syntax for predicates and terms.
%
In fact, Prolog represents predicates and structured terms in the same way, collapsing their syntaxes and making the two notions interchangeable.
%
This simplifies the definition of meta-predicates -- i.e. predicates accepting other predicates as arguments --, as terms can be used to represent predicates.
%
Meta-predicates, in turn, make Prolog's semantics very flexible, as disjunctions, implications, negations, and many other features of FOL which are not supported by Horn clauses can be re-introduced in Prolog in this way.

\paragraph{Clark's Negation as Failure}

NaF \cite{Clark77} is the last relevant extension of SLD we discuss in this section.
%
It essentially aims at supporting negation in Horn clauses.
%
SLD resolution extended with NaF is often concisely referred to as SLDNF.

SLDNF supports negation by defining the meta-predicate $not(g)$ which is proven true if and only if the argument goal $g$ is proven unsatisfiable.
%
So, in procedural terms, the goal $not(g)$ can be read as ``attempt to prove $g$, and, if no solution exists, then $not(g)$ is true, false otherwise''.

Notably, NaF subtends a \emph{closed} world assumption, where everything that is not know -- nor deducible from what is known -- is false.

\section{Sub-symbolic Reasoning}
%
\mypapers{xaisurvey-ia14}

Within the sub-symbolic realm, the term `inference' is often abused.
%
There, `inference' refers to the application phase of any data-driven solution which has been previously trained on data.
%
Therefore, inference in simply a phase in the life-cycle of a data-driven model, as opposed to training.

In the inference phase of any sub-symbolic system, novel information is actually drawn, and that information strongly depends on what the systems has learned from data (prior knowledge) during training.
%
For instance, classifiers enable the labelling of arbitrarily complex unknown data according to some predefined set of labels.
%
Similarly, regressors enable predictions on unknown data, out of prior experience.
%
So, in a broad sense, sub-symbolic systems support the inference of novel, useful information.
%
By definition, however, no symbolic manipulation of data occurs in sub-symbolic systems, regardless of whether training or inference are considered.
%
Hence, it is cumbersome speaking of reasoning.

Nevertheless, a number of recent proposals are pushing relevant aspects of logic inference into the sub-symbolic realm.
%
As a result, methods for building \emph{hybrid} systems -- i.e. systems mixing symbolic and sub-symbolic means to represent, learn, or infer -- are flourishing.

Generally speaking, hybridisation may occur in two ways, namely by \emph{model integration} or by \emph{symbolic knowledge embedding}.
%
In the former case, symbolic information is used to \emph{structure} or \emph{constrain} the behaviour of a sub-symbolic system---in most cases, a neural network, because of its malleability.
%
In the latter case, symbolic information is \emph{embedded} into a sub-symbolic representation to enable its sub-symbolic processing.

\subsection{Model Integration}\label{ssec:model-integration}

In this category we review the main attempts to \emph{integrate} symbolic models (such as the logic ones) with sub-symbolic ones (such as statistical and numerical).
%
The main research lines here are those related to the neural-symbolic computing \cite{Hammer2007-neuralsymbolic}  -- the study of logics and connectionism as well as statistical approaches working on the integration of computational learning and symbolic reasoning -- and relational learning \cite{deRaedt2008-logicalRL}---focused on learning expressive logic / relational representations.

Approaches in this category integrate logic and symbolic knowledge with sub-symbolic predictors such as (deep) neural networks.
%
Integration exploits logic rules expressed via FOL -- or some subset of it -- which are used to either constrain or structure the behaviour of one or more predictors.

On the one hand, constraining is commonly performed by extending the loss function used by most numeric learning algorithms -- there including the back-propagation algorithm used for neural networks -- with an additive, regularisation term constructed from the logic constraints.
%
The numeric predictor is then trained ``as usual'', via optimisation---i.e. minimising some loss function.
%
However, thanks to a \emph{regularisation} term attained by encoding the logic rules accordingly, the training process is more likely to select a set of parameters for the numeric predictor, which are consistent with those logic rules.
%
Generally speaking, the key advantage of these approaches lies in the blended integration of different models, where the logic one -- where expressing crisp information is trivial -- can be used to inject prior knowledge or common-sense into the sub-symbolic one, even in lack of data.

On the other hand, structuring is commonly performed by building the sub-symbolic predictors in such a way that their internal structure mirrors the provided symbolic knowledge.
%
For this reason, malleable models such as neural networks are often preferred to serve this purpose.
%
There, the internal topology of neurons, as well as their activation functions, are structured in such a way to mimic some relevant property of given logic rules---such as their interpretation.
%
Computation is then shifted into the sub-symbolic realm, since the so-constructed predictors act ordinarily.
%
Generally speaking, the key advantage of these approaches sub-symbolic emulation of symbolic facilities, thus allowing efficiency of reasoning in particular cases -- at the price of constraining it scope of application --, and robustness w.r.t. missing or contradictory data.

\paragraph{Logic as constraints}

Paradigmatic works in this category are for instance: DNN with Logic Rules \cite{hu2016}, Logic Tensor Networks (LTN) \cite{serafini2016,Serafini2017}, Semantic Loss Function (SLF) \cite{xu2018}, and Lyrics \cite{marra2019lyrics}.

DNN with Logic Rules (no concise name is given) \cite{hu2016}, proposes a method for constraining a (deep) neural network behaviour via FOL rules.
%
The proposed framework enables neural networks to be simultaneously trained on labelled data or logic rules, via an iterative distillation procedure aimed at transferring the symbolic knowledge encoded in the logic rules into the network parameters.
%
To do so, the authors propose the exploitation of two networks: a \emph{teacher} and a \emph{student} one.
%
The teacher network is rule-regularised via an \emph{ad-hoc} term added to the loss function, meaning that it is trained by keeping into account the user-provided logic rules.
%
In particular, logic constraints are encoded into the loss function via soft logic \cite{BachBHG17}.
%
Conversely, the student network is trained to balance between emulating the teacher network output and predicting the expected outcomes of the dataset.

LTN \cite{serafini2016,Serafini2017} integrate learning based on tensor networks \cite{socher2013} with reasoning based first-order many-valued logic \cite{bergmann2008}.
%
They enable a range of knowledge-based tasks using rich knowledge representation in FOL to be combined with efficient data-driven machine learning based on the manipulation of real-valued vectors.
%
% Given data available in the form of real-valued vectors, logic soft and hard constraints, and relations that apply to certain subsets of the vectors can be specified in a compact way using FOL.
% %
% Reasoning about the constraints can help improve learning, and, viceversa, learning from new data can revise the constraints thus affecting the reasoning task.
%
Notably, integration is defined upon the Real Logic \cite{Serafini2017}.
%
FOL formul\ae{} are used to build a loss function that aims at training a network capable of approximating the truth value (in the $[0,1]$ interval) of the formul\ae{} given as input.
%
This is done by searching for the best possible representation for symbolic constructs in a vector space (grounding of atoms, functions, predicates), so that the satisfiability of the network is as close as possible to 1 on the test dataset.
%
The resulting network is able to learning from the rightly-labelled real examples, but keeps the logic imprint given in the training phase.

SLF \cite{xu2018} is another attempt of bridging neural networks and symbolic constraints via loss-function manipulation, similarly to LTN.
%
In the intentions of its authors, it aims to
%
\begin{itemize}
    \item improve the predictive performance of neural networks -- by allowing the training process to take background knowledge into account --, and
    \item support semi-supervised learning.
\end{itemize}
%
To do so, SLF constrains the training process of a neural network via some \emph{propositional} logic formul\ae{} which are then encoded as part the loss function exploited by the training algorithm.
%
Such formul\ae{} consist of boolean variables representing input and output neurons of the networks to be constrained, possibly combined via classical logic connectors.

Finally, Lyrics \cite{marra2019lyrics} is an extension of LTN, improving the way symbolic knowledge is declaratively enforced while training the sub-symbolic part of an intelligent system.
%
According to the authors, the major applications of Lyrics are related to predictive model verification, semi-supervised learning with background knowledge, collective classification \cite{SenNBGGE08}, and text chunking.
%
Similarly to LTN, Lyrics can combine one or more neural networks into a single computational graph.
%
Each neural network is mapped onto a logic predicate, when necessary, while (possibly global) constrains over the outcomes of the networks are mapped into logic formul\ae{}.
%
The resulting computational graph is then optimised against the available data via state-of-the-art gradient-descent technologies---e.g. TensorFlow.

\paragraph{Logic as structure}

Paradigmatic works in this category are for instance: Knowledge-Based Artificial Neural Networks (KBANN) \cite{Towell1990}, CILP++ \cite{Franca2014}, Neural Theorem Prover (NTP) \cite{rocktaschel2017}, Differentiable Inductive Logic Programming ($\partial$ILP) \cite{Evans2017}, DeepProbLog \cite{Manhaeve2018}, and Lifted Relational Neural Networks (LRNN) \cite{SourekAZSK18}.

KBANN \cite{Towell1990} is one of the earliest attempts of exploiting symbolic AI to govern the structure and the behaviour of neural networks.
%
It is capable of devising the structure of a neural network from a symbolic knowledge base containing the user-defined, symbolic background knowledge.
%
More precisely, KBANN assumes a stratified, Prolog-like, logic theory is available, encoding the background knowledge.
%
Under this assumption, the KBANN algorithm aims at creating a neural network semantically reflecting the symbolic knowledge from which it was created.
%
This step essentially sets the network structure and weights in order to reflect the rules contained into the logic theory.
%
The resulting neural network can then be trained over data via back-propagation, in order to refine or generalise its functioning over (possibly novel) data.
%
% According to the authors, the KBANN algorithm has proven to be useful in the area of molecular biology.
%
% In particular, neural networks attained via KBANN has been used to detect promoters in strings of nucleotides, with superior performance w.r.t. randomly initialised neural networks or other sorts of numeric predictors.

CILP++ \cite{Franca2014} is a model aimed at performing inductive logic programming (ILP) via bottom clause propositionalisation and neural networks.
%
CILP++ leverages on
%
\begin{inlinelist}
    \item neural networks to make ILP faster, and on
    \item propositionalisation to make the construction of neural networks out of arbitrary logic theories possible.
\end{inlinelist}
%
More precisely, propositionalisation \cite{Lachiche2010} is a preliminary step, which is necessary to convert the example clauses into real vectors and the background knowledge into a multi-layered neural network to be fed with those vectors.
%
Of course, the structure of this network reflects the rules contained in the background knowledge, and the input layer contains a neuron for each possible atom used in the background knowledge.

NTP \cite{rocktaschel2017} are neural networks acting as logic reasoners (a.k.a. theorem provers).
%
They are built by taking inspiration from backward-chaining-based reasoning algorithms, as in Prolog.
%
In particular, the neural network is recursively constructed to encapsulate the knowledge encoded in some logic theory, and trained to correctly answer to all possible queries on such theory.
%
Of course, the structure of the resulting network reflects the structure of the clauses contained into the source logic theory.
%
However, differently from the other techniques presented in this sub-category, both theories and queries supported by NTP can contain logic variables, as NTP is able to calculate, at the neural network level -- i.e., in the sub-symbolic model --, the logic unification.
%
In other words, NTP perform symbolic reasoning on top of sub-symbolic and distributed representations of knowledge.

$\partial$ILP \cite{Evans2017} is another means for ILP  leveraging on neural networks.
%
It works by mimicking logic deduction on definite clauses via a neural network, similarly to NTP.
%
However, differently from NTP, $\partial$ILP perform deduction using forward chaining, instead of backward chaining.
%
Briefly speaking, the authors re-interpret ILP as a binary-classification problem.
%
As for other similar approaches discussed in this category, a neural network is constructed in such a way that its structure reflects a grounded version of the background knowledge.
%
The resulting network is then trained to minimise the cross-entropy with respect to positive and negative examples.

DeepProbLog \cite{Manhaeve2018} is another attempt of blending neural networks with logic programming, and in particular \emph{probabilistic} logic programming (PLP).
%
It is an extension of ProbLog exploiting neural networks for
%
\begin{inlinelist}
    \item computing the probabilities of facts, and
    \item letting neural classifiers be used as logic predicates---defined as ``neural predicates'' by the authors.
\end{inlinelist}
%
In particular, each DeepProbLog program is translated into a tensorial computational graph -- possibly including one ore more neural classifiers as sub-graphs -- to be optimised via gradient descend.
%
The structure of the computational graph reflects the structure of the rules contained into the DeepProbLog program.
%
The optimisation step is aimed at simultaneously setting all the possible parameters regulating the behaviour of the computational graph, including the probabilities of facts and the internal weights of neural predicates.
%
The resulting sub-symbolic system is then exploited to draw probabilistic inferences.
%
In other words, hybrid systems based on DeepProbLog fruitfully combine probabilistic reasoning and sub-symbolic classification in a single, unified, coherent framework.

Finally, LRNN \cite{SourekAZSK18} aim at performing relational learning from data via neural networks.
%
Similarly to DeepProbLog, LRNN exploit sets of weighted first-order formul\ae{} as structural templates for building a neural network to be trained over the available data.
%
The resulting network is exploited to infer latent rules buried in data and to estimate the weights of the existing clauses.

\subsection{Symbolic Knowledge Embedding}

In this category we review the main attempts to \emph{embed} symbolic (and, in particular, logic) knowledge into arrays of numbers, to make them amenable of sub-symbolic processing.

Most techniques developed so far are tailored on \emph{description logics}, that are particular sub-sets of FOL generally aimed at describing categories of entities and their possible relations, along with instances of both.
%
The key idea is to translate components of an ontology (a.k.a.\ knowledge graph, or simply KG) into continuous vector spaces, to allow neural networks to accept such a type of structured information as input and take advantage of its background knowledge to perform ordinary machine learning tasks.

Most of the currently-available techniques perform the embedding task only on the basis of observed facts.
%
Given a KG, knowledge graph injection techniques first represent entities and relations in a continuous vector space, and then measure facts plausibility exploiting some scoring function.
%
Entity and relation embeddings can be obtained by maximising the total plausibility of observed facts.

During this whole procedure, the learned embeddings are only required to be compatible within each individual fact, and hence might not be predictive enough for downstream tasks \cite{wang2015,wei2015}.
%
As a result, more and more researchers have started to add other types of information, including logic rules \cite{wang2015,rocktaschel2015,guo2016}, in order to learn more predictive embeddings.

The noteworthy approaches that we deem significant for the purpose of this survey -- as they combine symbolic and sub-symbolic models -- are:
%
\begin{itemize}
	\item \textsc{Rescal} + \textsc{Trescal} (2015) \cite{wang2015}
	\item \textsc{Ins} (2015) \cite{wei2015}
	\item Low-rank Logic Embeddings, LLE (2015) \cite{rocktaschel2015}
	\item \textsc{Kale} (2016) \cite{guo2016}
	\item \textsc{Oscar} (2019) \cite{goodwin2019}
\end{itemize}
%
In particular, \cite{wang2015,wei2015} exploit rules to refine embedding models aimed at KG completion.
%
KG completion is formulated as an integer linear programming problem, where the objective function is generated from embedding models and constraints are generated from rules.
%
Facts inferred in this way are the most preferred by the embedding models and comply with all the rules.
%
By incorporating rules, these approaches can greatly reduce the solution space and significantly improve the inference accuracy of embedding models.
%
\textsc{Trescal} \cite{wang2015} is an extension of \textsc{Rescal}, requiring the arguments of a relation to be entities of certain specified types.

Along this line, other works -- e.g., \cite{rocktaschel2015,guo2016} -- propose approaches that embed KG facts and logic rules simultaneously in a unified framework.
%
In particular, in \textsc{Ins}, formul\ae{} are injected into the embeddings of relations and entity-pairs, i.e., the embeddings are estimated such that predictions based on them conform to given logic formul\ae.
%
\textsc{Kale}, on the other side, represents rules as complex formul\ae{} modelled by t-norm fuzzy logics.
%
Embedding then amounts to minimising a global loss over both atomic and complex formulae.
%
Thus embeddings are learnt as compatible with rules.

In \cite{goodwin2019} the authors propose a method, \textsc{Oscar}, for injecting task-agnostic knowledge from a KG into a neural network during the training.
%
\textsc{Oscar} is a pre-training regularisation technique capable of injecting world knowledge and ontological relationships into a deep neural network: the expert knowledge is exploited as a regulariser for the network.

It is worth noting that in all these approaches rules are modelled separately from embedding models, serving as post-processing steps: this is why we classify these work as combination and not integration.
%
Furthermore, all these works share a common drawback, in that they have to instantiate universally-quantified rules into ground rules before learning their models.
%
This is called grounding procedure, and can be time- and space-inefficient---especially when dealing with big data scenarios or in case of rules complexity.

\subsection{Hybrid Systems: Final Remarks}

Hybrid systems are still in their infancy.
%
Hybridisation usually comes at the cost of a reduced expressiveness of the logic formalism adopted.
%
Empirically, we observe that full fledged FOL is too complex to handle for sub-symbolic systems, which are therefore forced to take countermeasures into account.
%
Once again, issues concern KR.
%
In particular, \emph{intensional} logic representations as well as the flexibility of logic -- which is open to the addition of novel symbols --, are what makes hybridisation difficult.

Countermeasures generally involve using a sub-sets of FOL -- thus renouncing to the full expressiveness of FOL --, and enforcing knowledge to be extensively represented.

In the former case, constraints are imposed at the KR level.
%
These may involve
%
\begin{inlinelist}
    \item forbidding structured terms,
    \item limiting the shape of predicates or clauses,
    \item focussing on simpler logics such as Horn logic, description logics, or predicate logic,
    \item or a combination of these constraints.
\end{inlinelist}\
%
In all such cases, the scope of the hybrid system is reduced, w.r.t. a full-fledged symbolic system.
%
Consider for instance the case of Horn logic with no structured terms.
%
This would imply, for instance, that lists could not be used in the symbolic part of the system---hence greatly reducing the practical reach of hybrid systems.

In the latter case, \emph{grounding} of the knowledge base is usually assumed as a preliminary step before any sub-symbolic processing.
%
In the general case, grounding a non-ground knowledge base involves enumerating all the possible variable assignments of for all variables of all formul\ae{} therein contained.
%
Variable assignments may in turn be infinite, depending on how may items the underlying Herbrand universe contains.
%
Of course, grounding is only possible in practice when the amount of items in the Herbrand universe -- and therefore the amount of admissible variable assignments --, is \emph{finite}.
%
Notably, by admitting structured terms for KR, the Herbrand universe will certainly be infinite (cf. \cref{par:herbrand})---hence why leveraging on grounding usually subtends forbidding (at least) structured terms from the KR formalism.

\chapter{Explaining AI via Symbolic Knowledge}\label{chap:explaining}

% Despite the open philosophical issues, i
It is undeniable that AI and ML are nowadays becoming more and more intertwined with a growing number of aspects of people's every day life \cite{helbing2019, elliott2019}.
%
In fact, more and more decisions are delegated by humans to software agents whose intelligent behaviour is not the result of some skilled developer endowing them with some clever code, but rather the consequence the agents' capability of learning, planning, or inferring what to do from data.

In spite of the large adoption, intelligent machines whose behaviour is the result of automatic synthesis / learning procedures are difficult to trust for most people---in particular when they are not expert in the field.
%
This is especially true for agents leveraging on machine or deep learning based techniques, often producing models whose internal behaviour is opaque and hard to explain for their developers too.

There, agents often tend to accumulate their knowledge into \emph{black-box} predictive models which are trained through ML or DL.
%
As we further discuss in this paper, ``black boxes'' are models where knowledge is \emph{sub-symbolically} represented -- such as NN, support vector machines (SVM), or random forests --, and it is therefore difficult, for humans, to understand what they actually know, or what led them to a particular decision.

Such difficulty in understanding black-boxes content and functioning is what prevents people from fully trusting -- and thus accepting -- them.
%
In several contexts, such as the medical or financial ones, it is not sufficient for intelligent agents to output bare decisions, since, for instance, ethical and legal issues may arise.
%
An \emph{explanation} for each decision is therefore often desirable, preferable, or even required.
%
Furthermore, it may happen for instance that black-boxes \emph{silently} learn something wrong (e.g., Google image recognition software that classified black people as gorillas \cite{fourcade2017, crawford2016artificial}), or something right, but in a biased way (like  the ``background bias'' problem, causing for instance husky images to be recognised only because of their snowy background \cite{RibeiroSG16}).

% To tackle such trust issues, the \emph{eXplainable Artificial Intelligence} (XAI) research field has recently emerged, and a comprehensive research road map has been proposed by DARPA \cite{darpa2016-xai}, targeting the themes of explainability and interpretability in AI -- and in particular ML -- as a challenge of paramount importance in a world where AI is becoming more and more pervasively adopted.
% %
% There, DARPA reviews the main approaches to make AI either more interpretable or \emph{a posteriori} explainable, it categorises the many currently available techniques aimed at building meaningful interpretations or explanations for black-box models, it summarises the open problems and challenges, and it provides a reference framework for the researchers interested in the field.

% Broadly speaking, research efforts in the field of XAI are focused on achieving key properties in AI, such as \emph{interpretability}, \emph{transparency}, \emph{explainability}, \emph{accountability}, and \emph{trustworthiness}.
% %
% Unfortunately, such goals are still far from being reached.
% %
% For instance, as pointed out in \cite{Lipton18}, the aforementioned properties are still lacking a formal and agreed-upon definition.
% %
% Some authors \cite{Rudin2019} propose to strengthen the adoption of most \emph{interpretable} (i.e. algorithmically transparent) predictive models -- such as generalised linear models or decision trees --, while others seek new ways to produce \emph{post-hoc} explanations capable of tackling even most opaque predictors, such as NN.
% %
% However, as demonstrated by the comprehensive survey produced by Guidotti et al. \cite{GuidottiMRTGP19}, most works only target classification problems, and they rarely take wider properties -- such as accountability and trustworthiness -- into account.

% \sidenote{Spostare il capoverso sotto in un posto più opportuno}
% Several works, among the various springs of AI, proposed to extract symbolic knowledge from sub-symbolic models.
% %
% As witnessed by a number of surveys \cite{GuidottiMRTGP19, GarcezBRFHIKLMS15, AndrewsDT95, GarcezBG01} and works on the topic \cite{BolognaH18, BolognaH16, FrosstH17, JohanssonN09, KrishnanSB1999, HruschkaE2006, ZhouZYS1983, CravenS95, AugastaK12, SatoT2002, KahramanliA09a} -- some of which are from the 80s or the 90s -- the potential of symbolic knowledge \emph{extraction} is well understood, despite not being subject to hype.
% %
% Unfortunately, a comprehensive and general framework tackling such problem in a general way is still missing.

% \note{Armonizzare quanto segue con ciò che precede}

% Since the adoption of interpretable predictors usually comes at cost of a lower potential in terms of predictive performance, \emph{explanations} are the newly preferred way for providing understandable predictions without necessarily sacrificing accuracy.
% %
% The idea, and the main goal of XAI is to create intelligible and understandable explanations for uninterpretable predictors \emph{without} replacing or modifying them.
% %
% Thus explanations are built through a number of heterogeneous techniques, broadly referred to as \emph{explanators} \cite{GuidottiMRTGP19}---just to cite some, \emph{decision rules} \cite{Augasta2012}, \emph{feature importance} \cite{tolomei2017interpretable}, saliency masks \cite{FongV17}, sensitivity analysis \cite{SundararajanTY17}, etc.

% The state of the art for explainability currently recognises two main sorts of explanators, namely, either local or global.
% %
% While \emph{local} explanators attempt to provide an explanation for each particular prediction of a given predictor $p$, the \emph{global} ones attempt to provide an explanation for the predictor $p$ as a whole.
% %
% In other words, local explanators provide an answer to the question ``why does $p$ predict $\mathbf{y}$ for the input $\mathbf{x}$?'' -- such as the LIME technique presented in \cite{RibeiroSG16} --, whereas global explanators provide an answer to the question ``how does $p$ build its predictions?''---such as decision rules.

% In spite of the many approaches proposed to explain black boxes, some important scientific questions still remain unanswered.
% %
% One of the most important open problems is that, until now, there is no agreement on what an explanation is.
% %
% Indeed, some approaches adopt as explanation a set of rules, others a decision tree, others rely on visualisation techniques \cite{GuidottiMRTGP19}.
% %
% Moreover, recent works highlight the importance for an explanation to guarantee some properties, e.g., soundness, completeness, and compactness \cite{GuidottiMRTGP19}.

% \note{Probabilmente si può tagliare da qui in poi}

% This is why our proposal aims at integrating sub-symbolic approaches with symbolic ones.
% %
% To this end, DT can be exploited as an effective bridge between the symbolic and sub-symbolic realms.
% %
% In fact, DT can be easily \emph{(i)} built from an existing sub-symbolic predictor, and \emph{(ii)} translated into symbolic knowledge -- as it is shown in the reminder of this paper -- thanks to their rule-based nature.

% Decision trees are an interpretable family of predictors that have been proposed as a \emph{global} means for explaining other, less interpretable, sorts of black-box predictors \cite{TrattnerPR2019,BastaniKB17}---such as neural networks \cite{CravenS95}.
% %
% The main idea behind such an approach is to build a DT approximating the behaviour of a given predictor, possibly, by only considering its inputs and its outputs.
% %
% Such approximation essentially trades off predictive performance with interpretability.
% %
% In fact, the structure of such a DT would then be used to provide useful insights concerning the original predictor inner functioning.

% Describing the particular means for extracting DT from black-boxes is outside the scope of this paper.
% %
% Given the vast literature on the topic -- e.g., consider reading \cite{GuidottiMRTGP19,AndrewsDT95} for an overview or \cite{CravenS95,JohanssonN09,FrosstH17} for a practical examples -- we simply assume an extracted DT is available and it has an high \emph{fidelity}---meaning that the loss in terms of predictive performance is low, w.r.t. the original black-box.
% %
% In fact, whereas there exist several works focussing on how to synthesise DT out of black-box predictors, no attention is paid to merging them with symbolic approaches, which can play a key role in enhancing the interpretability and explainability of the system.
% %
% In this paper we focus on such a matter.

% We believe that a logical representation of DT may be interesting and enabling for further research directions.
% %
% For instance, as far as explainability is concerned, we show how logic-translated DT can be used to both navigate the knowledge stored within the corresponding predictors -- thus acting as \emph{global} explanators --, and produce \emph{narrative} explanations for their predictions---thus acting as \emph{local} explanators.
% %
% Note that the restriction on the DT representation makes it easy to map DT onto logical clauses, since DT are finite and with a limited expressivity (if / else conditions).

Accordingly, in the reminder of this chapter we discuss the meaning and the role of explanations in modern AI, we review the recent literature on this topic, and we present the possible means to construct \emph{symbolic} explanations for sub-symbolic predictors.

%===============================================================================
\section{eXplainable Artificial Intelligence}\label{sec:xai-background}
%===============================================================================

\mypapers{agentbasedxai-aamas2020,agentbasedxai-extraamas2020}

Most intelligent systems (IS) today leverage on \emph{numerical} predictive models which are trained from data through ML.
%
The reason for such a wide adoption is easy to understand.
%
We live in an era where the availability of data is unprecedented, and ML algorithms make it possible to semi-automatically detect useful statistical information hidden into such data.
%
Information, in turn, supports decision-making, monitoring, planning, and forecasting in virtually any human activity where data is available.

However, ML is not the silver bullet.
%
Despite the increased predictive power, ML comes with some well-known drawbacks which make it perform poorly in some use cases.
%
One blatant example is algorithmic \emph{opacity}---that is, essentially, the difficulty of human mind in \emph{understanding} how ML-based IS function or compute their outputs.
%
Such difficulty is a serious issue in all those contexts where human beings are liable for their decision or must provide some sort of \emph{explanation} for it---even if the decision has been supported by some IS.
%
For instance, think about a doctor willing to motivate a serious, computer-aided diagnosis, or, a bank employee in need of explaining to a customer why his/her profile is inadequate for a loan.
%
In all contexts, ML is at the same time an enabling -- as it aids the decision process by automating it -- and a limiting factor---as opacity prevents human awareness of \emph{how} the decision process works.

Opacity is why ML predictors are also referred to as \emph{black boxes} into the literature.
%
The ``black box'' expression refers to models where knowledge is not explicitly represented \cite{Lipton18}.
%
The lack of some explicit, symbolic representation of knowledge is what makes it hard for humans to \emph{understand} the functioning of black boxes, and why they led to suggest or undertake a given decision.
%
Obviously, troubles in understanding black-box content and functioning prevents people from fully trusting -- therefore accepting -- them.
%
To make the picture even more complex, current regulations such as the GDPR \cite{gdpr-voigt2017} are starting to recognise the citizens' \emph{right to explanation} \cite{explanation-aimag38}---which implicitly requires IS to eventually become \emph{understandable}.
%
In fact, understanding IS is essential to guarantee algorithmic fairness, to identify potential bias/problems in the training data, and to ensure that IS perform as designed and expected.

%%%%
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/interpretability-performance-tradeoff}
    \caption[Interpretability/performance trade-off]{Interpretability/performance trade-off for some common sorts of black-box predictors}
    \label{fig:tradeoff}
\end{figure}
%%%%

Unfortunately, the notion of understandability is neither standardised nor systematically assessed, yet.
%
At the same time, there is no consensus on what exactly providing an \emph{explanation} should mean when decisions are supported by a black box.
%
However, several authors agree that not all black boxes are equally \emph{interpretable}---meaning that some black boxes are easier to understand than others for our mind.
%
For example, \Cref{fig:trade-off} is a common way to illustrate the differences in black-box interpretability.

Even though informal -- as pointed on in \cite{Rudin2019}, given the lack of way to measure ``interpretability'' -- \Cref{fig:trade-off} effectively express why more research is need on understandability.
%
In fact, the image essentially states how the better performing black boxes are also the less interpretable ones.
%
This is a problem in practice since only rarely predictive performances can be sacrificed in favour of an higher degree of interpretability.

To tackle such issues, the \emph{eXplainable AI} (XAI henceforth) research field has recently emerged.
%
Among the many authors and organisations involved in the topic, DARPA has proposed a comprehensive research road map \cite{darpa2016-xai} which reviews the main approaches to make black boxes more understandable.
%
There, DARPA categorises the many currently available techniques aimed at building meaningful interpretations or explanations for black-box models, it summarises the open problems and challenges, and it provides a successful reference framework for the researchers interested in the field.
%
Unfortunately, in spite of the great effort in defining terms, objects, and methods for the research line, a clear definition of fundamental notions such as \emph{interpretation} and \emph{explanation} is still missing.

%-------------------------------------------------------------------------------
\subsection{Related works}\label{ssec:related}
%-------------------------------------------------------------------------------

Notions such as explanation, interpretation, transparency, etc., are mentioned, introduced, or informally defined in several works.
%
However, a coherent framework has not emerged yet.

In this subsection we recall some of the main contributions from the literature where the concepts of explanation and interpretation -- or any variant of theirs -- are discussed.
%
Our goal here is to highlight the current lack of consensus on the meaning of such terms, for which we propose a possible, unambiguous alternative in the next sections.

Similarly to what we do here, Lipton \cite{Lipton18} starts his discussion by recognising how most definition of ML interpretability are often inconsistent and underspecified.
%
In his clarification effort, Lipton essentially maps interpretability on the notion of \emph{transparency}, and explanation on the notion of \emph{post-hoc} interpretation.
%
Then, he enumerates and describes the several possible variants of transparency, that are
%
\begin{inlinelist}
    \item simulatability -- i.e., the \emph{practical} possibility, for a human being, to ``contemplate the entire model at once'' and simulate its functioning on some data  -- which characterises, for instance, generalised linear models;

    \item decomposability -- i.e., the possibility, for the model to be decomposed in elementary parts whose functioning is intuitively understandable for humans and helpful in understanding the whole model -- which characterises, for instance, decision trees; and

    \item algorithmic transparency -- i.e., the possibility, for a human being, to intuitively understand how a given learning algorithm, or the predictors it produces, operate -- which characterises, for instance, k-nearest-neighbours techniques.
\end{inlinelist}
%
Similarly, \emph{post-hoc} interpretability is defined as an approach where some information is extracted from a black box in order to ease its understanding.
%
Such information have not necessarily to expose the internal functioning of the black box.
%
As stated in the paper: ``examples of post-hoc interpretations include the verbal explanations produced by people or the saliency maps used to analyse deep neural networks''.

Conversely, Besold et al. \cite{BesoldU2018} discuss the notion of explanation at a fundamental level.
%
There, the authors provide a nice philosophical overview on such topic, concluding that ``explanation is an epistemological activity and explanations are an epistemological accomplishment---they satisfy a sort of epistemic longing, a desire to know something more than we currently know. Not only do they satisfy this desire to know, they also provide the explanation-seeker a direction of action that they did not previously have''.
%
Then they discuss the topic of explanation in AI from an historical perspective.
%
In particular, when focussing on ML, they introduce the following classification of IS systems:
%
\begin{inlinelist}
    \item opaque systems -- i.e., black boxes acting as oracles where the logic behind predictions is not observable or understandable --,

    \item interpretable systems -- i.e., white boxes whose functioning is understandable to humans, also thanks to expertise, resources, or tools --, and

    \item comprehensible systems---i.e., ``systems which emit \emph{symbols} along with their outputs, allowing the user to relate properties of the input to the output''.
\end{inlinelist}
%
According to this classification, while interpretable systems can be inspected to be understood -- thus letting observer draw their explanations by themselves --, comprehensible systems must explicitly provide a symbolic explanation of their functioning.
%
The focus there is thus on \emph{who} produces explanations, rather than \emph{how}.

In \cite{DoshiVelezK2017}, interpretability of ML systems is defined as ``the ability to explain or to present in understandable terms to a human''.
%
Interpretations and explanations are therefore collapsed in this work, as confirmed by the authors using the two terms interchangeably.
%
The reminder of that paper focuses
\begin{inlinelist}
    \item on identifying under which circumstances interpretability is needed in ML, and
    \item how to assess the quality of some explanation.
\end{inlinelist}

The survey by Guidotti et al. \cite{GuidottiMRTGP19} is a nice entry point to explainable ML.
%
It consists of an exhaustive and recent survey overviewing the main notions, goals, problems, and (sub-)categories in this field and it encompasses a taxonomy of existing approaches for ``opening the black box''---which may vary a lot depending on the sort of data and the family of predictors at hand.
%
There, the authors define the verb to interpret as the act of ``providing some meaning of explaining and presenting in understandable terms some concepts'', borrowing such a definition from the Merriam-Webster\footnote{\url{https://www.merriam-webster.com/dictionary/interpret}} dictionary.
%
Consequently, they define interpretability as ``the ability to explain or to provide the meaning in understandable terms to a human''---a definition they again borrow from \cite{DoshiVelezK2017}.
%
So, in this case as well the notions of \emph{interpretation} and \emph{explanations} are collapsed.

In \cite{Rudin2019}, Rudin does not explicitly provide a definition for explainability or interpretability, and she refers about interpretable or explainable ML almost interchangeably.
%
However, she states some interesting properties about \emph{interpretability}, which influenced our work.
%
In particular, she acknowledges that ``interpretability is a domain-specific notion''.
%
Furthermore, she links interpretability of information with its complexity -- and, in particular, its \emph{sparsity} --, as the amount of cognitive entities the human mind can at one is very limited ($\sim 7 \pm 2$ according to \cite{numberseven-psyrev63}).
%
As far as explainability is concerned, apparently, Rudin adopts a \emph{post-hoc} perspective similar to the one in \cite{Lipton18}, as she writes ``an explanation is a separate model that is supposed to replicate most of the behaviour of a black box''.
%
In the reminder of the paper, the author argues how the path towards interpretable ML steps through a wider adoption of inherently interpretable predictors -- such as generalised linear models or decision trees -- instead of the relying on \emph{post-hoc} explanations which do not reveal what is inside black boxes---thus preventing their full understanding.

Finally, the recent article by Rosenfeld et al. \cite{RosenfeldR2019} is similar in its intents to our current work.
%
There, the authors attempt to formally define what explanation and interpretation respectively are in the case of ML-based classification.
%
% However, their work differs from ours in several ways.
%
% In particular, they define interpretation and explanation differently from what we do.
%
% In fact, a
According to the authors, ``interpretation'' is a function mapping data, data schemes, and predictors to some representation of the predictors internal logic, whereas ``explanation'' is defined as ``the human-centric objective for the user to understand'' a predictor using the aforementioned interpretation function.
%
Other notions are formally defined into the paper, such as for instance,
%
\begin{inlinelist}
    \item explicitness,
    \item fairness,
    \item faithfulness,
    \item justification, and
    \item transparency.
\end{inlinelist}
%
Such concepts are formally defined in terms of the aforementioned interpretation and explanation functions.
%
The reminder of the paper then re-interprets the field of XAI in terms of all the notions mentioned so far.

\section{Explanation vs. Interpretation}\label{sec:exp-int-basics}

This section introduces the preliminary notions, intuitions, and notations we leverage upon in \cref{ssec:framework} and subsequent sections, in order to formalise our abstract framework for agent-based explanations.
%
We start by providing an intuition for the notion of \emph{interpretation}, and, consequently, for the \emph{act} of interpreting something.
%
Accordingly, we provide an intuition for the property of ``being interpretable'' as well, stressing its comparative nature.
%
Analogously to what we did with \emph{interpretation}, we then provide intuitions for terms such as \emph{explanation} and its derivatives.

%---
\paragraph{About interpretation}
%---

Taking inspiration from the field of Logics, we define the \emph{act} of ``interpreting'' some object $X$ as the activity performed by an agent $A$ -- either human or software -- assigning a \emph{subjective} meaning to $X$.
%
Such meaning is what we call \emph{interpretation}.
%
Roughly speaking, an object $X$ is said to be  \emph{interpretable} for an agent $A$ if it is \emph{easy} for $A$ to draw an interpretation for $X$---where ``easy'' means $A$ requires a low \emph{computational} (or \emph{cognitive}) effort to understand $X$.
%
For instance, consider the case of road signs, which contain symbols instead of scripts to be easily, quickly, and intuitively interpretable.

We model such intuition through a function $I_A(X) \mapsto [0, 1]$ providing a \emph{degree of interpretability} -- or simply interpretability, for short -- for $X$, in the eyes of $A$.
%
The value $I_A(X)$ is not required to be directly observable or measurable in practice, since agents' mind may be inaccessible in most cases.
%
This is far from being an issue, since we are not actually interested in the absolute value of $I_A(X)$, for some object $X$, but rather we are interested in being able to order different objects w.r.t.\ their subjective interpretability.
%
For instance, we write $I_A(X) > I_A(Y)$, for two objects $X$ and $Y$, meaning that the former is more interpretable than the latter, according to $A$.

For example, consider the case of a neural network and a decision tree, both trained on the same examples to solve the same problem with similar predictive performances.
%
Both objects may be represented as graphs.
%
However, it is likely for a human observer to see the decision tree as more interpretable---as their nodes bring semantically meaningful, high-level information.

Summarising, we stress the subjective nature of interpretations, as agents assign them to objects according to their State of Mind (SoM) \cite{PremackW1978} and background knowledge, and they need not be formally defined any further.

%%%%
\begin{figure}
    \centering
    \includegraphics[width=.5\linewidth]{figures/framework.pdf}
    \caption{Explanation vs. Interpretation: a simple framework}
    \label{fig:framework}
\end{figure}
%%%%

%---
\paragraph{About explanation}
%---

We define ``explaining'' as the activity of producing a more interpretable object $X'$ out of a less interpretable one, namely $X$, performed by agent $A$.
%
More formally, we define \emph{explanation} as a function $E(X) \mapsto X'$ mapping objects into other objects, possibly, in such a way that $I_A(X') > I_A(X)$, for some agent $A$.
%
The simple framework described so far is summarised in \cref{fig:framework}.

Notice that human beings tend to collapse into the concept of ``explanation'' the whole sequence of steps actually involving both explaining and interpreting, according to our framework.
%
This happens because, if the explained object $X'$ is as interpretable for the listening agent $B$ as it is for the explaining agent $A$, then both $A$ and $B$ are likely to be satisfied with $X'$.
%
Conversely, it may also happen the explanation $E$ adopted by $A$ produces an object $X'$, which is more interpretable than $X$ for $A$ but not for $B$.
%
Similarly to how two persons would handle such an unpleasant situation, we envision that interaction and communication may be adopted to break such \emph{impasses} in multi-agent systems.

In the following sections, we develop such an idea, describing how our simple framework could be extended to support ML-based intelligent systems.

%-------------------------------------------------------------------------------
\subsection{A conceptual framework for XAI}\label{ssec:framework}
%-------------------------------------------------------------------------------

In AI several tasks can be reduced to a functional model $M: X \rightarrow Y$ mapping some input data $X \subseteq \mathcal{X}$ from an input domain $\mathcal{X}$ into some output data $Y \subseteq \mathcal{Y}$ from an output domain $\mathcal{Y}$.

In the following, we denote as $\mathcal{M}$  the set of all \emph{analogous} models $M': X \rightarrow \mathcal{Y}$, which attempts to solve the same problem on the same input data---usually, in (possibly slightly) different ways.
%
For instance, according to this definition, a decision tree and a neural network, both trained on the same data-set to solve the same classification problem with similar accuracies, are analogous---even if they belong to different families of predictors.

At a very high abstraction level, many tasks in AI may be devoted to compute, for instance:
%
\begin{itemize}
    \item the best $M^* \in \mathcal{M}$, given $X \subseteq \mathcal{X}$ and $Y \subseteq \mathcal{Y}$ (e.g. supervised ML),
    \item the best $M^*$ and $Y$, given $X$ (e.g.\ unsupervised ML),
    \item the best $Y^*$, given $X$ and $M$ (e.g.\ informed/uninformed search),
    \item the best $X^*$, given $Y$ and $M$ (e.g.\  abduction, most likely explanation), etc
\end{itemize}
%
according to some goodness criterion which is specific for the task at hand.

In the reminder of this section, we discuss how explanation may be defined as a function searching or building a -- possibly more interpretable -- model w.r.t.\ the one to be explained.
%
For this process to even make sense, of course, we require the resulting model to be not only analogous to the original but also similar in the way it behaves on the same data.
%
We formalise such a concept through the notion of \emph{fidelity}.

Let $M, M' \in \mathcal{M}$ be two analogous models.
%
We then say $M$ has a \emph{locally} good \emph{fidelity} w.r.t.\ $M'$ and $Z$ if and only if $\Delta f(M(Z), M'(Z)) < \delta$ for some arbitrarily small threshold $\delta \geq 0$ and for some subset of the input data $Z \subset X$.
%
There, $\Delta f : 2^\mathcal{Y} \times 2^\mathcal{Y} \rightarrow \mathbb{R}_{\geq 0}$ is a function measuring the performance \emph{difference} among two analogous models.

%%%%
\begin{figure}
    \centering
    \includegraphics[width=.5\linewidth]{figures/local.pdf}
    \caption{Local explanation and interpretation of a model}
    \label{fig:local}
\end{figure}
%%%%

%---
\paragraph{Local interpretations}
%---

When an observer agent $A$ is \emph{interpreting} a model $M$ behaviour w.r.t.\ some input data $Z \subseteq X$, it is actually trying to assign a subjective interpretability value $I_A(R)$ to some representation $R = r(M, Z)$ of choice, aimed at highlighting the behaviour of $M$ w.r.t.\ the data in $Z$.
%
There, $r : \mathcal{M} \times 2^\mathcal{X} \rightarrow \mathcal{R}$ is \emph{representation means}, i.e., a function mapping models into \emph{local} representations w.r.t.\ a particular subset of the input domain, whereas $\mathcal{R}$ is the set of model representations.
%
For instance, in the case $M$ is a classifier, $R$ may be a graphical representation of (a portion of) the decision boundary/surface for a couple of input features.

There may be more or less interpretable \emph{representations} of a particular model for the same observer $A$.
%
Furthermore, representations may be either global or local as well, depending on whether they represent the behaviour of the model for the whole input space, or for just a portion of it.
%
For example, consider the case of a plot showing the decision boundary of a neural network classifier.
%
This representation is likely far more interpretable to the human observer than a graph representation showing the network structure, as it synthesise the global behaviour of the network concisely and intuitively.
%
Similarly, saliency maps are an interpretable way to \emph{locally} represent the behaviour of a network w.r.t. some particular input image.
%
So, a way for easing interpretation for a given model behaviour w.r.t.\ a particular sort of inputs is about looking for the right representation in the eyes of the observer.

%---
\paragraph{Local explanations}
%---

Conversely, when an observer $A$ is \emph{explaining} a model $M$ w.r.t.\ some input data $Z \subseteq X$, it is actually trying to produce a model $M' = E(M, Z)$ through some function $E: \mathcal{M} \times 2^\mathcal{X} \rightarrow \mathcal{M}$.
%
In this case, we say $M'$ is a \emph{local explanation} for $M$ w.r.t.\ to $Z$.
%
We also say that $M'$ is produced through the explanation strategy $E$.

Furthermore, we define an explanation $M'$ as \emph{admissible} if it has a valid fidelity w.r.t.\ the original model $M$ and the data in $Z$---where $Z$ is the same subset of the input data used by the explanation strategy.
%
More precisely, we say $M'$ is $\delta$-admissible in $Z$ w.r.t.\ $M$ if $\Delta f(M(Z), M'(Z)) < \delta$.

Finally, we define an explanation $M'$ as \emph{clear} for $A$, in $Z$, and w.r.t.\ the original model $M$, if there exists some representation $R' = r(M', Z)$ which is more interpretable than the original model representation $R$.
%
More precisely, we say $M'$ is $\varepsilon$-clear for $A$, in $Z$, and w.r.t $M$ if $I_A(R') - I_A(R) > \varepsilon$ for some arbitrarily big threshold $\varepsilon > 0$.

Several \emph{explanations} may actually be produced for the same model $M$.
%
For each explanation, there may be again more or less interpretable \emph{representations}.
%
Of course, explanations are useful if they ease the seek for more interpretable representations.
%
Thus, providing an explanation for a given model behaviour w.r.t.\ a particular class of inputs is about creating \emph{ad-hoc} metaphors aimed at easing the observer's understanding.

%%%%
\begin{figure}
    \centering
    \includegraphics[width=.5\linewidth]{figures/global.pdf}
    \caption{Global explanation and interpretation of a model}
    \label{fig:global}
\end{figure}
%%%%

%---
\paragraph{Global / local explanations}
%---

The theoretical framework described so far -- which is graphically synthesised in \cref{fig:local} -- is aimed at modelling \emph{local} interpretations and explanations, that are, the two means an explanator agent may exploit in order to make AI tasks' \emph{outcomes} more understandable in the eyes of some explanee.

Conversely, when the goal is not to understand some model outcome, but the model itself, from a \emph{global} perspective -- or, equivalently, when the goal is to understand the model outcome w.r.t the whole set of input data $X$ --, the theoretical framework described so far is simplified as shown in \cref{fig:global}, where the dependency on the input data is omitted from functions $E$, $\Delta f$, and $r$.
%
This is possible because we consider the global case as a particular case of the local one, where $Z \equiv X$.

Finally, we remark that the case where a model $M$ is to be understood on a single input-output pair, say $x$ and $y = M(x)$, is simply captured by the aforementioned local model, through the constraint $Z = \{ x \}$ and $M(Z) = \{ y \}$.

%-------------------------------------------------------------------------------
\subsection{Discussion}
%-------------------------------------------------------------------------------

Our framework is deliberately abstract in order to capture a number of features we believe to be essential in XAI.
%
First of all, our framework acknowledges -- and properly captures -- the orthogonality of interpretability w.r.t.\ explainability.
%
This is quite new, indeed, considering that most authors tend to use the two concepts as if they were equivalent or interchangeable.

Furthermore, our framework explicitly recognises the \emph{subjective} nature of interpretation, as well as the subtly \emph{objective} nature of explanation.
%
Indeed, interpretation is a subjective activity directly related to agents' perception and SoM, whereas explanation is an epistemic, computational action which aims at producing a high-fidelity model.
%
The last step is objective in the sense that it does not depend on the agent's perceptions and SoM, thus being reproducible in principle.
%
Of course, the \emph{effectiveness} of an explanation is again a subjective aspect.
%
Indeed, a clear explanation (for some agent) is a more interpretable variant of some given model---thus, the subjective activity of interpretation is again implicitly involved.

The proposed framework also captures the importance of representations.
%
This is yet another degree of freedom that agents may exploit in their seek for a wider understandability of a given model.
%
While other frameworks consider interpretability as an intrinsic property of AI models, we stress the fact that a given model may be represented in several ways, and each representation may be interpreted differently by different agents.
%
As further discussed in the remainder of this chapter, this is far from being an issue.
%
This subjectivity is deliberate, and it is the starting point of some interesting discussions.

Finally, our framework acknowledges the global/local duality of both explanation and interpretation, thus enabling AI models to be understood either general or with respect to a particular input/output pair.

%-------------------------------------------------------------------------------
\subsection{Practical remarks}
%-------------------------------------------------------------------------------

The ultimate goal of our framework is to provide a general, flexible, yet minimal framework describing the many aspects concerning AI understandability in the eyes of a \emph{single} agent.
%
We here illustrate several practical issues affecting our framework in practice, and further constraining it.

According to our conceptual framework, a \emph{rational} agent seeking to understand some model $M$ (or make it understandable) may either choose to elaborate on the \emph{interpretation axis} -- thus looking for a (better) representation $R$ of $M$ -- or it can elaborate on the \emph{explainability axis}---thus producing a novel, high fidelity model $M'$, coming with a representation $R'$ which is more interpretable than the original one (i.e., $R$).

Notice that, in practice, the nature of the model constrains the set of admissible representations.
%
This means that a rational agent is likely to exploit both the explanation and interpretation axes in the general case---because novel representations may become available through an explanation.
%
We argue and assume that each family of AI models comes with just a few \emph{natural} representations.
%
Because of this practical remark, we expect that, in real-world scenarios, an agent seeking for understandability is likely to ``work'' on both the interpretation and the explanation axes.

For instance, consider decision trees, which come with a natural representation as a tree of subsequent choices leading to a decision.
%
Conversely, neural networks can either be represented as graphs or as algebraic combinations of tensors.
%
In any case, neural network models are commonly considered less interpretable than other models.
%
In such situation, a rational agent willing to make a neural network more understandable may choose to combine decision trees extraction (explanation) -- possibly focusing on methods from the literature \cite{AndrewsDT95,xailp-woa2019} -- to produce a decision tree whose tree-like structure (representation) could be presented to the human observer to ease their interpretation.
%
The decision-tree like representation is not ordinarily available for neural networks, but it may become available provided that an explanation step is performed.

Another interesting trait of our framework concerns the semantics of clear explanations.
%
The current definition requires explanation strategies to consume a model $M$ with a given representation $R$ and to produce a high-fidelity model $M'$ for which a representation $R'$ exists, which is more interpretable than $R$.
%
Several semantics may fit this definition.
%
This is deliberate, since different semantics may come with different computational requirements, properties, and guarantees.
%
For instance, one agent may be interested in finding the \emph{best} explanation---that is, the one for which \emph{each} representation is more interpretable than the most interpretable representation of the original model.
%
Similarly, in some cases, it may be sufficient -- other than more feasible -- to find an \emph{admissible} explanation---that is, a high-fidelity model for which \emph{some} representation exists that is more interpretable than \emph{some} representation of the original model.
%
However, the inspection of the possible semantics and their properties falls outside the scope of this paper and is going to be considered as a future research direction.

\subsection{Assessment of the Framework}\label{sec:validation}

The abstraction level of the presented framework has also been conceived in order to capture most of the current state of the art.
%
Along this line, this section aims at validating the fitting of the existing contributions w.r.t.\ the framework presented in section \cref{ssec:framework}: if our framework is expressive enough, it should allow most (if not all) existing approaches to be uniformly framed, to be easily understood and compared.
%
To this end, we leverage on the work by Guidotti et al.\ \cite{GuidottiMRTGP19}, where the authors perform a detailed and extensive survey on the state-of-the-art methods for XAI, by categorising the surveyed methods according to an elegant taxonomy.
%
Thus, hereafter, we adopt their taxonomy as a reference for assessing our framework.

The taxonomy proposed by Guidotti et al.\ essentially discriminates among two main categories of XAI methods.
%
These are the ``transparent box design'' and the ``black-box explanation'' categories.
%
While the former category is not further decomposed, the latter comes with three more sub-categories, such as ``model explanation'', the ``outcome explanation'', and the ``model inspection''.
%
Notice that, despite the authors' definition of ``explanation'' does not precisely match the one proposed in this paper, we maintained the original categorisation.

The remainder of this section navigates such a taxonomy accordingly, by describing how each (sub-)category -- along with the methods therein located -- fits our abstract framework.

%-------------------------------------------------------------------------------
\subsubsection{Model explanation}
%-------------------------------------------------------------------------------

The mapping of the methods classified as part of the ``model explanation'' sub-category into our framework is seamless.
%
Hence, it can be defined as follows:
%
\begin{itemize}
    \item[] Let $M$ be a sub-symbolic classifier whose internal functioning representation $R$ is poorly interpretable in the eyes of some explanee $A$, and let $E(\cdot)$ be some \emph{global} explanation strategy.
    %
    Then, the model explanation problem consists of computing some \emph{global} explanation $M' = E(M)$ which is $\delta$-admissible and $\varepsilon$-clear w.r.t.\ to $A$, for some $\delta, \varepsilon > 0$.
\end{itemize}
%
For instance, according to Guidotti et al., possible sub-symbolic classifiers are neural (possibly deep) networks, support vector machines, and random forests.
%
Conversely, explanation strategies may consist of algorithms aimed at
%
\begin{enumerate*}[label=\emph{(\roman{*})}]
    \item extracting decision trees/rules out of sub-symbolic predictors and the data they have been trained upon,
    \item compute feature importance vectors,
    \item detecting saliency masks,
    \item detecting partial dependency plots, etc.
\end{enumerate*}

In our framework, all the algorithms mentioned above can be described as \emph{explanation strategies}.
%
Such mapping is plausible given their ability to compute an admissible, and possibly more explicit models out of black boxes and the data they have been trained upon.
%
However, it is worth to highlight that the clarity gain produced by such explanation strategies mostly relies on the implicit assumption that their output models come with a natural representation which is intuitively interpretable to the human mind.

%-------------------------------------------------------------------------------
\paragraph{Outcome explanation}
%-------------------------------------------------------------------------------

Methods classified as part of the ``outcome explanation'' sub-category can be very naturally described in our framework as well.
%
In fact, it can be defined as follows:
%
\begin{quotation}
    Let $M$ be some sub-symbolic classifier whose internal functioning representation $R = r(M, Z)$ in some subset $Z \subset \mathcal{X}$ of the input domain is poorly interpretable to some explanee $A$, and let $E(\cdot, \cdot)$ be some \emph{local} explanation strategy.
    %
    Then, the outcome explanation problem consists of computing some \emph{local} explanation $M' = E(M, Z)$ which is $\delta$-admissible and $\varepsilon$-clear w.r.t.\ to $A$, for some $\delta, \varepsilon > 0$
\end{quotation}
%
Summarising, while input black boxes may still be classifiers of any sort, explanation, and explanation strategies differ from the ``model explanation'' case.
%
In particular, explanation strategies in this sub-category may rely on techniques leveraging on attention models, decision trees/rules extraction, or well-established algorithms such as LIME \cite{RibeiroSG16}, and its extensions---which are essentially aimed at estimating the contribution of every input feature of the input domain to the particular outcome of the black box to be explained.

Notice that the explanation strategies in this category are only required to be admissible and clear in the portion of the input space surrounding the input data under study.
%
Such a portion is implicitly assumed to be relatively small in most cases.
%
Furthermore, the explanation strategy is less constrained than in the global case, as it is not required to produce explanations elsewhere.

%-------------------------------------------------------------------------------
\paragraph{Model inspection}
%-------------------------------------------------------------------------------

Methods classified as part of the ``model inspection'' sub-category can be naturally defined as follows:
%
\begin{quotation}
    Let $M$ be a sub-symbolic classifier whose available \emph{global} representation $R = r(M)$ is poorly interpretable to some explanee $A$, and let $r(\cdot), r'(\cdot)$ be two different representation means.
    %
    Then, the model inspection problem consists of computing some representation $R' = r'(M)$ such that $I_A(R') > I_A(R)$
\end{quotation}
%
Of course, solutions to the model inspection problem vary a lot depending on which specific representation means $r(\cdot)$ is exploited by the explanator, other than the nature of the data the black box is trained upon.
%
Guidotti et al.\ also provide a nice overview of the several sorts of representations means which may be useful to tackle the model inspection problem, like, for instance, sensitivity analysis, partial dependency plots, activation maximization images, tree visualisation, etc.

It is worth pointing out the capability of our framework to reveal the actual nature of the inspection problem.
%
Indeed, it clearly shows how this is the first problem among the ones presented so far, which only relies on the interpretation axis alone to provide understandability.

%-------------------------------------------------------------------------------
\paragraph{Transparent box design}
%-------------------------------------------------------------------------------

Finally, methods classified as part of the ``transparent box design'' sub-category can be naturally defined as follows:
%
\begin{quotation}
    Let $X \subseteq \mathcal{X}$ be a dataset from some input domain $\mathcal{X}$, let $r(\cdot)$ be a representation means, and let $A$ be the explanee agent.
    %
    Then the transparent box design problem consists of computing a classifier $M$ for which a global representation $R = r(M, X)$ exists such that $I_A(R) > 1 - \delta$, for some $\delta > 0$
\end{quotation}
%
Although very simple, the transparent-box design is of paramount importance in XAI systems as it is the basic brick of most general explanation strategies.
%
Indeed, it may be implicit in the functioning of some explanation strategy $E$ to be adopted in some other model or outcome explanation problem.

For instance, consider the case of a local explanation strategy $E(M, X) \mapsto M'$.
%
In the general case, to compute $M'$, it relies on some input data $X$ and the internal of the to-be-explained model $M$.
%
However, there may be cases where the actual internal of $M$ are not considered by the particular logic adopted by $E$.
%
Instead, in such cases, $E$ may only rely on $X$ and the outcomes of $M$, which are $Y = M(X)$.
%
In this case, the explanation strategy $E$ is said \emph{pedagogical}---whereas in the general case it is said \emph{decompositional} (cf.\ \cite{AndrewsDT95}).

In other words, as made evident by our framework, the pedagogical methods exploited to deal with the model or outcome explanation problems must internally solve the transparent box design problem, as they must build an interpretable model out of some sampled data-set and nothing more.

\section{Symbolic Knowledge Extraction}\label{sec:knowledge-extraction}

\mypapers{xmas-aiiot2019,xaisurvey-ia14,xailp-woa2019}%,shallow2deep-extraamas2021}

Many strategies can be exploited to pursue the purpose of explainability~\cite{GuidottiMRTGP19}.
%
Some authors suggest for instance to \emph{only} rely on \emph{interpretable} algorithms~\cite{Rudin2019} -- such as generalised linear models, decision trees, etc. -- to construct data-driven solutions that are explainable by construction.
%
However, this may hinder predictive performance in the general case, as it essentially cuts off most effective algorithms---e.g., ANN.
%
Another strategy consists of deriving \emph{post-hoc} explanations \cite{KENNY2021103459}, aimed at reverse-engineering the inner operation of a BB so as to make it explicit.
%
In this way, data scientists can keep using prediction-effective predictors such as NN, while still attaining high predictive performance.
%
The focus of this paper is on the latter strategy.

Symbolic knowledge extraction (SKE) \cite{GarcezBG01} is among the most promising means to derive \emph{post-hoc} explanations for sub-symbolic predictors.
%
Roughly speaking, the main idea behind SKE is to enable the construction of a \emph{symbolic} surrogate model mimicking the behaviour of a given predictor.
%
There, symbols may consist of intelligible knowledge, such as flat lists or hierarchical trees of \emph{rules}.
%
Such rules can then be exploited to either derive predictions or to better understand the behaviour of the original predictor.

SKE has been applied, for instance, to credit-risk evaluation \cite{baesens2003using,baesens2001building,steiner2006using},  healthcare -- i.e., to make early breast cancer prognosis predictions \cite{franco2007early} and to help the diagnosis and discrimination among hepatobiliary disorders \cite{hayashi2000comparison} or other diseases and dysfunctions \cite{bologna1997three,bologna2000study} --, credit card screening \cite{setiono2011rule}, intrusion detection systems \cite{hofmann2003rule}, and keyword extraction \cite{azcarraga2012keyword}.

\subsection{State of the art}\label{ssec:ske-soa}

Here we discuss the main approaches for extracting symbolic knowledge out of sub-symbolic predictors.

The main underlying assumption behind most works in this category is that, once a sub-symbolic system has been trained over large amounts of data reaching some good predictive performance, then it must have attained a distributed representation of the knowledge contained in the data.
%
Even though unintelligible to human beings, the distributed representation is still somehow buried in the internals of that sub-symbolic systems.
%
Assuming this is the case, then a knowledge extraction technique is a means for making the distributed representation explicit and intelligible.

It is worth to mention that the idea of extracting decision rules or trees from sub-symbolic predictors is not new: it has been introduced several times, in many forms, and with different names and methods, since the late 80s.
%
In fact, generally speaking, systems supporting symbolic knowledge extraction have a number of appealing features.
%
In particular, they support a full exploitation of sub-symbolic techniques, which are the best choice when information must be mined from large amounts of data, and are usually better suited in terms of precision, robustness, and predictive performance.
%
However, thanks to the knowledge extracted, those systems retain desirable XAI-related properties which would otherwise be lost.

Knowledge extraction techniques can be described and discriminated according to a number of orthogonal dimensions, including:
%
\begin{enumerate}
	\item\label{opt:structure-of-knowledge} the structure of the symbolic knowledge they extract (e.g., decision rules, decision trees, etc)
	\item the type of constraints they exploit for decision-making (e.g., linear constraints, M-of-N rules, etc)
	\item\label{opt:sort-of-predictor} the sort of sub-symbolic predictor(s) they can deal with (e.g., neural networks, support vector machines, etc)
\end{enumerate}
%
In the reminder of this section we partition the surveyed works according to dimensions \ref{opt:structure-of-knowledge}, and \ref{opt:sort-of-predictor}, then for each approach we discuss the sort of the constraints exploited.
%
In particular, in the same way as other impactful surveys on the topic \cite{GuidottiMRTGP19,AndrewsDT95}, we distinguish between techniques extracting \emph{rule} lists and techniques extracting decision \emph{trees}.
%
Then, we further distinguish between pedagogical and decompositional approaches.
%
In doing so we borrow the terminology from \cite{AndrewsDT95}, where \emph{pedagogical} techniques are those capable of extracting symbolic knowledge from any sort of sub-symbolic predictor -- as they do \emph{not} exploit any internal detail of the predictor under study to perform the extraction --, whereas \emph{decompositional} techniques are those only capable of extracting symbolic knowledge from some particular sort of sub-symbolic predictor (e.g., neural networks, in most cases)---as they perform the extraction by looking at the internals of the predictor at hand.

%%%%---------------------------%%%%
\subsubsection{Rules extraction}
%%%%---------------------------%%%%

Here we focus on methods for extracting \emph{flat} list of rules in the form
%
\begin{center}
	\textbf{if} $condition_1$ \textbf{then} $outcome_1$
	\\
	\textbf{else if} $condition_2$ \textbf{then} $outcome_2$
	\\
	$\vdots$
	\\
	\textbf{else} $outcome_n$
\end{center}
%
out of sub-symbolic predictors, where each $condition$ is can be a conjunction or disjunction of
%
\begin{inlinelist}
    \item boolean predicates,
    \item linear constraints, or
    \item M-of-N rules
\end{inlinelist}
%
over the attributes of the data used to train the sub-symbolic predictor.


We categorise the surveyed techniques for rule extraction depending on whether they are decompositional or pedagogical;
then we provide some details for each technique;
finally, we analyse them from the XAI perspective in an aggregate manner, given the huge similarity characterising the surveyed techniques from the XAI perspective.

%%%%
\paragraph{Pedagogical approaches}
%%%%

We identified three main pedagogical approaches for rule extraction:
\begin{itemize}
	\item the method from Saito et al.\ (1988) \cite{saito1988}
	\item RxREN (2012) \cite{Augasta2012}
	\item ALPA (2015) \cite{Fortuny2015}
\end{itemize}

In particular, \cite{saito1988} extracts M-of-N rules out of any black-box classifier, regardless of whether it is a neural network or not.
%
Apparently, however, this method does not support regression, and it only supports categorical attributes as conditions in the extracted rules.
%
In spite of its limitations, this work has been proven to be effective in expert systems for diagnosis support.

On the contrary, \cite{Augasta2012} and \cite{Fortuny2015} extract if-then-else rules out of arbitrary classifiers.
%
In particular, RxREN supports datasets with mixed mode attributes (i.e., either categorical or numerical).
%
The algorithm is based on a reverse-engineering algorithm that essentially discards insignificant attributes and discovers the variation range of input attribute for each possible outcome of the classification.
%
For this reason, the rules extracted by RxREN are composed by linear constraints.
%
Conversely, the ALPA rule extraction technique is the first that is applicable to any black-box model with no limitations on the nature of constraints.

It is worth remarking that pedagogical approaches are not based on the structure of the network, therefore they also work with other sub-symbolic models---even though oldest papers tend to mention neural networks more than other sorts of predictors.

Finally, it is worth to be mentioned that pedagogical extraction algorithms can essentially be described as oracle-based algorithms.
%
In fact, in most cases the extraction algorithm works by querying the black box (which is therefore considered as an oracle), and by using the corresponding responses to build the rule list.
%
This behaviour is repeated until the set of rules given by the white-box model converges to that of the black box.
%
In other words, the extraction procedure terminates when the rule set as whole reaches an high \emph{fidelity} w.r.t. the original black box.

%%%%
\paragraph{Decompositional approaches}
%%%%

We identify some main decompositional approaches for rule extraction:
%
\begin{itemize}
	\item RuleNet (1992) \cite{mcmillan1992}
	\item MofN (1992) \cite{towell1992}
	\item the method from Giles et al.\ (1993) \cite{giles1993}
	\item KT (1994) \cite{fu1994}
	\item VI-Analysis (1995) \cite{thrun1995}
	\item RX (1997) \cite{Setiono1997}
	\item the method from N\'u\~{n}ez et al.\ (2008) \cite{NunezAC08}
\end{itemize}

Generally speaking, most approaches here explicitly target a particular sort of sub-symbolic predictor.
%
In particular, all approaches except \cite{NunezAC08} target neural networks, whereas \cite{NunezAC08} target support vector machines (SVM).

Some approaches \cite{mcmillan1992,towell1992,giles1993} exploit some strict assumptions that limit the kind of neural networks they can manage, thus reducing their generality.
%
For instance, the RuleNet technique described in \cite{mcmillan1992} can only handle neural networks aimed at computing endomorphisms on $n$-sized strings of characters, and it aims at making explicit the condition-action rules exploited by such sorts of networks.
%
At the same time, the MofN technique \cite{towell1992} can only handle neural networks attained via the KBANN algorithm described above.
%
As suggested by its name, this method extracts M-of-N-like rules.
%
Finally, the method proposed in \cite{giles1993} focuses on neural networks trained to act as recognisers for regular languages, and it is capable of extracting rules in the form of finite state automata for parsing these languages.

Other approaches -- e.g., \cite{fu1994,thrun1995,Setiono1997} -- target general purpose neural networks.
%
Briefly speaking, they compile networks into sets of rules with equivalent structure.
%
There, each processing unit (neuron) is mapped into a separate rule -- or a small set of rules --, and the in-going connections are interpreted as preconditions to that rule.
%
The particular shape of preconditions -- e.g., linear constraints, M-of-N constraints, etc. --, is then inferred by taking into account the weights of a neuron in-going connections, and its activation function.
%
For instance, the KT algorithm \cite{fu1994} is capable of learning if-then-else rules with linear constraints out of general neural-network classifier.
%
Similarly, the VI-Analysis \cite{thrun1995} and RX \cite{Setiono1997} algorithms perform the same task via different procedures.

Finally, a different and noteworthy approach is described in \cite{NunezAC08}.
%
There, the authors propose a method for extracting if-then-else rules with linear constraints out of SVM classifiers.

\subparagraph{XAI Perspective}

Generally speaking, rule extraction techniques provide \emph{post-hoc} explainability via model simplification.
%
In fact, all the surveyed extraction procedures aims at creating a list of rule having an high-fidelity w.r.t. the source black-box predictor.
%
This rule list can then be considered a symbolic, intelligible explanation of the source predictor.
%
Accordingly, we argue that all these techniques may contribute to the pursuit of XAI goals as: trustworthiness, causality, transferability, informativeness, confidence, and possibly fairness.
%
In fact, by making the inner operation of a black-box predictor explicit and intelligible, these techniques may increase the trustworthiness and confidence of intelligent systems.
%
Furthermore, by providing an overview of the all the possible context-decision situation an intelligent system may face, and by making it possible to inspect which particular rule lead to a particular decision, rule extraction techniques may provide informativeness and causality.
%
Moreover, the symbolic knowledge extracted can be translated into several forms, possibly making it compliant with symbolic intelligent systems.
%
This of course provides for transferability.
%
Finally, rule extraction techniques may help with fairness as well, by highlighting the biases possibly learned by sub-symbolic predictors.

It is worth to mention, however, that rule extraction technique are not the silver bullet of XAI.
%
Issues related to accuracy, fidelity, and consistency, may easily arise in this kind of approaches, because the extracted rule list may not perfectly reflect insights of the original one.
%
We argue that this is essentially unavoidable: the extracted rule lists are essentially approximated models, which are attained by removing (i.e. loosing) information from the source black-box.
%
Moreover, interpretability of the extracted rule list may easily deteriorate as the amount of rules (or the amount of predicates per rule) increases---a situation which may easily arise as the complexity or the dimensionality of the black-box become non-trivial.
%
Finally, it is worth to be noted that virtually all rule extraction techniques only focus on black-box predictors acting as classifiers.
%
Not so much attention has been devoted by the academic community to the extraction of rules out of sub-symbolic regressors, as well as black boxes aimed at performing unsupervised learning tasks.

As a side note concerning SVM-based rule extraction techniques, it is worth to be mentioned that, although they have been known to produce classifiers that are easily comprehensible, they often approximate secondary models of worse accuracy \cite{Barakat2010}.
%
Moreover, even though these models may be reasonably understandable from an expert perspective, they still lack the simplicity and familiarity to an individual user that often intelligent systems have to provide, as in the case of recommendation.

% \subparagraph{Technological Perspective}

% In spite of the many surveyed papers for rule extraction algorithm, only one of them comes with some actual implementation: ALPA.
% %
% The implementation of ALPA is available for download on the web page of the Applied Data Mining Research Group at the University of Antwerp\footnote{\url{http://applieddatamining.com/cms/?q=software}}.
% %
% It consists of a plugin for the Weka data-mining framework\footnote{\url{https://www.cs.waikato.ac.nz/ml/weka}}.
% %
% Thus, it is JVM-based software coming with a detailed manual.
% %
% Apparently, the ALPA source and binary code was published in 2013 and never been updated since then.


%%%%---------------------------%%%%
\subsubsection{Decision trees extraction}
%%%%---------------------------%%%%

Here we focus on methods for extracting \emph{hierarchical} decision tree out of sub-symbolic predictors.

Generally speaking, extracted decision trees are ordinary decision trees whose nodes are represented by rules consisting of a conjunction or disjunction of
%
\begin{inlinelist}
    \item boolean predicates,
    \item linear constraints, or
    \item M-of-N rules
\end{inlinelist}
%
over the attributes of the data used to train the sub-symbolic predictor, similarly to the aforementioned decision rules.
%
In other words, the main difference with decision rules lays in the hierarchical nature of decision choices.

Given the small amount of techniques for decision tree extraction surveyed in this section, we do not split our discussion any further to distinguish between pedagogical or decompositional approaches.
%
Rather we provide this information as part of the details description of each method, provided below.
%
We provide a joint discussion of decision tree extraction methods from the XAI perspective, at the end of the paragraph.

\paragraph{Surveyed methods}

We identify three main approaches for decision tree extraction:
%
\begin{itemize}
	\item \textsc{Trepan} (1996, pedagogical) \cite{CravenS95}
	\item the method by Krishnan et al.\ (1999, pedagogical) \cite{KrishnanSB1999}
	\item the method by Schetinin et al.\ (2007, decompositional: random-forest-specific) \cite{schetinin2007}
\end{itemize}

\textsc{Trepan} \cite{CravenS95} is a pedagogical tree extraction algorithm that extracts decision trees from sub-symbolic models.
%
\textsc{Trepan} grows a tree through recursive partitioning, using a best-first expansion strategy, towards M-of-N-like, tree-structured rules.
%
The black box model -- be it a neural network, a support vector machine, or any other model that can be used for classification -- is used as an oracle to answer questions of class belongingness on artificially-generated data points.
%
It also exploits the active learning process to additionally generate data points according to network constraints.

Along the same line, \cite{KrishnanSB1999} proposes decision tree extraction from neural networks.
%
Unlike \textsc{Trepan}, however, the internal structure of the neural network is taken into consideration in the process of decision tree construction.
%
Furthermore, while \textsc{Trepan} leverages on a restricted form of active learning, the method proposed by \cite{KrishnanSB1999} leverages on a genetic algorithm.
%
Finally, it is worth mentioning that the latter algorithm supports the extraction of trees of a given size.
%
In other words, the size of extracted tree can be tuned.

Finally, \cite{schetinin2007} proposes an approach for the probabilistic interpretation of Bayesian decision trees ensembles (a.k.a.\ random forests) as a single decision tree.
%
Classification confidence for each tree in the forest is calculated by exploiting training data: the decision tree covering the maximum number of correct training examples is selected, keeping the amount of classification errors in the remaining examples minimal.
%
Unlike the previous ones, this method of explanation does not extend the input data set with random additional data and cannot be generalised to other types of sub-symbolic black boxes.

\subparagraph{XAI Perspective}

From the point of view of XAI, decision tree extraction methods are quite similar to rule extraction ones, thus similar concerns fit their case.
%
Accordingly, we argue that decision tree extraction techniques provide \emph{post-hoc} explainability via model simplification, and help in pursuing XAI goals such as trustworthiness, causality, transferability, informativeness, confidence, and fairness.

In spite of the many similarities with rule extraction techniques, a remarkable peculiarity of decision trees extractors is worth to be mentioned: as hierarchical models, they are less prone to interpretability issues when the complexity or dimensionality of the source predictor grows.

Other critical aspects remain however unresolved w.r.t.\ rule extraction techniques.
%
These include issues arising from the potential lack of fidelity, as well as the concentration of practically all the decision tree extraction techniques on the sole case of classification tasks---leaving others kinds of tasks in machine learning essentially uncovered.

% \subparagraph{Technological Perspective}

% As far as implementations of decision tree extraction facilities are concerned, we were only able to find an ancient C-based implementation of \textsc{Trepan} on the author's homepage\footnotetext{\url{http://www.biostat.wisc.edu/~craven/TrepanWin.zip}}.
% %
% The archive only contains the C source code of \textsc{Trepan} plus some basic instruction and a \texttt{Makefile} for build automation.
% %
% We classify this technology as a legacy experimental project.

\subsection{A practical framework for MAS}
\sidenote{Cite Sabba's WOA21 paper}

In the reminder of this thesis, we commit to computational logics as the preferred means for explainability.
%
In particular, we sketch a general framework for XAI, reifying the abstract framework from \cref{ssec:framework} via SKE.

The basic idea is that SKE can be used to draw explanations in the form logic knowledge, which can then be further symbolically manipulated to ease the interpretation of the users.
%
Explanations, in this case, consist of \emph{surrogate} predictors trained to mimic the ones to be explained, as closely as possible.
%
Such surrogates consist of logic knowledge bases, intensively representing the internals of some sub-symbolic ML predictor via interpretable formul\ae{}.
%
In fact, given a trained predictor and a knowledge-extraction procedure applicable to it, the extracted rules/trees act as \emph{explanations} for that predictor -- or as a basis to build some --, provided that they retain high \emph{fidelity} w.r.t.\ both the original predictor and the data used to train it.

\paragraph{Framework design}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/psyke-abstract.pdf}
    \caption{A practical framework for XAI based on SKE}
    \label{fig:psyke-abstract}
\end{figure}

In particular, as depicted in \cref{fig:psyke-abstract},  a pivotal role in the design of our practical framework is played by the notion of \emph{extractor}, defining the general contract of any knowledge extraction procedure.
%
More precisely, any algorithm accepting a \emph{ML-trained} predictor -- either a classifier or a regressor -- as input, and producing logic rules as output can act as an extractor.
%
Thus, the many algorithms described in \cref{ssec:ske-soa} are well suited to act as extractors.

To perform their job, extractors may require additional information about the data the input predictor has been trained upon.
%
In the general case, such information consists of the data set itself and its schema---i.e., a formal description of the names and the data types of all features characterising the data set itself.
%
Data sets are required to let extraction procedures inspect BB behaviour -- and therefore build the corresponding output rules --, whereas schemas are required to
%
\begin{inlinelist}
	\item let the extraction procedure take informed decisions on the basis of the feature \emph{types},
	\item let the extracted knowledge be clearer by referring to the feature \emph{names}.
\end{inlinelist}
%
For all these reasons, extractors expect a data set and its schema metadata to be provided in input as well.

We stress the logic nature of the extractors' outputs.
%
These may consist of \emph{knowledge bases} containing logic rules expressed via some logic formalism of choice---e.g. FOL, Horn clauses, or ProbLog.
%
These rules should \emph{intensively} represent the general behaviour of the original predictor, in a symbolic way.
%
Furthermore, the actual behaviour of the original predictor on a particular input should be reproducible via inference.
%
Thus, the whole knowledge base acts as a \emph{global} explanation for the original predictor, whereas the proof tree aimed at inferring a particular output acts as a \emph{local} explanation for that particular prediction.

Of course, logic rules may still be poorly interpretable to inexpert human agents.
%
The formalism may for instance be obscure for the human, the rules may be too many, their arity may be too large, or their bodies may involve too many literals.
%
For all these reasons, the framework assumes one further processing step, aimed at representing explanations in the most adequate way for the human agent consuming them.
%
While the possible representations are manifold, the key point here is that the extraction of logic knowledge out of sub-symbolic predictors is not the ultimate step of explanation but rather an intermediate one, enabling the \emph{inspection} of the inner operation of some black-box predictor.

Consider for instance the case of a sub-symbolic predictor $\mathcal{P}$ (say, a neural network) trained on the well-known Iris data-set to classify iris flowers as one of the $\functor{setosa}$, $\functor{versicolor}$, or $\functor{virginica}$ types, by only looking at a flower's sepal width ($SW$) and height ($SH$), and petal width ($PW$) and ($PH$).
%
Suppose that the following logic theory $\mathcal{T}$ is extracted by means of some extraction procedure:
%
\begin{equation*}
    \begin{array}{rcl}
        iris(SL, SW, PL, PW, \functor{setosa}) & \leftarrow & PW \leq 0.65 .
        \\
        iris(SL, SW, PL, PW, \functor{versicolor}) & \leftarrow & PW \in\ ]0.65, 1.64] .
        \\
        iris(SL, SW, PL, PW, \functor{virginica}) & \leftarrow & PW > 1.64 .
    \end{array}
\end{equation*}
%
In the hypothesis that $\mathcal{T}$ has an high fidelity w.r.t. $\mathcal{P}$, the as a whole theory provides useful insights about how it works.
%
For instance, it demonstrates how the ``petal length'' feature plays a central role in the strategy followed by $\mathcal{P}$ to classify iris flowers.
%
Furthermore, given a particular query such as $iris(4.9,\, 2.4,\, 3.3,\, 1,\, C)$, and the proof tree corresponding to a resolution attempt of that query w.r.t $\mathcal{T}$, each query-to-solution path is highly informative:
%
\begin{equation*}
    \resizebox{\linewidth}{!}{
        \begin{prooftree}
            \hypo{\bot\quad\text{(a)}}
            \infer1{C \mapsto \functor{setosa} \quad \cancel{1 \leq 0.65}}
            \hypo{\top\quad\text{(b)}}
            \infer1{C \mapsto \functor{versicolor} \quad 1 \in\ ]0.65, 1.64]}
            \hypo{\bot\quad\text{(c)}}
            \infer1{C \mapsto \functor{virginica} \quad \cancel{1 > 1.64}}
            \infer3{iris(4.9,\, 2.4,\, 3.3,\, 1,\, C)}
        \end{prooftree}
    }
\end{equation*}
%
There, path (a) explains why the iris flower above is \emph{not} of type $\functor{setosa}$ -- i.e., because its petal width (1) is greater than 0.65 --, path (b) explains why it is of type $\functor{versicolor}$ -- i.e., because its petal width is in the $0.65\div1.64$ range --, and path (c) explains why the iris flower is \emph{not} of type $\functor{virginica}$---totally analogous to the $\functor{setosa}$ case.

Finally, more user-friendly representations could be generated for both rules and proof tree paths.
%
The topic is further discussed in \cite{xailp-woa2019}.

\paragraph{Why logic}

The exploitation of computational logic as the basic means to draw explanations is strategical under a number of perspectives.
%
First, we argue that symbolic representations (e.g., the language of FOL formul\ae{}), may act as a \emph{lingua franca} for knowledge representation and exchange among heterogeneous intelligent agents---there including humans.
%
Second, we believe that the adoption of symbolic AI to be an enabling choice for the full exploitation of MAS.
%
Finally, this would enable XAI technologies to benefit form the wide gamma of results, methods, algorithms, and toolkits developed under the umbrella of symbolic AI.

In particular, the potential of logic-based models and their extensions is mainly due to their \emph{declarativeness} and \emph{explicit knowledge representation} -- enabling knowledge sharing at an adequate level of abstraction -- modularity, and separation of concerns \cite{OliyaP2011}---which are especially valuable in open (and possibly distributed) systems composed by several intelligent agents.
%
The interested readers may consider reading \cite{xmas-aiiot2019, expectation-extraamas2021} for a more detailed description of the expected benefits provided by a logic based approach to XAI.

\part{How}
\label{part:how}

\chapter{The Role of Logic Based Technologies}

\mypapers{logictech-information11}

Artificial intelligence (AI) is getting ever growing attention from both the academia and the industry, in terms of resources, economical impact, available technologies and widespread adoption in virtually any application area.
%
In fact, more and more industries are adopting and applying state-of-the-art AI techniques, to actively pursue challenging business objectives.

Such a general interest, and technology adoption, has been favoured by two main ingredients:
%
\begin{inlinelist}
    \item the development of advanced technologies even at the micro scale, and
    \item the availability of large amounts of data in the environment around us to learn from.
\end{inlinelist}
%
These ingredients have boosted \emph{sub-symbolic} AI techniques, such as machine learning (ML), -- there including deep learning and neural networks -- aimed at exploiting big data to make predictions and take autonomous decisions---in contrast to the more long-established \emph{symbolic} techniques, based on the formal representation of knowledge and its elaboration via explicit reasoning rules.

The increasing role of intelligent systems in human society, however, raises unprecedented issues about the need to \emph{explain} the behaviour, or the result of, intelligent systems---in the sense of being capable of \emph{motivating} their decision and make the underlying decision process \emph{understandable} by human beings: this is where sub-symbolic techniques, despite their efficiency, fall short.
%
This is especially relevant when AI is exploited in the context of human organisations meant at providing public services---such as, e.g., health care / diagnostic systems or legal advice.
%
There is therefore an emerging need to reconcile and synthesise symbolic and sub-symbolic techniques, exploiting the first to \emph{explain} the latter---the scope of \emph{eXplainable Artificial Intelligence} (XAI) \cite{darpa2016-xai}.

So, just when AI's general focus is on sub-symbolic techniques, symbolic approaches are re-emerging as the means to bring AI closer to the human understanding, helping humans to overcome fears and ethical issues by providing explainability, observability, interpretability, responsibility, and trustability.
%
In this context \emph{logic-based} approaches, despite their age, are finding a new youth, for a number of reasons---first of all, because of their closer relation to the human cognitive process.
%
Moreover, their role in (not just computer) science is well understood -- think for instance of the formal study of programs and semantics in computational models, computational logic, inference as computation, logic programming, and automatic theorem proving \cite{gallier2015,boyer2014-computationallogic}.
%
Last but not least, logic-based approaches have long been at the centre of many successful agent-based models and technologies: indeed, agents reason through logic, and plan and coordinate through logical processes \cite{levesque1984,omicini1995,bordini2006}.
%
Overall, from the XAI spark, wider perspectives are raising also beyond the symbolic/sub-symbolic dichotomy, yet all sharing a logic-based root.

Accordingly, in this chapter we focus on the role that logic technologies have played over the years and are going to play in the forthcoming AI landscape---in particular, for the engineering of intelligent systems.
%
We leverage on that analysis to identify the most promising research perspectives and the open issues characterising the current state of the art.

%===============================================================================
\section{Logic-based AI: Application Areas}\label{sec:application}
%===============================================================================

\begin{figure}
    \centering\includegraphics[width=\linewidth]{figures/logicForAI.png}
    \caption{Logic-based technologies application areas with respect to the main AI categories---namely, AI Foundations, AI for Society, and AI for Business.  Intentionally, the picture only illustrates the AI areas that are closely related to logic.}
    \label{fig:logicBasedAIArea}
\end{figure}

The above techniques have been applied in a variety of fields: \cref{fig:logicBasedAIArea} summarises both the main application areas and their interconnections.
%
For each application area, in the following we \emph{(i)} introduce what the area is about, \emph{(ii)} outline the main sub-categories (if any), \emph{(iii)} discuss the role of logic in each sub-category as well as \emph{(iv)} its benefits and limits, and \emph{(v)} present the main actual applications.

In order to make the comparison actually effective, \cref{tab:logic-usages} and \cref{tab:logic-segments} summarise our findings from two different viewpoints.
The first outlines the strengths of the diverse techniques per application area, that is, where they provide the strongest contribution; the second puts each technique in relation with the different market segments, providing appropriate references to the literature where each technique is used.

\input{tables/tech-tables}

%-------------------------------------------------------------------------------
\subsection{AI Foundations}\label{ssec:ai-foundations}
%------------------------------------------------------------------------

%---------------------------------------
\subsubsection{Formalisation \& Verification of Computational Systems}
%---------------------------------------

% What is this area about
Formalisation and verification of computational systems refer to a collection of techniques for the automatic analysis of reactive systems---in particular, safety-critical systems, where subtle design errors can easily elude conventional simulation and testing techniques.

The main logic-based technology exploited in this field is model checking---nowadays a standard procedure for quality assurance both because of its cost-effectiveness and of the ease of integration with more conventional design methods.
%
The model checker input is a description of the system to be analysed and a number of properties that are supposed to hold: logic is used both to formalise the system description -- states, transitions, model description, and specifications to be verified -- and to express the behavioural aspects, capturing the key properties of information flow.
%
Accordingly, such descriptions are often expressed in temporal and probabilistic logic (and their extension/variations).
%
The model checker input is then a (usually finite-state) description of the system to be analysed, and the expected properties in terms of temporal-logic formulas.

% Example and applications
Application examples (\cref{model-check}) are notably heterogeneous, since model-checking is multidisciplinary and cross-field by its very nature.

% Benefits and Limits
Model checking can provide a significant increase in the level of confidence of a system, enabling system verification a-priori, a-posteriori, and -- what is most relevant nowadays -- at runtime.
%
On the other hand, any validation is, by definition, only as good as the system model itself: so, the validation result strongly depends on the precision of the input model.
%
In addition, model checking can turn out to be unsuitable for data intensive applications, as it increases the number communications.

%---------------------------------------
\subsubsection{Cognitive Agents \& Intelligent Systems}\label{ssec:cognitive-arch}
%---------------------------------------

Cognitive architectures are design methodologies, i.e., collections of knowledge and strategies applied to the problem of creating \emph{situated intelligence}.
%
Here, the main technologies borrow from \emph{multi-agent systems} (MAS), since the cognitive architecture can be considered as the brain of an agent reasoning to solve problems, achieving goals and taking decisions.

Generally speaking, cognitive agents in intelligent MAS straightforwardly exploit the logic-based models and technologies for the rational process, knowledge representation, expressive communication, and effective coordination.
%
Developing an agent means to set up a deduction process: each agent is encoded as a logic theory, and selecting an action means to perform a deduction that reduces the problem to a solution, as in theorem proving.
%
Logic can also be used to represent the agent's surrounding \emph{environment} and the \emph{society} of agents---that is, overall, two of the three key aspects when it comes model the structure and dynamics of non-trivial MAS \cite{soda-aoseI}.

Technologies reflect the above context: many are related to agent programming and reasoning (\cref{sec:symbolic-reasoning}), others to agent reliability and verification (\cref{model-check}).
%
Many others focus on the societal aspect of cognitive architectures, by interpreting society as the ensemble where the collective behaviour of the MAS are \emph{coordinated} towards the achievement of the global system goals.
%
Along this line, \emph{coordination models} glue agents together by governing agent interaction, paving the way towards social intelligence: after the seminal work of Shared Prolog \cite{logictuplespaces-ngc12}, notable examples are \tucson{} \cite{tucson-jaamas2}, \respect{} \cite{respect-scp41}, and AORTA \cite{jensen2014-aorta-emas}.

Within an agent society, agents can enter into argumentation processes to reach agreements and dynamically adapt to changes: so, disputes and conflicts need to be managed in order to achieve a common agreement and establish the winner argument.
%
A number of technologies exist for solving reasoning tasks on the abstract argumentation frameworks \cite{Dung:1995:AAF:220193.220197}.
%
Since problems of this kind are intractable, efficient algorithms and solvers are needed.
%
As discussed in \cite{Gaggl_Linsbichler_Maratea_Woltran_2018}, most solvers are based on logic-based programming or logic frameworks including ASP and SAT-solvers.

Specific technologies exist for dealing with the \emph{environment} abstraction of cognitive architectures, mostly in the \emph{coordination} area.
%
There, coordination/interaction artefacts work as runtime abstractions which encapsulate and support coordination/interaction services, usable as building blocks for designing and governing coordination, collaboration,  competition services inside heterogeneous MASs.
%
\emph{Description spaces with fuzziness} \cite{DBLP:conf/sac/NardiniOV11} and \emph{semantic tuple centres} \cite{DBLP:conf/sac/NardiniVP10} can be read as technologies for \emph{situated interaction \& coordination}, emphasising the \emph{situated} aspect of interaction, i.e., the environment-related aspect.
%
In-between lies \lpaas{} (Logic Programming as a Service), a framework aimed at supporting the distribution of logic knowledge in the environment.
%
There, artefacts work as knowledge repositories (in the form of environment structure and properties) while also embedding the reasoning process (enabled and constrained by the knowledge they embody).

When agents are immersed in a Knowledge-Intensive Environment (KIE), the cognition process goes beyond that of the individual agent, and distributed cognition processes may take place, promoting the idea of \emph{intelligent environment} \cite{distributedcognition-hollan-2000}.
%
In such a way, the environment concept is extended beyond situated action---which, by the way, motivates the inclusion of the semantic web within the macro-area of environmental abstractions.

Moving from \cite{Hendler2001}, the ``Agents {\bf in} the semantic web'' sub-category lists JADL, AgentOWL, and EMERALD, which exploit semantic web technologies to inter-operate.

Hybrid cognitive architectures have recently gained attention to combine symbolic and sub-symbolic (emergent) approaches.
%
Examples are ACT-R \cite{Anderson2003} -- based on the modelling of human behaviour --, CLARION \cite{Sun2005} and LIDA \cite{franklin2006}.

In spite of the simplicity and elegance of the logical semantics in logic-based architectures, some issues do exist.
%
The \emph{transduction} problem\cite{bie2004} has to do with the difficulty of accurately translating the model into a symbolic representation, especially in a complex environment.
%
One more difficulty comes from suitably representing information in such a symbolic form that agents can reason about, with and in a time-constrained environment.
%
Finally, the transformation of percepts may not be accurate enough to describe the environment itself, due to sensor faults, reasoning errors, etc.

%-------------------------------------------------------------------------------
\subsection{AI for Society}\label{ssec:ai-society}
%-------------------------------------------------------------------------------

%---------------------------------------
\subsubsection{Healthcare \& Well-being}
%---------------------------------------

In the healthcare domain, AI typically takes the form of complex algorithms and software systems to emulate human cognition in the analysis of complicated medical data, approximating conclusions without direct human input.
%
The primary aim here is to analyse relationships between prevention or treatment techniques and patient outcomes. AI programs have been developed and applied to practices such as diagnosis processes, treatment protocol development, drug development, personalised medicine, and patient monitoring and care.

In this field, logic is exploited to represent knowledge in a human understandable way, and reason on it via properly-formalised rules---in particular, decision support (symbolic) rules, obtained from domain experts and/or decision models induced from data.

At the same time, symbolic logic scales does not scale easily: knowledge engineers need to extract the logic by interviewing or observing human experts.
%
On the other hand, sub-symbolic techniques such as supervised deep learning scale more easily, but are subject to bias in the training data---and, of course, their outcome cannot be explained.

Here again, the semantic web provides a technical framework for the formal semantic modelling -- i.e. interpretation, abstraction, axiomatisation, and annotation -- of healthcare knowledge in terms of classes, properties, relations and axioms \cite{berners2001semantic}.
%
The semantic web framework for healthcare systems provide notable features:
%
\begin{inlinelist}
    \item semantic modelling of the procedural and declarative healthcare knowledge as ontologies, hence a semantically rich and executable knowledge representation formalism;
    \item annotation -- typically via RDF (Resource Description Framework) -- of healthcare knowledge artefacts guided by the ontological model of the knowledge artefact, so as to characterise the main concepts and relations within the artefact;
    \item representation of different patient data sources in a semantically-enriched formalism, that helps to integrate heterogeneous data sources by establishing semantic similarity between data elements;
    \item semantic interoperability between multiple ontologies, using ontology alignment and mediation methods to dynamically synthesise / shape multiple knowledge resources so as to address all the facets of the specific healthcare problem;
    \item specification of the decision-making logic in terms of symbolic rules, which can be executed using proof engines to infer suitable recommendations/actions;
and
    \item provision of a justification trace of the inferred recommendations, so as to let users understand the rationale of the recommended interventions \cite{Abidi2008}.
\end{inlinelist}

Among the healthcare systems based on reasoning, CARA (Context Aware Real-time Assistant) \cite{yuan2012} aims at providing personalised healthcare services for chronic patients in a timely manner, adapting the healthcare technology so that it fits in both with the normal activities of the elderly and with the working practices of the caregivers.
%
Based on a fuzzy-logic context model and a related context-aware reasoning middleware, CARA provides context-aware data fusion and representation, as well as inference mechanisms that support remote patient monitoring and caregiver notification.

%---------------------------------------
\subsubsection{Law \& Governance}\label{sssec:ai-and-law}
%---------------------------------------

Due to its wide potential impact on society and economy, \emph{AI \& law} is one of today's most relevant research areas.
%
It consists of an interdisciplinary effort combining methods and results from several sources, from deontic logic, norms and agent-based simulation to game theory and norms, normative agents, norms and organisation, norms and trust, norms and argumentation.

Contributions in the field of AI \& law are strongly connected with the aforementioned agents architectures.
%
\emph{Agreement technologies} \cite{ossowski2012}, in particular, is a new vision outlining next-generation, open, distributed systems where interaction between computational agents could be  based on the notion of \emph{agreement}.
%
This calls for
%
\begin{itemize}
    \item a normative context defining the rules of the game, or the ``space'' of agreements that the agents can possibly reach;
    \item an interaction mechanism to establish (first) and enact (then) agreements; and
    \item a joint research effort from several fields -- including, but not limited to, multi-agent systems, semantic technologies, social sciences -- aimed at fruitfully combining results and contributions from all such areas---like, for instance, semantic alignment, negotiation, argumentation, virtual organisations, learning, real time, and others.
\end{itemize}
%
Semantic web standards provide a good basis for representing the knowledge of local agents, the functionalities and everything needed to achieve a goal in agreement with other agents.

However, the formalisms behind these technologies fall short when dealing with the distributed, open and heterogeneous nature of AT systems where agents may have different views of the world and, therefore, mutually-inconsistent knowledge bases.
%
To cope with this issue, new logical formalisms -- specifically aimed at handling situations where pieces of knowledge are independently defined in different contexts -- have been defined, extending classical logics in order to deal with incomplete and \emph{defeasible} knowledge.
%
Logic is thus exploited to represent the knowledge with a high degree of peculiarity (for instance defeasibility, but also the possibility to discern among permission, obligation or beliefs in deontic logic), and to reason over such knowledge.

Many interesting experiments have been performed in this application area.
%
Notable defeasible argumentation implementations, aimed at supporting reasoning and resolve inconsistencies, are Defeasible Logic Programs \cite{garcia2004}, ASPIC \cite{modgil2014}, and ABA \cite{dung2009}.
%
Several other applications use ontologies and legal search engines \cite{solarte2016}, which exploit advanced search technology from AI, data mining, data analytics, ontologies and natural language processing \cite{kerikmae2018}.
%
The main issues that remain unsolved in this area is that a unique and general framework for dealing with norms and argumentative issues is still missing: in fact, most solutions are too narrow in scope, tailored to specific use cases, other than being possibly weak from the software engineering perspective.

In short, logic-based approaches in the legal field \cite{Prakken2015}
%
\begin{itemize}
    \item help formalise legal norms and concepts in a clear and understandable way, thus enabling verification and the detection of
unfair policies, or the violation of essential rights;
    \item support explanatory and arguable decisions in the regulatory context.
\end{itemize}

In general, however, current tools are unable to imitate advanced cognitive processes such as human reasoning, understanding, meta-cognition or the contextual perception of abstract concepts that are essential for legal thinking.
%
Indeed, a lawyer's work is often very complex, implying the management and processing of huge amounts of data, where to find correlations between facts and circumstances, and formulate reasoned opinions and action guidelines taking into account all the applicable rights and obligations.
%
This is why the process of understanding and formulating a decision is mostly creative---the result of a complex cognitive process.


%---------------------------------------
\subsubsection{Education}\label{sssec:ai-and-education}
%---------------------------------------

AI has been part of many e-learning platforms for a long time, with applications ranging from personalised learning, recommendation of resources, automated grading, to prediction of attrition rates---to name just a few.
%
The rapid expansion of the \emph{educational technology} industry is now further pushing and exploiting advanced AI-enabled learning technologies.

Within this area, symbolic AI techniques have been used in adaptive educational systems, such as fuzzy logic, decision tree, etc. there, logic has been mainly applied for knowledge management and recommendation.
%
In some systems, for instance, the focus is on examining and assessing the student characteristics in order to generate students' profiles, to be used for evaluating their overall level of knowledge and, consequently, as a basis for prescribed software pedagogy.
%
Symbolic AI approaches are used to support the diagnostic process, so that the course content can be adjusted to cater each student's needs.
Some of them, in addition, are also used to learn from student's behaviour so as to adjust the prescribed software pedagogy.

Applications are related to semantic web technologies, contextualised to e-learning so as to adapt instruction to the learner’s cognitive requirements in three ways---background knowledge, knowledge objectives and the most suitable learning style \cite{guangzuo2004,sancho2005}.
%
Over the years, fuzzy logic techniques and logic MAS have also been experimented for e-learning purposes.
%
In particular, in \cite{almohammadi2013,chrysafiadi2013}, a fuzzy logic-based system learns the users' preferred knowledge delivery to generate a personalised learning environment; whereas in \cite{gong2006} agents detect, recognise, eliminate, and repair the faults of the e-learning course, keeping the system up \& working, providing robustness.
%
Another interesting application in the domain of formal logic proofs, taken as the base of several further extensions, is the Logic-ITA (Intelligent Teaching Assistant) web-based system \cite{yacef2005}: its purpose is to soothe the issues caused by large classes or distance learning, acting as an intermediary between teacher and students.
%
On the one hand, it provides students with an environment to practice formal proofs, giving proper feedback;  on the other, it allows teachers to monitor the class's progress and mistakes.

Although the impact on classrooms has been relatively minor so far, the potential of AI in education is high and likely to increase, as demonstrated by the many European actions / projects currently in place \cite{pedro2019,tuomi2018}.
%
The main challenges and issues concern the creation of a sustainable educational environment, capable of developing equitable education even for the least developed countries---to be dealt with at the suitable political level.

%-------------------------------------------------------------------------------
\subsection{AI for Business: Automation \& Robotics}
%-------------------------------------------------------------------------------

Automation is probably the earliest and perhaps most impactful application area for AI, as it represents the first step towards machine autonomy.
%
Autonomy, in turn, is highly desirable whenever there is a need of re-designing, re-building, or re-programming machines while the deployment context evolves.
%
\emph{Autonomous} machines differ from \emph{automatic} ones in that designers no longer need to forecast any possible situation, because the machine is programmed for learning or planning.
%
This is particularly interesting in \emph{cyber-physical systems} (CPS) \cite{baheti2011} and \emph{robotics}, where machines have a physical body that makes them capable of affecting (or being affected by) the physical world.

Needless to say, applications of automation and robotics in industry are manifold, and so are the corresponding research lines.
%
In the following we explore the role and impact of logic-based paradigms and technologies in such areas.

%---------------------------------------
\subsubsection{Planning \& Task Allocation}
%---------------------------------------

Planning and scheduling are one of the oldest fields in AI, also related to multi-agents and cognitive architectures: research has mainly to do with the decision making process that determines what, when, where, and how to reach a goal and compute a task.
%
There, logic is exploited to represent the knowledge domain, its constraints, and the reasoning mechanism.

Logic-based scheduling methodologies include \emph{rule-based} approaches and \emph{constraint-guided} search.
%
Rule-based scheduling methods aim to emulate the decision-making behaviour of human schedulers, captured in terms of suitable logic rules.
%
Correspondingly, rule-based systems are typically envisioned as a means to replicate the actions of experienced humans with specific scheduling skills.
%
Unsurprisingly, this is one the most successful application domains of CLP techniques: the scheduler goal is to identify feasible solutions which balance different constraints or schedule requirements.

Applications spread from manufacturing to traffic scheduling and management (e.g., autonomous vehicles, aircraft, \ldots), up to urban search and rescue activities (e.g., traffic assignment in natural disaster evacuations, \ldots), and many others.
%
A typical example of a constraint-based scheduling application is ATLAS \cite{akbarinia2006}, which schedules the production of herbicides at the Monsanto plant in Antwerp.
%
PLANE \cite{Simonis2001} is another system used at Dassault Aviation to plan the production of the military Mirage 2000 jet and the Falcon business jet: the objective is to minimize changes in the production rate, which has a high set-up cost, while finishing the aircraft just in time for delivery.
%
The COBRA system \cite{Simonis2001} generates workplans for train drivers of North Western Trains in the UK: each week, about 25000 activities need to be scheduled in nearly 3000 diagrams on a complex route network.
%
The DAYSY Esprit project \cite{simonis2000} and the SAS-Pilot program \cite{baues1994} consider the operational re-assignment of airline crews to flights.
%
The STP (Short Term Planning) application at Renault \cite{wallace1996} assigns product orders to factories so as to minimise transportation costs.
%
The MOSES application by COSYTEC \cite{wallace1996} schedules the production of compound food for different animal species, eliminating contamination risks while satisfying customer's demand at the minimal cost.
%
FORWARD \cite{simonis1995} is a decision support system, based on CHIP, used in three oil refineries in Europe to tackle all the scheduling problems occurring in the process of crude oil arrival, processing, finished product blending and final delivery.
%
Finally, Xerox has adopted a constraint-based system for scheduling various tasks in reprographic machines (like photocopiers, printers, fax machines, etc.); the scheduler is supposed to determine the sequence of print making and coordinate the time-sensitive activities of the several hardware modules that make up the machine configuration \cite{bistarelli2001}.

Overall, the CLP approach faces well some of the key issues such as development time, nodes visited in the search tree, number of generated feasible solutions, and efficiency.
%
At the same time, the very nature of such systems mandates for considerable development and tuning effort for each new application, as there is no expert to emulate.
%
More generally, the main two issues are \emph{i)} the lack of a structured way to carry the insight gained from one application to the next, and \emph{ii)} the complexity of generating the symbolic knowledge that fully describes the application domain.

%---------------------------------------
\subsubsection{Robotics \& Control}
%---------------------------------------

Cognitive architectures, planning, and task allocation techniques have been widely applied to robotics and control system: indeed, robotics applications translate the agent abstraction of cognitive architecture into a mechanical robot capable of doing action and taking decision.

Logic in robotics is, much more than elsewhere, tailored to the specificity of the application field, since control mechanisms need to control the robot sensors and actuators, along with all their low-level control software (for instance, robot motion mandatorily requires a set of feedback control primitives in order to keep motion coherent).
%
More generally, control systems are present in lifts, photocopiers, car engines, assembly lines, power stations, etc.

Again, the logic-based approaches (and technologies) that are mostly adopted in this context are CLP, fuzzy logic, and temporal logic: in fact, many works dealing with robotic reasoning \cite{Ferrein2008} exploit languages and technologies detailed in \cref{sec:symbolic-reasoning}.
%
CLP-based applications are typically at the smaller end, where it is still possible to prove that some global properties can be guaranteed with a given control.
%
Thus, CLP is often exploited to build control software for electro-mechanical systems with a finite number of inputs, outputs, and internal states: each component is connected to a small part of the overall system, so its behaviour can be captured quite simply.
%
However, when the system is considered as a whole, the number of global states can become very large: this calls for a smart technology that is able to handle such combinatorial explosion \cite{lytras2008}.

On the other side, many control system have been developed exploiting a fuzzy logic approach for dealing with real data which are sometimes imprecise, uncertain, complex, and with a high degree of randomness.
%
Due to its good tolerance of uncertainty and imprecision, fuzzy logic has gained wide application in the area of advanced control of humanoid robots.
%
For the same reason, fuzzy system are powerful tools to face crucial problems in industrial engineering
and technology, such as risk management or product quality assurance, as well as in intelligent decision support system for adaptive industrial engineering \cite{chilwal2020,rastogi2015,patil2012,zhu2004,center1998}.
%
Also, the hybrid techniques based on the integration of neuro-fuzzy networks, neuro-genetic algorithms, and fuzzy-genetic algorithms are of great importance in the development of efficient algorithms \cite{Tahmasebi2012}.

Temporal logic approaches and technologies have been exploited, e.g., for controlling robot motion or planning activities \cite{finucane2010,fainekos2009}, because of their ability to reason over the time and its change, which makes it possible to build control laws to be verified over the time elapse.
%
This is specially relevant for mobile robots, whose specifications are often temporal---even though time is not necessarily captured explicitly.
%
For example, a swarm might be required to reach a certain position and shape eventually, or maintain a size smaller than a specified value until a final desired value is achieved.
%
Other examples are collision avoidance among robots, obstacle avoidance, and cohesion, which are always required.
%
In a surveillance mission, a selected area needs be visited ``infinitely often'' \cite{Kloetzer2007}.

%===============================================================================
\section{Discussion}
%===============================================================================

The new AI era calls for two fundamentals enabling factors:
%
\begin{inlinelist}
    \item the availability of big computing power even in minimal spaces, and
    \item the availability of huge amounts of context-related data.
\end{inlinelist}
%
Such factors on the one side make it possible to learn from experience, which is the playground of  sub-symbolic algorithms; on the other, make logic algorithms, historically used for expert systems and hence very effective as for transparency and explainability, computable \emph{in good time}.

Big data have naturally led sub-symbolic approaches to prevail, because of their effectiveness in elaborating and getting valuable results from context-related data, learning trends and repeating patterns: yet, their inherent black-box nature is a clear issue.
%
This is precisely where the integration with symbolic approaches can naturally provide added-value, complementing symbolic and sub-symbolic approaches with each other.
In fact, the two main weaknesses of symbolic approaches concern specifically \textit{(a)} the extraction of context-related knowledge, and \textit{(b)} computational complexity---the first being the natural territory of sub-symbolic approaches.

Computational complexity, in its turn, can be partially addressed thanks to the exponential increase of computational power, by suitably exploiting  parallelism, as well as by re-defining and re-tuning symbolic approaches so as to fit nowadays computing paradigms and architectures---as in the case, for instance, of \lpaas{} \cite{lpaas-tplp18}.
%
However, it still remains an issue in some application contexts, often leading to higher processing costs.
%
An example is propositional interval temporal logics (ITL) \cite{goranko2004}, which provide a natural framework for representing and reasoning about temporal properties, but whose computational complexity constitutes a barrier for extensive use in practical applications.
%
To cope with this issue, several approaches exploit constraints or adopt a locality principle; in other cases, as in DLs, complexity is decreased at the price of a limited expressiveness.
%
For instance, in Bowman and Thompson’s decision procedure for propositional ITL, decidability is achieved by means of a simplifying hypothesis -- the locality principle -- that constrains the relation between the truth value of a formula over an interval and its truth values over initial sub-intervals \cite{holldobler2008}.
%
Tableau-based decision procedures have been recently developed \cite{dellaMonica2013} for some interval temporal logics over specific classes of temporal structures, without resorting to any simplifying assumption.

Parallelism and concurrent programming techniques are another valuable tool to deal with complexity.
%
The computing power of multi-level parallelism (MLP), in particular, constitutes a promising technique to facilitate concurrent programming while delivering performance comparable to that of fine-grained locking implementations---see for instance \cite{larus2007} and \cite{jacobsen2013}.

To recap, due to their strong foundations and features, logic-based technologies have the full potential to power symbolic approaches in such integration, opening intriguing perspectives currently under exploration in many research contexts.
%
%as discussed in \xs{perspective}.
%%
%\xt{logic-usages} and \xt{logic-segments}, in particular, point out the very connections among the diverse logics, their application areas, and market segments.
%%
%\xt{logic-usages} highlights that cognitive agents and robotics are the application areas that exploit the widest spectrum of logic-based approaches, whereas other areas typically rely on a smaller subset.
%%
%Reading the table orthogonally, first-order logic, description logic, and fuzzy logics appear to be the most general purpose ones, the others being more specific.
%%
%In its turn, \xt{logic-segments} puts in evidence that some logics -- such as description logic and fuzzy logics -- are widely used in a variety of market segments, while the same does not hold for other logics, like BDI, defeasible reasoning, and probabilistic logic, thus opening a space of action for their possible expansion.
%%
%BDI and defeasible reasoning, in particular, could effectively help to enable intelligent systems, intended as agents immersed in a continuous collaboration with humans, to behave and reason more  ``like a human''.

Overall, the synergy of symbolic and sub-symbolic approaches appears to be a viable and promising option to face key issues in today's intelligent systems---namely, the need of explainable, responsible, ethical AI.
%
In particular, the adoption of symbolic approaches can help to achieve the key features of e-justice, fairness, ethics and transparency.

\chapter{Technological State of the Art}

\mypapers{lptech4mas-jaamas35,lptech4mas-aamas2021}

Precisely when the success of artificial intelligence (AI) sub-symbolic techniques makes them be identified with the whole AI by many non-computer-scientists and non-technical media, symbolic approaches are getting more and more attention as those that could make AI amenable to human understanding.
%
Given the current status of AI technologies -- mostly focussed on sub-symbolic approaches successful in well-delimited application scenarios --, a key issue for intelligent system engineering is \emph{integration} of the diverse AI techniques: in software engineering terms, not just how to integrate diverse technologies, but also how to preserve \emph{conceptual integrity} when highly-heterogeneous approaches -- bringing about manifold abstractions of various nature -- are put to work together.

The most straightforward and generally-acknowledged way to address the above issue is by using \emph{agents} and \emph{multi-agent systems} (MAS).
%
Agents and MAS have been at the core of the design of intelligent systems since their very beginning:  their long-term connection with \emph{logic-based technologies} might open new ways to engineer \emph{explainable intelligent systems}.

This is why understanding the current status of \emph{logic-based technologies for MAS} is nowadays of paramount importance and why our work focus on logic-based approaches in MAS: they are to be counted among the most promising techniques for building understandable and explainable intelligent systems.
%
Furthermore, given the unavoidable push towards the exploitation of intelligent applications, focussing on logic-based \emph{technologies} is of strategical importance.
%
Accordingly, understanding and representing the current status of the available logic-based MAS technologies is a key step -- from both an historical and an avant-garde perspective -- to let MAS researchers and practitioners identify the actually usable methods for the engineering of intelligent systems.

To this end, in \cite{lptech4mas-jaamas35} we provide a Systematic Literature Review (\slr{}) driven by the primary research question: ``What is the role played by logic-based technologies in MAS nowadays?''.
%
In particular, the \slr{} aims at understanding which and how many logic-based technologies for MAS can be considered ready enough to face the challenges of modern and future intelligent systems, other than identifying what is missing and what research directions require further attention.
%
Accordingly, the goal is to provide an exhaustive assessment of the available logic-based technologies for MAS, by performing a carefully-designed \slr{} on the subject.

\section{Method}

The \slr{} follows a well-founded, understandable, and reproducible method defining how to find, include/exclude, and analyse papers describing logic-based MAS technologies.
%
It relies on the standard \slr{} method: we carried out a manual retrieval, filtering, analysis, and categorisation of huge number of papers, by repeating 8 queries on 6 search engines (Google Scholar, IEEE Xplore, ScienceDirect, SpringerLink, DBLP, ACM Digital Library) and 5 specific conference/workshop proceedings.
%
To keep a tight focus on the \emph{reproducibility} of the whole process, the methodological approach, and the inclusion/exclusion and analysis criteria are carefully designed and described in detail.
%
In particular, we only included works defining or exploiting some \emph{logic-based MAS technology}.
%
A specific definition of \emph{logic-based MAS technology} is provided as well, explicitly requiring the provable availability of
%
\begin{inlinelist}
    \item a clearly identifiable logic-based MAS-related framework into the literature, and
    %
    \item some actual software reification of that framework.
\end{inlinelist}

%
Out of the retrieves papers, we selected 271 documents and there identified 47 technologies, classified them according to both a MAS and a logic perspective, and analysed from the technology viewpoint.
%
Accordingly, the technologies selected in our SLR are analysed and assessed from two different perspectives -- namely, the MAS and the logical perspective --, thus discussing the specific MAS- and logic-related aspects defined, tackled, or exploited by each technology.
%
Along the MAS perspective, we categorise the selected technologies w.r.t.\ the main MAS abstractions they relate to---agents, societies, environment.
%
Along the logic perspective, we categorise the selected technologies w.r.t.\ the sort of logic they relate to---thus choosing among first-order logic, description logic, BDI logic, etc.
%
Such categorisations reveal an uneven distribution of logic-based technologies along both MAS abstractions and logics, and highlighting research opportunities on abstractions and logics which are currently in an urgent need of technologies---such as the environment abstraction and the defeasible logic.

We also perform a technical assessment of each technology, according to number of technological criteria including, but not limited to,
%
\begin{inlinelist}
    \item source-code organisation,
    %
    \item maintenance status,
    %
    \item target platform(s),
    %
    \item availability of executable as well as documentation,
    %
    \item some technical assessment involving the run of executables and available examples.
\end{inlinelist}
%
Arguably, the analysis enables a detailed discussion on the current state of logic-based MAS technologies---in particular highlighting their state of maintenance.
%
More precisely, we consider technologies as unmaintained based on the last provable edit involving either the technology source code or any of its software artefacts.\footnote{Since our original assessment (September 2020), some technologies described as unmaintained reworked their repositories, code and/or documentation---as in the case of DALI (\url{https://github.com/AAAI-DISIM-UnivAQ/DALI}) and MCAPL (\url{https://autonomy-and-verification.github.io/tools/mcapl}).}

%%===============================================================================
\section{Main outcomes}\label{sec:outcomes}
%%===============================================================================

The outcome of the \slr{} highlights that, as far as logic-based technologies for MAS are concerned, there is still room for technological advancements---except for a few relevant success stories.
%
In fact, despite the enormous technological effort clearly carried out by the MAS community in the last decades, several surveyed technologies cannot be considered as mature and ready for use in the new challenging contexts required by AI.
%
Several technologies are in fact unmaintained, outdated, or just proof of concepts.

In our original work the discussion attempts to provide a comprehesive answer to all the \slr{} research questions.
%
In the following we summarise some general remarks in relation to key features of modern intelligent systems, namely:
%
\begin{enumerate}[label=\emph{(\roman*)}]
    \item inherent distribution and decentralisation and deep intertwist with domains like the Internet of (Intelligent) Things (Io(I)T) and Cyber-Physical Systems (CPS);
    %
    \item support to key properties such as robustness, efficiency, interoperability, portability, standardisation, situatedness, and real-time support;
    %
    \item need to reconcile and synthesise symbolic and sub-symbolic AI, exploiting the former to \emph{explain} the latter so as to overcome fears and ethical issues posed by AI by providing for explainability, observability, interpretability, responsibility, and trustability---the scope of XAI.
\end{enumerate}

%----
\subsubsection{Applicability to distributed domains such as \iot{} and CPS}
%----

The existing agent-oriented logic-based solutions applicable to the \iot{} and CPS are only available for a specific and limited set of devices and platforms.
%
For instance, Agent Factory Micro Edition (AFME) \cite{afme-iccs2006} enables the execution of a deliberative agent on top of mobile phones with CLDC/MIDP profiles and Sun-SPOT sensor by means of TCP/IP and Zigbee protocols.

However, some technologies, more than others, are explicitly designed to support \iot{} domains and CPS.
%
For example, the \lpaas{} architecture \cite{lpaas-tplp18} is designed to promote distributed intelligence for the \iot{} world---offering logic programming as a service, and explicitly addressing the requirements and issues of cloud and edge architectures.
%
Analogously, the situated coordination approach promoted by the \tucson{}/\respect{} model and technology can be explicitly exploited to handle situatedness in MAS as a coordination issue.
%
Also, \tucson{} \cite{tucson-jaamas2} provides the main abstractions for \iot{} environments: environmental resources can be sources of perceptions (like sensors), targets of actions (like actuators), or even both.

Finally, there are technologies that are not explicitly meant to address the \iot{} and CPS domains, but still let us suppose they would be easily portable to those domains---because of their standard compliance, interoperability, and portability features.
%
Among the many, \jason{} \cite{jason-clima2005} supports interoperability with non-\jason{} agents via \jade{} \cite{jade-mapbook2005} through \fipa{}-ACL communication \cite{fipa-acl}.
%
Similarly, there are extensions to \jack{} \cite{jack-mapbook2005} that make it work in open systems.
%
Finally, the Teleo-Reactive \cite{nilsson2001-teleoreactive} approach has been often exploited to facilitate the development of the \iot{} systems as a set of communicating Teleo-Reactive nodes.

%----
\subsubsection{Symbolic and sub-symbolic integration.}
%----

With respect to the need to reconcile and integrate symbolic and sub-symbolic techniques, none of the selected technologies has been experimented yet \cite{xaisurvey-ia14}, due to their original design purpose out of this scope.
%
However, we argue that portable and interoperable technologies might be more suitable for the integration.
%
Anyway, the field is still unexplored and represents a frontier research domain.

%----
\subsubsection{Can existing technologies be labelled as ready? If not, what is missing?}
%----

The role of logic-based technologies in MAS nowadays exhibits a huge potential for covering the vast majority of intelligent system abstractions.
%
However, just a few among the technologies surveyed can be actually labelled as \emph{ready-to-go}, in particular when considering the new challenges for symbolic technologies in AI.

Even though 10\% of the selected technologies can be considered as mature -- in terms of cross-platform support, code quality, and ease of distribution in heterogeneous environments --, most of the times they have not been tested in pervasive and real-world scenarios, yet.
%
This implies, at least, that further research and technical activity are required to ensure that any technological barrier can be overcome.
%
Furthermore, integration with sub-symbolic techniques remains a \emph{nice-to-have} feature, but it is not actually a thing in any MAS technology, for the time being.
%
Nevertheless, the selected technologies are an excellent starting point for \emph{(i)} highlighting the advantages of logic-based technologies, and  \emph{(ii)} broadening the scope of research towards the directions envisioned.

In the end, we forward the interested readers to the original SLR for the full details \cite{lptech4mas-jaamas35}.

%\section{Current State of Logic-Based Technologies}

%\cite{lptech4mas-aamas2021}
%\cite{lptech4mas-jaamas35}
%\cite{logictech-information11}

%\section{Current State of Machine Learning Technologies}

%\section{Current State of XAI Technologies}

%\cite{xaisurvey-ia14}

%\chapter{Need for An Open Ecosystem for Logic-Based AI}
%
%\cite{cco-softwarex-2021-2pkt}

\note{Take more info from the survey?}

\note{A chapter on the state of Prolog systems?}

\chapter{The 2P-Kt Ecosystem for Logic-Based AI}\label{chap:ecosystem}

\mypapers{cco-softwarex-2021-2pkt,kotlindsi4prolog-woa2020}

While their impact on the \emph{symbolic} branch of AI is well established, many emergent AI techniques leverage logic to make data-driven AI either more predictable or more understandable.
%
This is why the need for solid, interoperable, general-purpose \emph{logic-based technologies} is nowadays more compelling than ever.
%
Most of the logic-based technologies proposed so far are typically either built on top or as extensions of the Prolog language.
%
Even when this is not the case, \emph{monolithic} solutions are built around different inference procedures, unification mechanisms, or knowledge representation techniques.

This chapter stems from the idea that logic-based technologies should be neither constructed as Prolog-centred monoliths nor tailored to a specific semantics or language.
%
Instead, in order to maximise their impact on AI, logic-based technologies should welcome the manifold contributions coming from the LP playground, supporting the exploitation of as many mechanisms as possible, in an unopinionated way.
%
As a foundational step in that direction, we present \twopkt{}, a reboot of the \tuprolog{} project offering a general-purpose, extensible, and interoperable \emph{ecosystem} for logic programming and symbolic AI.

\section{The Need for an Ecosystem}
\label{sec:motivation}

In spite of the wide availability of logics, inference rules, and resolution strategies in the LP literature, only a relatively small amount of them have been reified into actual logic-based technologies.
%
Among these, the Prolog language \cite{ColmerauerR93} is by far the most successful story \cite{logictech-information11}.
%
It consists of a well-defined language \cite{prologISO-pt1,prologISO-pt2} coming with several implementations \cite{homepageBprolog,homepageCiao,homepageEclipse,homepageSicstus,homepageSwi,homepageXsb,homepageTau}.

While standard implementations of Prolog target first-order logic (FOL) via SLDNF inference rule \cite{robinson1965,Kowalski1974,Clark77} and depth-first resolution strategy, most implementers have extended Prolog to support other resolution strategies as well.
%
This is the case of Prolog implementations supporting for instance, \emph{constraint logic programming} (CLP) \cite{jaffar1987}, \emph{constraint handling rules} (CHR) \cite{Fruhwirth98}, \emph{tabled resolution} \cite{SwiftW12}, etc.

Thanks to the versatility of FOL, it is a common practice in LP to either develop logic-based technologies either \emph{on top} of Prolog or \emph{from scratch}.
%
In the former case, the resulting logic-based technologies tend to be poorly interoperable -- as strictly Prolog-dependent \cite{kotlindsi4prolog-woa2020} --, while in the latter case they tend to be very narrow in scope---as heavily tailored on a particular domain.

Building logic-based technologies on top of Prolog is often preferred as they automatically inherit Prolog basic mechanisms, including e.g.\ the capability of
%
\begin{inlinelist}
    \item representing data structures via logic terms,
    \item knowledge via Horn clauses,
    \item logic unification,
    \item efficient in-memory indexing of logic information,
    \item a flexible inference rule, and
    \item meta-level programming.
\end{inlinelist}
%
This is the smartest strategy when novel logic-based technologies must be quickly bootstrapped, yet it may easily result in poorly-interoperable, Prolog-tailored solutions.
%
Conversely, when Prolog capabilities are not adequate for the particular problem at hand, logic-based technologies may be designed from scratch.
%
This commonly involves re-designing and re-implementing most LP features from scratch.

In \cite{Sterling1996}, Sterling states that logic unification is by itself the major contribution of LP to software engineering---thus singling a specific feature out of Prolog for its value and benefits.
%
Along this path, we argue that many aspects of LP may be useful in AI by themselves, and each contribution could be conveniently reified into some individually-usable software library.
%
Accordingly, our work aims at the creation of an \emph{open ecosystem} for interoperable, general-purpose LP libraries, virtually supporting multiple logics, inference rules, and resolution strategies, and possibly factorising any shared aspect---e.g. terms and clauses representation, unification, in-memory storage, (de)serialisation, etc.

In the early 2000s, the idea of LP as a key \emph{technology}-enabler of intelligent application was already in place.
%
The \tuprolog{} project \cite{tuprolog-padl01} was proposed for this purpose.
%
It consists of a lightweight \emph{malleable}, object-oriented, Java-based implementation of Prolog \cite{tuprolog-sac08} which can be used as a library for JVM projects.
%
Despite many versions have been proposed along the years -- bringing new features, or more platforms support \cite{2p-alpnews2013} --, and many research products have been built upon it -- such as \tucson{} \cite{tucson-jaamas2}, \respect{} \cite{respect-scp41}, \lpaas{} \cite{lpaas-bdcc2}, or \tenderfone{} \cite{blockchainmas-applsci10},  \argtwop{} \cite{arg2p-cilc2020}, etc. --, it still consists of a \emph{monolithic} library targetting Prolog \emph{alone}.

Accordingly, this chapter stems from the idea that Prolog is not the silver-bullet for logic-based technologies, and the belief that LP should not be reduced to Prolog alone.
%
For this reason, we present \twopkt{}, a \emph{reboot} of the \tuprolog{} project aimed at providing a common technological ground for LP.
%
Acknowledging that most mechanisms in LP have the potential to be of general value, not necessarily tailored to any specific logic, inference rule, or resolution strategy, \twopkt{} consists of a logic-based \emph{ecosystem} for symbolic AI, designed and implemented by taking openness, modularity, extensibility, and interoperability into account.

More precisely, the \tuprolog{} project has been completely re-designed and re-written, splitting LP functionalities into minimal, loosely-coupled, Prolog-agnostic, individually-usable, multi-platform \emph{modules}.
%
The rationale behind this choice is to enable the incremental addition of novel LP functionalities to the \twopkt{} ecosystem -- possibly targeting other inference rules and search strategies --, minimising duplication of features and reusing pre-existing ones, while supporting as many programming platforms as possible.

On the long run, \twopkt{} aims at becoming a comprehensive technological playground supporting several sorts of logics -- e.g. first-order, higher-order, temporal, deontic, etc. -- and mechanisms---e.g. deductive, inductive, abductive, probabilistic reasoning, etc.

Finally, a non-negligible effort is devoted to keep \twopkt{} widely interoperable at the technological level with as many platforms as possible---to maximise the pool of potential adopters.
%
This is why most \twopkt{} modules are Kotlin Multiplatform projects -- currently supporting the JVM, JS, and Android platforms --  while others are expected to be supported soon---e.g. MacOS, iOS, .NET, and Python.

%\section{Software description}
%\label{sec:sw-description}

%\twopkt{} is deeply rooted in LP, a programming paradigm based on computational logic \cite{lloyd1990computational,Nerode1996}.
%
%In LP, programs are typically \emph{theories} (a.k.a. \emph{knowledge bases}, KB), i.e. collections of sentences in logical form, expressing \emph{facts} and \emph{rules} about some domain.
%%
%These are often in the form of \emph{clauses}, i.e.:
%\[ Head \impliedBy Body_1,\ ...,\ Body_n \]%,
%where both $Head$ and $Body_i$ are \emph{atomic} formul\ae{}, and the whole sentence is read declaratively as logical implication ($Head$ is implied by all $Body_i$).
%%
%If $n = 0$, the clause is called \emph{fact}, \emph{rule} otherwise.
%%
%An atomic formula is an expression in the form $P(t_1,...,t_m)$ where $P$ is a $m$-ary predicate ($m \geq 0$), and $t_1,...,t_m$ are \emph{terms}.
%%
%Terms are the most general sort of data structure in LP languages.
%%
%They can be \emph{constant} (either \emph{numbers} or \emph{atoms}/strings), \emph{variables}, or recursive elements named \emph{structures}.
%%
%Structures are used to represent clauses, lists, sets, or other sorts of expressions.
%
%Logic \emph{solvers} exploit KB to answer users' \emph{queries} via some inference procedure and resolution strategy.
%%
%For instance, Prolog interpreters exploit a \emph{deductive} procedure rooted into the SLDNF resolution principle \cite{Kowalski1974, Clark77}, and a depth-first strategy.
%%
%Yet, other options exist like, e.g., abductive \cite{FungIff97}, inductive \cite{Muggleton94}, probabilistic \cite{RaedtK15}, inference.
%%
%Each of them represents a particular reification of a logic solver.
%
%A common mechanisms in LP is the \emph{unification} algorithm \cite{MartelliMontanari1982} for constructing a \emph{most general unifier} (MGU) for any two suitable terms.
%%
%Provided that such an MGU exists, the subsequent application of the resulting substitution to the terms, renders them syntactically equal.
%%
%This is a basic brick in virtually all LP algorithms, regardless of the particular inference rule.
%
%Summarising, LP leverages several mechanisms -- terms and clauses representation, knowledge base storage, unification, resolution, etc. --, which constitute the basis of any logic solver.
%%
%Subsets of these mechanisms may be useful \textit{per se}.
%%
%\twopkt{} makes all these mechanisms \emph{individually} available, while easing the construction of novel mechanisms on top of the existing ones.

\section{Overall Design}
\label{ssec:sw-architecture}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/2p-kt-project-map.pdf}
    \caption{\twopkt{} project map: LP functionalities are partitioned into some loosely-coupled and incrementally-dependent modules}
    \label{fig:2p-kt-project-map}
\end{figure}

\twopkt{} is deeply rooted in CL, a programming paradigm based on computational logic \cite{lloyd1990computational,Nerode1996}.
%
Hence, from an architectural perspective, \twopkt{} is a framework supporting the creation of logic-based software via several loosely-coupled \emph{modules}---each one tailored on a particular aspect of CL.

To further support reusability, each module factorises a small number of related functionalities, via a compact API composed by OOP types and methods.
%
As modules are the most basic deployable units in \twopkt{}, major LP functionalities are partitioned into modules on a per-usage basis, to make them selectively usable as dependencies in other projects.
%
The \twopkt{} ecosystem itself is attained by incrementally combining such modules, as depicted in \cref{fig:2p-kt-project-map}.
%
Accordingly, to maximise interoperability, \twopkt{} modules are individually available as pre-compiled libraries both on Maven Central Repository (MCR)\footnote{\url{https://search.maven.org/search?q=g:it.unibo.tuprolog}} -- for JVM-, Android- or Kotlin-based contexts -- and on the NPM Registry\footnote{\url{https://www.npmjs.com/org/tuprolog}} -- for JS-based contexts --, whereas a detailed description of their API is available on the Web as part of \twopkt{} documentation.
%
% In the latter case, self-executing Jars for \twopkt{} GUI and CLI are available on the GitHub Release page\footnote{\url{\twopktRelease}} of the project, while a Web-based GUI is available at \cite{2P-Playground} for direct in-browser usage in a serverless fashion.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/2p-kt-api.pdf}
    \caption{\twopkt{} public API: a type is provided for each relevant concept in LP}
    \label{fig:2p-kt-api}
\end{figure}

If all \twopkt{} modules were merged together, the most relevant aspects of their API could be summarised as in \cref{fig:2p-kt-api}.
% depicts the main aspects of \twopkt{} public API.
%
The diagram points out how all relevant aspect of LP are reified into types: e.g.
%
\begin{itemize}
    \item logic \texttt{Term}s (as well as any specific sort of term, e.g. \texttt{Var}iables, or \texttt{Struct}ures, etc.),
    \item logic \texttt{Substitution}s, unification, and MGU (computed by an \texttt{Unificator}),
    \item \texttt{Clause}s (there including \texttt{Rule}s, \texttt{Fact}s, and \texttt{Directive}s),
    \item knowledge bases and logic theories (e.g. the \texttt{Theory} type),
    \item automatic reasoning, via the \texttt{Solver} interface, and
    \item logic \texttt{Solution}s---computed by \texttt{Solver}s in response to queries.
\end{itemize}
%
There, interfaces are used to expose relevant aspects, in order to keep the system extensible.
%
Developers may e.g.\ define custom implementations for \texttt{Unificator} and \texttt{Solver} to provide novel inference mechanisms involving some variant of the unification algorithm.
%
Of course, a detailed diagram would include several more types, as the \twopkt{} API also supports:
%
\begin{inlinelist}
    \item (de)se\-ria\-li\-sa\-tion of logic terms and theories into/from standard data-representation formats such as JSON, or YAML;
    \item parsing/formatting logic terms and theories from/into concrete logic syntaxes such as Prolog's one;
    \item letting developers extend solvers via libraries of custom LP functionalities;
    \item letting users exploit logic solvers either by a command-line (CLI) and graphical (GUI) user interface;
\end{inlinelist}
%
etc.

\subsection{Overview of Functionalities}
\label{ssec:functionalities}

% Present the major functionalities of the software.

Each major \twopkt{} functionality is reified into a particular module.
%
Accordingly, in this subsection we enumerate \twopkt{} functionalities on a per-module basis.
%
Following Gradle convention, we denote modules by \module{mo\-du\-le\-Na\-me}.

The most fundamental module is \module{core}, which exposes types for representing symbolic knowledge via terms and clauses, other than methods to support their manipulation (e.g. construction, unfolding, scoping, formatting, etc.) for OOP or FP programmers.
%
It comes with several data structures aimed at covering most common KR needs in LP.
%
However, novel sorts of terms and clauses may optionally be added by developers by extending/implementing any public interface in \module{core}.
%
Furthermore, the pervasive adoption of an \emph{immutable} design makes data structures in \module{core} well suited for concurrent and multi-threaded contexts.

Terms and clauses are often compared or manipulated in LP via \emph{unification}.
%
Arguably \cite{Sterling1996}, unification \cite{unification-automatedreasoningbook2001} is -- by itself --, among the most useful contributions of LP to AI.
%
For this reason, we encapsulate it within an \emph{ad-hoc} module, \module{unify}, coming with a general notion of \texttt{Unificator} -- i.e. any algorithm aimed at computing MGU out of terms or clauses --, and a default implementation based on \cite{MartelliMontanari1982}.
%
Developers may extend the default implementation by configuring e.g. when terms should be considered equal or not, or they can provide a different implementation for \texttt{Unificator}, in case they need a specific unification strategy, or, they  prefer to adopt a different unification algorithm.

Another common need in LP is the in-memory storage of clauses into ordered -- e.g. queues -- or unordered -- e.g. multisets -- data structures, and their efficient retrieval via pattern-matching (e.g. unification).
%
The \module{theory} module follows this purpose, by providing notions such as \texttt{ClauseQueue}, \texttt{ClauseMultiset}---all coming both in an \emph{immutable} (access-efficient) and \emph{mutable} (update-efficient) implementation.
%
These data structures differ from ordinary collections as they enable an unification-based retrieval and indexing of clauses.
%
Prolog's notions of theory, and static/dynamic KB are built on top these data structures, exploiting the most adequate implementation in each case.

The practice of LP may also involve several ancillary operations over terms and clauses, e.g.:
%
\begin{inlinelist}
    \item formatting -- into some \emph{customisable} form --,
    \item (de)serialization -- into/from open data-representation formats such as JSON or YAML --, and
    \item parsing---out of a particular concrete syntax, such as, e.g., Prolog syntax.
\end{inlinelist}
%
While formatting is considered a \module{core} functionality, attained via the \texttt{TermFormatter} type, (de)serialization and parsing come with their own modules.
%
Thus, module \module{serialize-core} (resp. \moduleStyle{-theory}) supports the serialisation and deserialisation of terms (resp. theories) into JSON or YAML, according to a human-readable schema.
%
This is aimed at supporting distributed applications needing to exchange logic knowledge over the network.
%
Similarly, parsing terms (resp. theories) in Prolog syntax is currently supported through the \module{parser-core} (resp. \moduleStyle{-theory}) module, which is based on the well-known ANTLR technology \cite{Parr2013} for language engineering.

A generic API for logic solvers is available as well within the \module{solve} module.
%
Conceptually, the purpose of this module is as simple as exposing the \texttt{Solver} type, which represents any entity capable of performing some sort of logic resolution to provide one or more \texttt{Solution}s to a logic query.
%
However, resolution involves many practical aspects -- such as errors management, extensibility via libraries, I/O, etc. -- which are \emph{orthogonal} w.r.t. any particular resolution strategy.
%
This is why \module{solve} is a quite articulated -- despite not directly usable -- module.

While developers may easily build their inference procedure of choice by providing an implementation for the \texttt{Solver} interface -- possibly selectively reusing features from \module{solve} --, two implementations are currently available as part of \twopkt{} -- namely \module{solve-classic} and \moduleStyle{-streams} --, both implementing Prolog's SLDNF resolution strategy.
%
In particular, \module{solve-classic} is based on the work of Piancastelli et al. \cite{tuprolog-sac08} and is currently stable, while \module{solve-streams} is an experimental attempt of implementing Prolog via LP following the idea proposed in \cite{Carlsson84}.
%
Notably, none of them relies on the Warren Abstract Machine \cite{Warren1983}---the computational model Prolog is commonly built upon.

A generic API for developing Prolog-like predicates in Kotlin is available as well.
%
It heavily leverages FP and OOP to let developers extend their solvers with libraries of complex functionalities -- possibly involving backtracking or side-effects -- which are easier to implement in Kotlin than through LP.
%
There, lazy streams of data are treated as flows of solutions to be enumerated via backtracking.
%
This makes \twopkt{} very well-suited for handling possibly infinite streams of data via LP---an essential feature in modern AI.

User experience (UX) is enabled by two more modules -- namely, \module{repl} and \module{ide} --, which provide a CLI and GUI, respectively.
%
While they both target JVM-specific UX, an experimental web-based GUI is available at \cite{2P-Playground}, targetting JS-specific UX.

The many \module{dsl-*} modules in \cref{fig:2p-kt-project-map} are aimed at supporting the Kotlin-based DSL for LP described in \cite{kotlindsi4prolog-woa2020}.
%
It consists of façade to \twopkt{} API aimed at blending the OOP, FP, and LP programming paradigms via Kotlin's flexible syntax.
%
Within the \twopkt{} project, this DSL is extensively exploited for unit testing.

Finally, the \module{oop-lib} module is experimental logic library aimed at supporting the exploitation of OOP from within logic programs.

\note{Go on describing \twopkt}

\chapter{Bridging LP and Stream Processing}

\mypapers{2pkt-jelia2021}

Streams are a powerful abstraction in computer science as they enable the processing of huge amounts of data, especially when keeping all data in memory would be impractical or infeasible.
%
In the era of the Internet of Things (IoT) and data-driven artificial intelligence (AI), the ability of manipulating possibly unlimited streams of data is a must-have for all programming paradigms and languages.
%
Indeed, a growing amount of application scenarios are characterised by the pervasive exploitation of smart devices generating/capturing huge amounts of data, as well as of the software infrastructures aimed at processing them.

A stream is an \emph{ordered sequence} of data that may or may not be limited in length.
%
Stream processing facilities are thus commonly constructed in such a way that streams are \emph{lazily consumed}, in order to minimise the amount of required memory---which may be soon saturated otherwise.
%
However, despite all sorts of streams are lazily consumed, categories may be drawn depending on how they are \emph{generated}.
%
Depending on how the are \emph{generated}, streams are either \emph{cold} (a.k.a.\ \emph{pull}) or \emph{hot} (a.k.a.\ \emph{push}).
%
Each item of a cold stream is generated on the fly, as soon as a consumer \emph{pulls} it from the stream.
%
In the case of hot streams, instead, an external entity is supposed to be in charge of generating items and \emph{pushing} them to the stream, so that consumers can retrieve them in a FIFO way.

Cold streams are the simplest ones.
%
A cold stream can be naturally attained via functional programming and higher-order functions (e.g. \texttt{map}, \texttt{filter}, \texttt{reduce}): this is why mainstream programming languages such as Java, C\#, Python, JavaScript, Scala, Kotlin, etc., are being extended to blend functional features and constructs for dealing with streams.
%
Conversely, hot streams are more complex, as they require data to be buffered while waiting for consumption---making them ideal for \emph{temporally} decoupling data consumers and producers.
%
In particular, hot streams are key enablers of advanced stream processing techniques, such as sliding windows, or complex event processing (CEP)---which are deeply entangled with the \emph{time}-related aspects of data production.

In this scenario,  logic programming (LP), as well, has its role to play, both in data-driven AI -- in particular in relation to explainable systems \cite{xaisurvey-ia14} -- or in the IoT \cite{lpaas-bdcc2}.
%
For instance,  LP and rule-based frameworks are generally recognised as well-suited to support CEP~\cite{AnicicFRSSS10,AnicicRFS12}, as they are expressive enough to capture complex events from hot streams.
%
Similarly, answer-set programming (ASP) has been extensively exploited as a means for reasoning over hot streams of data~\cite{EiterIST05,BeckEB17,Beck2018}.

In this paper, we focus on the Prolog~\cite{ColmerauerR93} programming language---arguably, the most popular LP language.
%
Currently, Prolog can hardly be considered as a suitable stream-processing technology~\cite{Tarau2019}, as it provides minimal support for consuming both cold and hot streams.
%
However, we believe that this should be reconsidered because Prolog already supports the lazy exploration of possibly infinite search spaces via \emph{backtracking}.
%
Thus, the problem with Prolog is not to discuss \emph{whether} it supports stream processing or not, but rather \emph{how}.

Existing solutions extend Prolog with syntactical, semantical, or library enhancements aimed at supporting cold streams explicitly.
%
Conversely, in this paper, we discuss how Prolog can be reinterpreted as a \emph{stream processing tool}, capable of manipulating both cold and hot streams of data.
%
In particular, our solution does not affect the syntax (nor the operation) of the Prolog language.
%
More precisely, we show how Prolog predicates may be interpreted as \emph{primitives} of streams to be lazily consumed via backtracking.
%
Along this line, we present an abstract design for Prolog solvers based on finite-state machines, aimed at supporting our notion of primitives.
%
Finally, a practical demonstration based on the \twopkt{} technology \cite{homepage2PKt} is discussed showing how primitives may let a Prolog solver consume events from the external world in a transparent way.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Logic Solvers as Streams Prosumers}\label{sec:primitives}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Logic solvers as stream producers}

\begin{figure}
    \centering
    \caption{Interaction modes between logic solvers and users or KB.}
    \label{fig:user-solver-interaction}
    \begin{subfigure}{0.48\linewidth}\centering
        \includegraphics[width=\linewidth]{figures/stateful-solver.pdf}
        \caption{In \emph{stateful interaction} mode, solvers expose two functionalities: \texttt{solve} -- to compute the first solution to some query --, and \texttt{next}---to compute subsequent solutions to the same query.}
        \label{fig:user-solver-interaction:stateful}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\linewidth}\centering
        \includegraphics[width=\linewidth]{figures/streamful-solver.pdf}
        \caption{In \emph{stream-oriented interaction} mode, solvers expose one functionality: \texttt{solve}---which simply returns a stream of solutions that users may lazily consume}
        \label{fig:user-solver-interaction:streams}
    \end{subfigure}

    \begin{subfigure}{0.48\linewidth}\centering
        \includegraphics[width=\linewidth]{figures/streamful-kb.pdf}
        \caption{Interaction among a logic solver and its KB. As possibly mutable containers of knowledge KB expose three main functionalities: \texttt{get($C$)} returns a \emph{stream} of clauses matching $C$ via unification, whereas \texttt{assert($C$)} (resp. \texttt{retract($C$)}) adds (resp. removes) some clause (unifying with) $C$}
        \label{fig:solver-kb-interaction}
    \end{subfigure}
\end{figure}

Logic solvers \emph{à la Prolog} are typically queried \emph{interactively} by LP users in different \emph{modes}, which are naturally captured by the message passing perspective adopted in \cref{fig:user-solver-interaction}.
%
The most common mode of interaction among users and logic solvers is summarised in \cref{fig:user-solver-interaction:stateful}: users submit \emph{queries} (a.k.a.\ \emph{goals}) to a logic solver -- e.g. a Prolog interpreter -- via some \textit{ad-hoc} operation---e.g., \texttt{solve}.
%
Assuming that one or more \emph{solutions} exist, the solver computes and returns one of them---typically in terms of a \emph{unifying substitution}, assigning values to the query variables of interest for the user.
%
However, the user may be interested in solutions other than the first one: so, the solver should expose one further operation -- e.g., \texttt{next} -- letting users asking for further solutions to some previously-submitted query.
%
Finally, when no (more) solutions are available for a query, the solver can return one (last) answer carrying the \emph{failed} substitution (represented by $\bot$ in \cref{fig:user-solver-interaction}) instead of a unifier.

This mode of interaction is very effective since it enables the \emph{lazy} enumeration of a possibly infinite amount of solutions.
%
However, it comes with a few drawbacks.
%
First, despite logic solvers are actually capable of generating streams of solutions, the notion of stream is somewhat \emph{implicit} in the solver machinery---therefore, not explicitly exploitable.
%
Second, solvers are \emph{stateful}, in that they are responsible to keep track of the status of the interaction with each querying user.

To overcome these issues we suggest a shift of perspective, as depicted in \cref{fig:user-solver-interaction:streams}.
%
There, users and solvers interact in a \emph{stream-oriented} mode, where the stream of solutions is \emph{explicit} and the interaction between solvers and users is \emph{stateless}.
%
Thus, solvers expose just one operation -- i.e., \texttt{solve} -- accepting a user's query and returning a reference to the related \emph{cold} stream of solutions.
%
Users just need solvers to create solution streams that users can then lazily consume on demand.
%
Of course, solutions can still be produced lazily behind the scenes: whenever a user tries to consume a new solution, it can be computed on the fly.

Thus, even though interaction does not change from the operational viewpoint, our approach overcomes the limits of traditional logic solvers: solution streams here are \emph{explicitly} represented, and can therefore be \emph{manipulated} as such.

\subsection{Logic solvers as stream consumers}

By adopting a message passing perspective, logic solvers do not interact with users only.
%
Indeed, logic solvers typically act on a \emph{knowledge base} (KB).
%
In the general case, KBs are containers of the specific knowledge required by solvers to compute solutions to users' queries.
%
For instance, KB for Prolog solvers contain both rules and facts as Horn clauses, and are either static or dynamic.

From an interaction perspective, however, a KB is just a component exploited by solvers as part of their resolution process.
%
More precisely, solvers may need KB to retrieve some clauses, selected via unification, or, to retract or store some knowledge possibly learned/acquired during the resolution.

In particular, clause retrieval highlights how the interaction between solver and KB can be described in terms of streams as well.
%
As depicted in \cref{fig:solver-kb-interaction}, clause retrieval from KB can be modelled as a operation -- e.g., \texttt{get} -- accepting a clause template $C$ and returning the \emph{stream} of clauses unifying with $C$ currently stored into the KB.
%
The solver can then consume the stream as needed, e.g. either lazily or not, depending on the search strategy adopted.

Finally, storing a clause in the KB can be modelled as an \texttt{assert} accepting a clause $C$ and adding it to the KB, whereas clause retraction can be modelled as a \texttt{retract} accepting a clause template $C$ and removing a clause $C'$ unifying with $C$.
%
Both operations could be exploited either by the solver or by some \emph{external} entity willing to affect the solver's knowledge.

%%%%%
\subsection{Solvers vs. the World}

Yet, how can logic solvers deal with event streams coming from the external world?
%
Once KBs are recognised as individual entities, a trivial answer could be: \emph{via KB}.
%
External events may indeed be \emph{reified} into actual knowledge to be stored into some solver's KB.
%
In this scenario, external event streams should be translated into a sequence of \texttt{assert}ions aimed at injecting events into the KB, as facts.
%
The solver could then lazily consume the events by \texttt{get}ting or \texttt{retract}ing the corresponding facts from the KB.

There are, however, two major drawbacks in this approach.
%
First, the reification of events into KB requires space.
%
Second, solvers do not necessarily have to process or \emph{consume} reified events---thus a lot of space is wasted.
%
Accordingly, a different approach is required to let solvers consume event streams from the external world without reifying them unnecessarily.

In this work, we propose \emph{primitives} as the basic means to let solvers interact with the external world.
%
A primitive is a special Prolog facility capable of affecting and inspecting the external world via some I/O facility (\cref{fig:primitives}).
%
It is invoked by a solver and produces a \emph{stream of facts} to be consumed by the same solver.
%
However, from the solvers perspective, primitives are ordinary built-in predicates denoted by \emph{signatures}---i.e., name/arity couples of the form $p/n$.

\begin{figure}\centering
    \includegraphics[width=.65\linewidth]{figures/primitive.pdf}
    \caption{Dataflow and component view of \emph{primitives}, i.e.\ solvers' gates towards the external world}
    \label{fig:primitives}
\end{figure}

More precisely, whenever the solver needs to compute the assignment of variables $T_i$ satisfying relation $p(T_1, \ldots, T_n)$, it can trigger the primitive denoted by $p/n$ (if it exists), by sending the $p/n$ primitive a \emph{request} providing a snapshot of the current resolution context and possibly an initial assignment of some $T_i$.
%
The primitive answers by providing a stream of \emph{responses} -- each one with some possible complete assignment of $T_i$ -- that the solver can consume accordingly to its resolution strategy---i.e., possibly later.
%
To produce responses, primitives may take into account several information sources -- e.g., the resolution context, the external world -- as a part of the request.
%
They may also attempt to \emph{affect} the external world via some I/O \emph{action}---e.g., triggering a sensor.

Depending on the numbers of responses a primitive provides, it can either be classified as either \emph{functional} or \emph{relational}.
%
Functional primitives produce just one response and their execution is therefore analogous to the execution of a function, as they consume an input and return a single result.
%
Conversely, relational primitives produce two or more responses.

%-----------------------------------------------------------------------------------------------%
\subsection{Example: TSP in Prolog}\label{ssec:tsp}
%-----------------------------------------------------------------------------------------------%

Let us consider for instance the case of a user exploiting a standard Prolog system to solve arbitrary instances of the Traveling Salesman Problem (TSP).

Let us assume the system requires maps to be represented as facts in the form \prolog{path(+Src, +Dst, +Cst)} -- each one representing an undirected path between two locations, and the estimated cost --, like e.g.:
%
\begin{lstlisting}[language=Prolog]
path(bucarest, giorgiu, 90).
path(bucarest, pitesti, 101).
path(pitesti, 'rimnicu vilcea', 97).
path(pitesti, craiova, 138).
path('rimnicu vilcea', craiova, 146).
...
\end{lstlisting}
%
Under this assumption, Prolog exposes a predicate \prolog{tsp(?Cities, ?Circuit, ?Cost)} aimed at computing the best \prolog{Circuit} for some set of \prolog{Cities}, and the corresponding \prolog{Cost}---where, \prolog{Cities} is a set of cities, \prolog{Circuit} is a list of cities to be visited in a row, and \prolog{Cost} is an integer.
%
Following a purely-logical interpretation, the predicate represents a ternary relation $\texttt{tsp} \subseteq 2^\mathcal{C} \times \mathcal{C}^* \times \mathbb{N}$ grouping subsets of cities, lists of cities, and non-negative integers, where $\mathcal{C}$ is the set of all cities mentioned in the KB as either the first or second argument of a \prolog{path/3} fact, and $\mathcal{C}^*$ is the Kleene-closure of $\mathcal{C}$.
%
Thus, an assignment of the \prolog{Cities}, \prolog{Circuit}, and \prolog{Cost} variables satisfies the predicate if
%
\begin{itemize}
    \item \prolog{Circuit} $\equiv [c_0, \ldots, c_{n-1}, c_0]$, and
    \item \prolog{Cities} $\equiv \bigcup_{i=0}^{n-1} \{c_i\}$, and
    \item $\forall i \in \{1, \ldots, n\}$ \texttt{path($c_{i-1}$, $c_{i \mod n}$, $x_i$)} $\in$ KB, and
    \item \prolog{Cost} $\equiv \sum_{i=1}^{n} x_i$, and
    \item \prolog{Cost} is \emph{minimal}.
\end{itemize}
%
Accordingly, because of Prolog backtracking, a query of the form:
%
\begin{lstlisting}[language=Prolog]
?- tsp(Cities, Circuit, Cost).
\end{lstlisting}
%
would enumerate all minimally-costly circuits of all possible subsets of cities in $\mathcal{C}$, and their costs---one for each solution.
%
Users may partially instantiate some variable in order to contextualise their queries: for instance, a query of the form:
%
\begin{lstlisting}[language=Prolog]
?- tsp({pitesti, craiova, 'rimnicu vilcea'}, [pitesti | Others], Cost).
\end{lstlisting}
%
would enumerate all minimally-costly circuits starting in Pitesti, and involving the cities Craiova, and Rimnicu Vilcea.

The predicate \prolog{tsp/3} could be implemented declaratively in Prolog.
%
In its simplest formulation, the predicate may leverage Prolog's depth-first strategy, and its backtracking mechanism to lazily generate all the possible circuits and select the less costly one: not likely the best possible strategy, yet a working one.
%
However, better strategies have been proposed in the literature for solving the TSP, with efficient implementations built upon them---rarely based on pure Prolog.
%
Here, instead, primitives make it possible to exploit external libraries for solving the TSP in Prolog as if they were implemented via LP.

For instance, we assume that a ``ACME TSP'' C library exists that solves TSP efficiently, which can be wrapped within a relational primitive \prolog{tsp/3} to be exploited by a Prolog solver.
%
The primitive \prolog{tsp/3} should work as follows:
%
\begin{enumerate}
    \item whenever the Prolog solver encounters a \prolog{tsp(Cities, Circuit, Cost)} subgoal, it triggers the primitive via a \emph{request} containing a snapshot of the current KB and the \emph{actual} values of \prolog{Cities}, \prolog{Circuit}, and \prolog{Cost};
    \item the primitive reads
    %
    \begin{inlinelist}
        \item the map graph from the KB snapshot, and
        \item the cities from the actual value of \prolog{Cities};
    \end{inlinelist}
    % %
    % these must be marshalled and forwarded to the ACME TSP library---which is triggered behind the scenes;
    \item the primitive generates the stream of all the possible subsets of $\mathcal{C}$ and selects the ones unifying with the actual value of \prolog{Cities}, thus: if \prolog{Cities} is bound to a particular sub-set of cities, then the stream has just one element, otherwise it may have several ones;
    \item for each sub-set of cities in the stream, the primitive triggers ACME TSP and computes the corresponding TSP solution, if any;
    \item every time it is triggered, ACME TSP computes zero or more solutions for the TSP and returns them to the primitive;
    \item for each TSP solution of each selected instantiation of \prolog{Cities}, the primitive yields a response to the solver;
    \item each response may either contain a unifier -- assigning \prolog{Cities} to the selected list of cities, \prolog{Circuit} to the minimally-costly circuit for those cities, and \prolog{Cost} to the cost of that circuit -- or a failed substitution---informing the solver the \prolog{tsp/3} predicate should fail;
    \item the solver can consume the response stream lazily via backtracking.
\end{enumerate}
%
In other words, primitives can be exploited as a means to wrap external data producers and let the solver consume the data they produce via streams.
%
In Prolog, streams of this sort are lazily consumed via ordinary backtracking: the solver lazily generates a new choice point for each element in the stream and handles them as usual.
%
Solvers of different sorts may consume the stream differently---e.g. buffering (some slice of) it, or, handling each datum concurrently.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Solvers as Streams Prosumers via State Machine}
\label{sec:state-machine}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}\centering
    \includegraphics[width=\linewidth]{figures/2p-fsa-dataflow}
    \caption{The primitive-enabled state machine governing Prolog solvers' behaviour. Location \state{Goal Selection} is the initial one, whereas \state{End} and \state{Halt} are the final ones. Location \state{Primitive} (resp. \state{Rule}) \state{Selection} is where primitives (resp. KB) are triggered (resp. queried) and their data streams are opened. Conversely, location \state{Primitive} (resp. \state{Rule}) \state{Execution} is where response (resp. clause) streams are lazily consumed.}
    \label{fig:prolog-fsa}
\end{figure}

In order to design a Prolog solver supporting our notion of primitive, we enhance the Prolog state machine proposed in \cite{tuprolog-sac08} with the capability of lazily consuming streams of data coming from either a primitive or the KB (\cref{fig:prolog-fsa}).
%
In particular, we change how the state machine manages the resolution of (sub-)goals, by supporting the selection of a primitive as a means to provide one or more solutions for (sub-)goals, other than the ordinary selection of rules from the KB.

The state machine in \cref{fig:prolog-fsa} stems from the acknowledgement that a Prolog solver may solve a (sub-)goal by either selecting a primitive or a number of logic rules from the KB.
%
In both cases, a stream of data must be lazily consumed by the solver---either carrying primitive responses or clauses from the KB.

Whenever a stream of data needs to be processed, there are essentially two major phases: the \emph{opening} of the stream -- where a channel between the stream producer and its consumer is created --, and the \emph{consumption} of the stream---where items from the stream are sequentially processed.
%
To support both phases, two more locations are included -- namely \state{Primitive Selection} and \state{Primitive Execution} -- respectively aimed at triggering a primitive and consuming the response stream it provides.
%
Furthermore, to support a stream-oriented interaction among the solver and its KB, we model rule management as well through two locations, namely \state{Primitive Selection} and \state{Primitive Execution}, respectively aimed at querying the KB, and consuming the rule stream it provides.

All the other aspects are handled in the same way as in \cite{tuprolog-sac08}.
%
Thus, state machine execution is triggered whenever a user submits a query to the solver: when this is the case, execution starts from the \state{Goal Selection} location.
%
Then, it may go through any location until it eventually reaches some \emph{final} one (\state{End} or \state{Halt}), where a new solution is yielded---which the user can eventually consume.
%
Once a solution is consumed, the user can either submit a new query or ask for the next solution.
%
In the former case, the automaton is reset to the \state{Goal Selection} location.
%
Conversely, the latter case is only possible if the last solution was provided by the \state{End} location.
%
In that case, the automaton backtracks and looks for the next solution.
%
This may involve stepping through \state{Backtracking}, then moving back into the \state{Primitive} (resp. \state{Rule}) \state{Execution}, in order to consume one more element from some previously-opened response (resp. caluse) stream.

Overall, our state machine affects the operation of a Prolog solver as follows:
%
\begin{enumerate}
    \item $\left[\state{Primitive Selection}\right]$ whenever a new sub-goal is selected, the solver looks for a primitive whose signature matches the sub-goal one;

    \item $\left[\state{Primitive Execution}\right]$ if some are found, the solver considers the first response in the stream as a solution to the goal, and generates choice points for subsequent responses;

    \item $\left[\state{Rule Selection}\right]$ otherwise, if no primitive is selected for the current sub-goal, some rule is looked for instead, whose head unifies with the sub-goal;

    \item $\left[\state{Rule Execution}\right]$ if any such rule is found, resolution can proceed by addressing the rule's body as the next goal to be proved;

    \item $\left[\state{Backtracking}\right]$ otherwise, if no rule is found, the sub-goal is considered failed and resolution must backtrack.
\end{enumerate}
%
Location \state{Exception} completes the picture by intercepting exceptions -- possibly thrown by primitives as part of some response of theirs --, via the standard \prolog{catch/3} predicate.

Ordinary Prolog built-in primitives naturally fit the picture as they are re-interpreted as  primitives by solvers.
%
For instance, the \texttt{is/2} predicate can be considered a functional primitive accepting a variable and an expression and returning a single response assigning the variable to the value attained by reducing the expression -- if possible --, or an exception---in case the expression cannot be reduced.
%
Conversely, the \prolog{member/2} predicate can be considered as a relational primitive, enumerating all the possible items in a list.
%
Accordingly, the aforementioned \state{Primitive Selection} location is where built-in primitives are selected for execution in place of rules from the KB.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Predicates as Streams in \twopkt{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In order to demonstrate the feasibility of our approach, we propose a case study based on \twopkt{}.
%
\twopkt{} \cite{cco-softwarex-2021-2pkt} is a Kotlin-based ecosystem for LP, including general API for stream-oriented logic solvers of any sort.
%
Regardless of the particular logic, inference rule, or search strategy of choice, a logic solver is modelled in \twopkt{} as a prosumer of streams: it produces output streams of solutions and consumes input streams generated by primitives.
%
A Prolog solver implementation is available as well, leveraging the state-machine-based design presented in \cref{sec:state-machine}.
%
Furthermore, \twopkt{} involves an API for writing primitives in Kotlin, by blending an imperative, object-oriented, and functional programming style .

In this section, we first illustrate briefly the portion of the \twopkt{} API involving solvers and primitives, then we discuss an example primitive implementing the TSP example from \ref{ssec:tsp}.

\subsection{\twopkt{} Solvers and Primitives API}

Here we focus on the resolution-related portion of the \twopkt{} API (cf. \cref{chap:ecosystem} for further details).
%
There, logic solvers are modelled as instances of the \kotlin{Solver} type defined as follows:
%
\lstinputlisting[language=Kotlin]{listings/Solver.kt}
%
Essentially, a logic solver is any entity exposing a method \kotlin{solve} which accepts a logic \kotlin{Struct}ure -- i.e., a particular case of logic \kotlin{Term} in the \twopkt{} type system -- as the input goal, and produces a \kotlin{Sequence} -- i.e., a \emph{lazy} stream in the Kotlin type system -- of logic \kotlin{Solution}s as output.
%
Furthermore, \twopkt{} requires each logic solver to be composed by at least three more entities, namely:
%
\begin{inlinelist}
    \item a \kotlin{staticKb} and
    \item a \kotlin{dynamicKb}, both of type \kotlin{Theory} -- that is, an ordered and indexed container of logic clauses, retrievable via unification --, and
    \item a \kotlin{libraries} container of type \kotlin{Libraries}---which, within the scope of this section, is essentially an implementation of the structure indexing primitives.
\end{inlinelist}

Each \kotlin{Solution} in \twopkt{} may be of any of three sorts, namely \kotlin{Yes}, \mbox{\kotlin{No},} and \kotlin{Halt}, representing the positive, negative, and exceptional case, respectively.
%
All solutions carry the original query they are answering to, other than the \kotlin{Substitution} they are answering through.
%
So for instance, objects of type \kotlin{Solution.Yes} always contain an object of type \kotlin{Substitution.Unifier}, whereas other sorts of solutions always contain an object of type \kotlin{Substitution.Fail}.
%
Similarly, objects of type \kotlin{Solution.Halt} carry the uncaught exception which interrupted the resolution process.

Primitives are modelled in \twopkt{} as functions of the type:
%
\lstinputlisting[language=Kotlin]{listings/Primitive.kt}
%
i.e., functions accepting a \kotlin{Request} as input and returning a \kotlin{Sequence} of \kotlin{Responses} as output.
%
There, \kotlin{Request} is a container of all the information needed at runtime to produce a sequence of \kotlin{Response}s:
%
\lstinputlisting[language=Kotlin]{listings/Request.kt}
%
These include:
%
\begin{inlinelist}
    \item a snapshot of \kotlin{ExecutionContext} at invocation time -- in turn including a snapshot of the solver's \kotlin{staticKb} and \kotlin{dynamicKb} --,
    \item the \kotlin{Signature} of the invoked primitive, and
    \item the \kotlin{List} of \kotlin{Terms} storing actual \kotlin{arguments} provided to the primitive upon invocation.
\end{inlinelist}
%
Furthermore, each instance of \kotlin{Request} exposes a bunch of methods -- namely, the many \kotlin{reply*()} ones --, aimed at generating a new \kotlin{Response} for that particular \kotlin{Request}.
%
As \kotlin{Response}s are mere containers of \kotlin{Solution}s, there are many variants of the \kotlin{reply*()} methods, each one aimed at generating a given sort of responses -- e.g. responses carrying positive/negative/exceptional solutions -- for the sub-goal that triggered the primitive.
%
Finally, each request supports the spawning of an inner resolution process via its \kotlin{solve(...)} method.
%
This method creates a novel sub-solver through which primitive implementors can resolve sub-queries as part of some primitive execution.

Thanks to this design, any Kotlin method of the form:
%
\lstinputlisting[language=Kotlin]{listings/method.kt}
%
can be considered a primitive in the eyes of a logic solver.
%
This leverages a particular feature of Kotlin, namely the \kotlin{sequence \{ ... \}} blocks, which let developers write stream \emph{primitives} by blending the imperative and functional programming styles.
%
This is possible because of the \kotlin{yield(value)} method which users may call inside \kotlin{sequence \{ ... \}} blocks in place of \kotlin{return value} to provide values to the stream.

So, for instance, to implement the predicate \prolog{natural/1} -- which holds true for all natural numbers --, one may write the following primitive:
%
\lstinputlisting[language=Kotlin]{listings/natural.kt}
%
A Prolog solver would then treat such a primitive as a backtrackable predicate.
%
Thus, in Prolog, one may use the goal \prolog{natural(X)} to enumerate all the natural numbers.
%
Similarly, to implement the predicate \prolog{even/1} -- which holds true for all \emph{even} natural numbers --, one may simply rewrite method \kotlin{natural} as follows:
%
\lstinputlisting[language=Kotlin]{listings/even.kt}

Summarising, \twopkt{} primitives API supports the creation of backtrackable Prolog predicates out of lazy data streams.

\subsection{Travelling Salesman Problem in \twopkt{}}

The real potential of primitives is revealed when they are exploited by solvers to manage input data streams from the external world.
%
There, the external world may be any source of data, there including other solvers, possibly of different nature.
%
For example, primitives may be exploited to let a Prolog solver call a TSP solver to efficiently compute solutions for TSP instances, as discussed in \cref{ssec:tsp}.
%
Accordingly, here we demonstrate how a primitive of such a sort may be realised through \twopkt{}.

In \cite{2P-Kt-TSP-Example} we provide a GitHub repository hosting the source code of a \twopkt{} primitive leveraging Google OR-Tools \cite{ortools} to efficiently solve TSP instances.
%
Google OR-Tools is a C++ library proving many constraint programming and operative research tools -- there including routing-related facilities --, and some JVM bindings which let us exploit such tools in Kotlin.

Accordingly, our repository includes some scripts aimed at automating the compilation and execution of a simple demo involving a command-line TSP-enabled Prolog interpreter.
%
Following the discussion from \cref{ssec:tsp}, such a Prolog interpreter exposes a \prolog{tsp/3} predicate aimed at enumerating the minimally-costly circuits for any given set of cities, provided that the interpreter's KB contains several \prolog{path/3} facts describing the connections among those cities.
%
As an ordinary Prolog interpreter, such facts may be either consulted from a \texttt{.pl} file or dynamically asserted via \prolog{assert/1}.

\begin{figure}
    \lstinputlisting[basicstyle=\ttfamily\tiny,language=Kotlin]{listings/Tsp.kt}
    \caption{\twopkt{} primitive implementing the \prolog{tsp/3} predicate}
    \label{lst:2pkt:tsp}
\end{figure}

The actual operational behaviour of predicate \prolog{tsp/3} is governed by the \texttt{Tsp} primitive whose source code (stub) is shown in \cref{lst:2pkt:tsp} (cf. \cite{2P-Kt-TSP-Example} for full source code).
%
The \kotlin{Tsp} primitive is a singleton object of type \kotlin{TernaryRelation} -- i.e., a particular sort of \kotlin{Primitive}, tailored on ternary predicates --, whose main behaviour is encapsulated within the \kotlin{computeAll} method.

The \kotlin{Tsp} object is also endowed with a method -- namely, \kotlin{tsp} -- which returns a sequence of circuits and costs for any given list of cities provided as input.
%
Such method assumes each input city to be represented by a logic term -- in particular, a constant --, and outputs circuits represented as logic lists of cities represented in the same way.
%
Behind the scenes, the \kotlin{tsp} interacts both the Prolog interpreter's KB to read distances among cities, and a Google OR-Tool solver for computing all possible solution to a particular TSP instance.

The \kotlin{computeAll} handles the situation where the Prolog interpreter meets a (sub-)goal of the form \prolog{tsp(Cities, Circuit, Cost)}---where all variables may be partially or totally uninstantiated.
%
The method operation can then be described as a pipeline of \emph{lazy} operations applied to the actual arguments of \prolog{tsp/3}, which we refer as \kotlin{fst}, \kotlin{snd}, and \kotlin{trd} within the method.
%
Accordingly, the method firstly performs a sub-query aimed at computing the set of all cities currently contained into the KB (cf. variable \kotlin{allCities} in \cref{lst:2pkt:tsp}).
%
The sub-query is a Prolog goal of the form \prolog{path(_, _, _)}, whose solutions are all eagerly consumed and their first and second arguments -- which are assumed to be city names -- are merged into a set, to remove duplicates.
%
Then, all possible permutations of all possible subsets of \kotlin{allCities} are lazily generated.
%
However, only the subsets of cities that unify with \kotlin{fst} are actually selected (this may be just one set of cities if \kotlin{fst} refers to a fully instantiated set of cities) for the next steps of the computation.
%
Then, for all selected sets of cities, all possible solutions to the corresponding TSP instance are computed.
%
Finally, each possible circuit (resp.\ cost) computed for each TSP instance is unified with \kotlin{snd} (resp. \kotlin{trd}).
%
Failed unifications are of course dropped, while the successful ones are converted into responses of the \prolog{tsp/3} primitive.

It is worth to highlight that the whole pipeline is \emph{lazy}.
%
This implies that even once the first TSP solution has been presented to the user, the other ones are still to be computed.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Towards Side-Effects and Concurrency}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\note{remove recap, expand future works. mention concurrency in future works}

In this paper we address the issue of stream processing in logic programming.

In particular, we discuss how logic solvers can be naturally conceived as lazy prosumers of data streams as they
%
\begin{inlinelist}
    \item lazily \emph{produce} data streams thanks to their interactive nature,
    \item lazily \emph{consume} data streams as part of their resolution process---e.g. when they access knowledge bases.
\end{inlinelist}
%
Furthermore, we show how logic solvers can support the processing of input data stream via the notion of predicates as \emph{primitives}, which we introduce in this paper.
%
Summarising, primitives are reactive computational units which logic solvers may trigger so as to receive data streams from the external world.
%
This may be useful, for instance, to let a solver delegate some part of its resolution process to some external entity---assuming that it is optimised to the purpose.

To demonstrate the feasibility of our approach in the specific (and technically most relevant) case of Prolog, we propose a primitive-enabled modelling of Prolog solvers as state machines, formalising the lazy consumption of streams via backtracking.
%
The proposed formalisation preserves the standard operation of Prolog and requires no modification to the language, while enabling Prolog solvers to process data streams.

Finally, we discuss the use case of \twopkt{} \cite{homepage2PKt}, a Kotlin-based technology for LP including an implementation of Prolog solvers relying on our state-machine-based formalisation.
%
We then exploit \twopkt{} to show how primitives can be used to bridge different sorts of solvers together via a few lines of Kotlin code.

In our perspective, this work represents one further step towards the \emph{practical} exploitation of LP -- and, in particular, Prolog -- as a general means for stream processing.
%
Notably, our contribution presents some similarities with other works~\cite{Tarau2019,Redl16}.
%
In particular, similarly to~\cite{Tarau2019}, we focus on letting Prolog manipulate streams of data; while, similarly to~\cite{Redl16}, we provide a mechanism to let logic solvers delegate computations to extenal entities.
%
However, differently from~\cite{Tarau2019}, we require no variation to the syntax, functioning, or libraries of Prolog; while, unlike~\cite{Redl16}, we focus on Prolog rather than ASP.

A number of issues remain uncovered in this work, and will be the subject of our future research.
%
Among the many, the most relevant issues concern \emph{time} and \emph{side effects}.
%
In particular we plan to explore the temporal dimension in LP-based stream processing, by providing for instance some means to support time-dependent or time-limited data streams.
%
Similarly, we would like to explore the intricacies related to the processing of data streams which may affect the internal state of a logic solver -- e.g. by affecting the KB -- in a predictable way.

\chapter{Bridging LP and Object Orientation}

\cite{cco-softwarex-2021-2pkt}
\cite{kotlindsi4prolog-woa2020}

\chapter{Bridging LP and Machine Learning}

Castiglio

\chapter{Bridging LP and XAI}

Psyke

\chapter{Enriching the Ecosystem}

\section{Probabilistic Logic Programming}

Jason

\section{Concurrent Logic Programming}

Giordano

\section{Inductive Logic Programming}

Speciale

\part{Who}
\label{part:who}

\cite{imagination-extraamas2021}
\cite{expectation-extraamas2021}

\chapter{Adding Control to Data via Agents}

\chapter{On the role of Interaction}

\cite{tusow-icccn2019}
\cite{respect-idc2017}
\cite{respectx-comsis15}

\chapter{Blockchain as the way to Trustworthiness}

\cite{bctcoord-bct4mas2018wi}
\cite{bctcoord-bct4mas2019}
\cite{bctcoordination-information11}
\cite{blockchain-goodtechs2018}
\cite{proactivesc-blockchain2019}
\cite{blockchainmas-applsci10}


%----------------------------------------------------------------------------------------
% BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\backmatter

\part*{}

% \nocite{*} % uncomment this to show all the reference in the .bib file
\bibliographystyle{alpha}
\bibliography{phd-thesis,ccdo-information-2020}


\end{document}